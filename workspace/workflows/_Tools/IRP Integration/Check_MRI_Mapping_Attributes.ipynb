{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# Check MRI Mapping Attributes\n",
    "\n",
    "This notebook checks MRI import files (Account and Location CSVs) against a mapping.json file to identify any **missing attributes** in the mapping.\n",
    "\n",
    "**What it does:**\n",
    "- Reads the CSV headers from Account and Location import files\n",
    "- Compares them against the `source` entries in the mapping.json file\n",
    "- Reports any CSV columns that are **not mapped** (missing from mapping)\n",
    "\n",
    "**This is a read-only operation** - it does not modify any files. Use this to preview what changes would be needed before running an MRI import.\n",
    "\n",
    "**Note:** During actual MRI import submission, missing attributes are automatically added to the mapping file. This notebook lets you check beforehand."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup-header",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "setup",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "from helpers.irp_integration.mri_import import MRIImportManager\n",
    "\n",
    "print(\"Setup complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "config-header",
   "metadata": {},
   "source": [
    "## 2. Configuration\n",
    "\n",
    "Specify the paths to your import files and mapping file.\n",
    "\n",
    "**Options:**\n",
    "1. **Use active cycle files** - Files are resolved from the active cycle's `files/working_files/` and `files/mapping/` directories\n",
    "2. **Specify paths directly** - Provide full paths to each file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "config",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Option 1: Use active cycle directories ===\n",
    "# Set USE_ACTIVE_CYCLE = True and specify just the filenames\n",
    "\n",
    "USE_ACTIVE_CYCLE = True  # Set to True to use active cycle directories\n",
    "\n",
    "# Filenames (used with Option 1)\n",
    "ACCOUNTS_FILE_NAME = \"Modeling_202503_Moodys_USOW_Account.csv\"\n",
    "LOCATIONS_FILE_NAME = \"Modeling_202503_Moodys_USOW_Location.csv\"\n",
    "MAPPING_FILE_NAME = \"mapping.json\"\n",
    "\n",
    "# === Option 2: Specify full paths directly ===\n",
    "# Set USE_ACTIVE_CYCLE = False and specify full paths below\n",
    "\n",
    "ACCOUNTS_FILE_PATH = \"/home/jovyan/workspace/workflows/_Tools/files/working_files/Modeling_202511_Moodys_Quarterly_USEQ_Account.csv\"\n",
    "LOCATIONS_FILE_PATH = \"/home/jovyan/workspace/workflows/_Tools/files/working_files/Modeling_202511_Moodys_Quarterly_USEQ_Location.csv\"\n",
    "MAPPING_FILE_PATH = \"/home/jovyan/workspace/workflows/_Template/files/mapping/mapping.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "resolve-paths",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using active cycle directories:\n",
      "  Data directory: /home/jovyan/workspace/workflows/Active_Test-USEQ/files/data\n",
      "  Mapping directory: /home/jovyan/workspace/workflows/Active_Test-USEQ/files/mapping\n",
      "\n",
      "Files to check:\n",
      "  Accounts:  /home/jovyan/workspace/workflows/Active_Test-USEQ/files/data/Modeling_202503_Moodys_USOW_Account.csv\n",
      "  Locations: /home/jovyan/workspace/workflows/Active_Test-USEQ/files/data/Modeling_202503_Moodys_USOW_Location.csv\n",
      "  Mapping:   /home/jovyan/workspace/workflows/Active_Test-USEQ/files/mapping/mapping.json\n",
      "\n",
      "All files found.\n"
     ]
    }
   ],
   "source": [
    "# Resolve file paths based on configuration\n",
    "if USE_ACTIVE_CYCLE:\n",
    "    from helpers.irp_integration.utils import get_cycle_file_directories\n",
    "    \n",
    "    dirs = get_cycle_file_directories()\n",
    "    accounts_path = os.path.join(dirs['data'], ACCOUNTS_FILE_NAME)\n",
    "    locations_path = os.path.join(dirs['data'], LOCATIONS_FILE_NAME)\n",
    "    mapping_path = os.path.join(dirs['mapping'], MAPPING_FILE_NAME)\n",
    "    \n",
    "    print(\"Using active cycle directories:\")\n",
    "    print(f\"  Data directory: {dirs['data']}\")\n",
    "    print(f\"  Mapping directory: {dirs['mapping']}\")\n",
    "else:\n",
    "    accounts_path = ACCOUNTS_FILE_PATH\n",
    "    locations_path = LOCATIONS_FILE_PATH\n",
    "    mapping_path = MAPPING_FILE_PATH\n",
    "    \n",
    "    print(\"Using specified file paths.\")\n",
    "\n",
    "print()\n",
    "print(\"Files to check:\")\n",
    "print(f\"  Accounts:  {accounts_path}\")\n",
    "print(f\"  Locations: {locations_path}\")\n",
    "print(f\"  Mapping:   {mapping_path}\")\n",
    "\n",
    "# Validate files exist\n",
    "missing_files = []\n",
    "for path, name in [(accounts_path, \"Accounts\"), (locations_path, \"Locations\"), (mapping_path, \"Mapping\")]:\n",
    "    if not os.path.exists(path):\n",
    "        missing_files.append(f\"{name}: {path}\")\n",
    "\n",
    "if missing_files:\n",
    "    print()\n",
    "    print(\"ERROR: The following files were not found:\")\n",
    "    for f in missing_files:\n",
    "        print(f\"  - {f}\")\n",
    "    raise FileNotFoundError(\"One or more files not found. Please check the paths.\")\n",
    "else:\n",
    "    print()\n",
    "    print(\"All files found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "check-header",
   "metadata": {},
   "source": [
    "## 3. Check Missing Attributes\n",
    "\n",
    "Run the check to see which CSV columns are missing from the mapping file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "check-missing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "MAPPING ATTRIBUTE CHECK RESULTS\n",
      "============================================================\n",
      "\n",
      "Accounts file:  Modeling_202503_Moodys_USOW_Account.csv\n",
      "Locations file: Modeling_202503_Moodys_USOW_Location.csv\n",
      "Mapping file:   mapping.json\n",
      "\n",
      "------------------------------------------------------------\n",
      "ACCOUNT FILE\n",
      "------------------------------------------------------------\n",
      "Total columns in CSV: 47\n",
      "Missing from mapping: 1\n",
      "\n",
      "Missing account attributes:\n",
      "  - ACCGRPNAME\n",
      "\n",
      "------------------------------------------------------------\n",
      "LOCATION FILE\n",
      "------------------------------------------------------------\n",
      "Total columns in CSV: 72\n",
      "Missing from mapping: 0\n",
      "\n",
      "All location columns are mapped.\n",
      "\n",
      "============================================================\n",
      "RESULT: 1 attribute(s) missing from mapping\n",
      "\n",
      "These attributes will be automatically added during MRI import.\n",
      "Each will be mapped as: SOURCE -> SOURCE (same name)\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Check for missing attributes\n",
    "result = MRIImportManager.check_missing_mapping_attributes(\n",
    "    mapping_file_path=mapping_path,\n",
    "    accounts_file_path=accounts_path,\n",
    "    locations_file_path=locations_path\n",
    ")\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"MAPPING ATTRIBUTE CHECK RESULTS\")\n",
    "print(\"=\"*60)\n",
    "print()\n",
    "print(f\"Accounts file:  {result['accounts_file']}\")\n",
    "print(f\"Locations file: {result['locations_file']}\")\n",
    "print(f\"Mapping file:   {result['mapping_file']}\")\n",
    "print()\n",
    "\n",
    "# Account results\n",
    "print(\"-\"*60)\n",
    "print(\"ACCOUNT FILE\")\n",
    "print(\"-\"*60)\n",
    "print(f\"Total columns in CSV: {len(result['account_headers'])}\")\n",
    "print(f\"Missing from mapping: {len(result['missing_account_attributes'])}\")\n",
    "\n",
    "if result['missing_account_attributes']:\n",
    "    print()\n",
    "    print(\"Missing account attributes:\")\n",
    "    for attr in sorted(result['missing_account_attributes']):\n",
    "        print(f\"  - {attr}\")\n",
    "else:\n",
    "    print()\n",
    "    print(\"All account columns are mapped.\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Location results\n",
    "print(\"-\"*60)\n",
    "print(\"LOCATION FILE\")\n",
    "print(\"-\"*60)\n",
    "print(f\"Total columns in CSV: {len(result['location_headers'])}\")\n",
    "print(f\"Missing from mapping: {len(result['missing_location_attributes'])}\")\n",
    "\n",
    "if result['missing_location_attributes']:\n",
    "    print()\n",
    "    print(\"Missing location attributes:\")\n",
    "    for attr in sorted(result['missing_location_attributes']):\n",
    "        print(f\"  - {attr}\")\n",
    "else:\n",
    "    print()\n",
    "    print(\"All location columns are mapped.\")\n",
    "\n",
    "print()\n",
    "print(\"=\"*60)\n",
    "\n",
    "if result['has_missing']:\n",
    "    total_missing = len(result['missing_account_attributes']) + len(result['missing_location_attributes'])\n",
    "    print(f\"RESULT: {total_missing} attribute(s) missing from mapping\")\n",
    "    print()\n",
    "    print(\"These attributes will be automatically added during MRI import.\")\n",
    "    print(\"Each will be mapped as: SOURCE -> SOURCE (same name)\")\n",
    "else:\n",
    "    print(\"RESULT: All attributes are mapped. No changes needed.\")\n",
    "\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "details-header",
   "metadata": {},
   "source": [
    "## 4. View All Headers (Optional)\n",
    "\n",
    "View all CSV column headers for reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "view-account-headers",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Account CSV Headers (47 columns):\n",
      "----------------------------------------\n",
      "  1. ACCNTNUM \n",
      "  2. ACCNTNAME \n",
      "  3. ACCGRPNAME [MISSING]\n",
      "  4. UWRITRNAME \n",
      "  5. PRODID \n",
      "  6. BRANCHNAME \n",
      "  7. PRODNAME \n",
      "  8. CEDANTID \n",
      "  9. CEDANTNAME \n",
      " 10. POLICYNUM \n",
      " 11. LOBNAME \n",
      " 12. INCEPTDATE \n",
      " 13. EXPIREDATE \n",
      " 14. UNDCOVAMT \n",
      " 15. UNDCOVCUR \n",
      " 16. PARTOF \n",
      " 17. PARTOFCUR \n",
      " 18. POLICYTYPE \n",
      " 19. POLICYSTRUCTURE \n",
      " 20. MINDEDAMT \n",
      " 21. MINDEDCUR \n",
      " 22. MAXDEDAMT \n",
      " 23. MAXDEDCUR \n",
      " 24. BLANDEDAMT \n",
      " 25. BLANDEDCUR \n",
      " 26. BLANLIMAMT \n",
      " 27. BLANLIMCUR \n",
      " 28. BLANPREAMT \n",
      " 29. BLANPRECUR \n",
      " 30. COMBINEDLIM \n",
      " 31. COMBINEDLCUR \n",
      " 32. COMBINEDDED \n",
      " 33. COMBINEDDCUR \n",
      " 34. COMBINEDPREM \n",
      " 35. COMBINEDPCUR \n",
      " 36. COVBASE \n",
      " 37. LIMITGU \n",
      " 38. USERDEF1 \n",
      " 39. USERDEF2 \n",
      " 40. USERDEF3 \n",
      " 41. USERDEF4 \n",
      " 42. USERTXT1 \n",
      " 43. USERTXT2 \n",
      " 44. POLICYUSERTXT1 \n",
      " 45. POLICYUSERTXT2 \n",
      " 46. POLICYUSERTXT3 \n",
      " 47. POLICYUSERTXT4 \n"
     ]
    }
   ],
   "source": [
    "# View all account headers\n",
    "print(f\"Account CSV Headers ({len(result['account_headers'])} columns):\")\n",
    "print(\"-\"*40)\n",
    "for i, header in enumerate(result['account_headers'], 1):\n",
    "    status = \"[MISSING]\" if header in result['missing_account_attributes'] else \"\"\n",
    "    print(f\"{i:3}. {header} {status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "view-location-headers",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Location CSV Headers (72 columns):\n",
      "----------------------------------------\n",
      "  1. ACCNTNUM \n",
      "  2. LOCNUM \n",
      "  3. LOCNAME \n",
      "  4. ADDRESSNUM \n",
      "  5. STREETNAME \n",
      "  6. DISTRICT \n",
      "  7. DSTRCTCODE \n",
      "  8. CITY \n",
      "  9. CITYCODE \n",
      " 10. STATE \n",
      " 11. STATECODE \n",
      " 12. POSTALCODE \n",
      " 13. COUNTY \n",
      " 14. COUNTYCODE \n",
      " 15. CRESTA \n",
      " 16. LATITUDE \n",
      " 17. LONGITUDE \n",
      " 18. FLOORAREA \n",
      " 19. AREAUNIT \n",
      " 20. CNTRYSCHEME \n",
      " 21. CNTRYCODE \n",
      " 22. NUMBLDGS \n",
      " 23. BLDGSCHEME \n",
      " 24. BLDGCLASS \n",
      " 25. OCCSCHEME \n",
      " 26. OCCTYPE \n",
      " 27. YEARBUILT \n",
      " 28. NUMSTORIES \n",
      " 29. TOCV4VAL \n",
      " 30. TOCV4VCUR \n",
      " 31. TOCV5VAL \n",
      " 32. TOCV5VCUR \n",
      " 33. TOCV6VAL \n",
      " 34. TOCV6VCUR \n",
      " 35. TOCV7VAL \n",
      " 36. TOCV7VCUR \n",
      " 37. TOCV4LIMIT \n",
      " 38. TOCV4LCUR \n",
      " 39. TOCV5LIMIT \n",
      " 40. TOCV5LCUR \n",
      " 41. TOCV6LIMIT \n",
      " 42. TOCV6LCUR \n",
      " 43. TOCV7LIMIT \n",
      " 44. TOCV7LCUR \n",
      " 45. TOCV4DED \n",
      " 46. TOCV4DCUR \n",
      " 47. TOCV5DED \n",
      " 48. TOCV5DCUR \n",
      " 49. TOCV6DED \n",
      " 50. TOCV6DCUR \n",
      " 51. TOCV7DED \n",
      " 52. TOCV7DCUR \n",
      " 53. TOSITELIM \n",
      " 54. TOSITELCUR \n",
      " 55. TOSITEDED \n",
      " 56. TOSITEDCUR \n",
      " 57. TOCOMBINEDLIM \n",
      " 58. TOCOMBINEDLCUR \n",
      " 59. TOCOMBINEDDED \n",
      " 60. TOCOMBINEDDCUR \n",
      " 61. RESISTOPEN \n",
      " 62. ROOFAGE \n",
      " 63. ROOFANCH \n",
      " 64. ROOFSYS \n",
      " 65. CLADRATE \n",
      " 66. ROOFGEOM \n",
      " 67. CLADSYS \n",
      " 68. USERTXT1 \n",
      " 69. USERTXT2 \n",
      " 70. USERID1 \n",
      " 71. USERID2 \n",
      " 72. PRIMARYBLDG \n"
     ]
    }
   ],
   "source": [
    "# View all location headers\n",
    "print(f\"Location CSV Headers ({len(result['location_headers'])} columns):\")\n",
    "print(\"-\"*40)\n",
    "for i, header in enumerate(result['location_headers'], 1):\n",
    "    status = \"[MISSING]\" if header in result['missing_location_attributes'] else \"\"\n",
    "    print(f\"{i:3}. {header} {status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "batch-header",
   "metadata": {},
   "source": [
    "## 5. Batch Check Multiple File Pairs (Optional)\n",
    "\n",
    "Check multiple account/location file pairs against the same mapping file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "batch-config",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No file pairs configured. Add file pairs to FILE_PAIRS list above.\n"
     ]
    }
   ],
   "source": [
    "# Define multiple file pairs to check\n",
    "# Each tuple is (accounts_file_path, locations_file_path)\n",
    "\n",
    "FILE_PAIRS = [\n",
    "    # Example file pairs - update with your actual files\n",
    "    # (\"/path/to/accounts1.csv\", \"/path/to/locations1.csv\"),\n",
    "    # (\"/path/to/accounts2.csv\", \"/path/to/locations2.csv\"),\n",
    "]\n",
    "\n",
    "# Mapping file to use for all checks\n",
    "BATCH_MAPPING_PATH = mapping_path\n",
    "\n",
    "if not FILE_PAIRS:\n",
    "    print(\"No file pairs configured. Add file pairs to FILE_PAIRS list above.\")\n",
    "else:\n",
    "    print(f\"Configured {len(FILE_PAIRS)} file pair(s) to check.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "batch-check",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped - no file pairs configured.\n"
     ]
    }
   ],
   "source": [
    "# Run batch check\n",
    "if FILE_PAIRS:\n",
    "    import pandas as pd\n",
    "    \n",
    "    batch_results = []\n",
    "    \n",
    "    for accounts_path, locations_path in FILE_PAIRS:\n",
    "        try:\n",
    "            result = MRIImportManager.check_missing_mapping_attributes(\n",
    "                mapping_file_path=BATCH_MAPPING_PATH,\n",
    "                accounts_file_path=accounts_path,\n",
    "                locations_file_path=locations_path\n",
    "            )\n",
    "            \n",
    "            batch_results.append({\n",
    "                'accounts_file': result['accounts_file'],\n",
    "                'locations_file': result['locations_file'],\n",
    "                'account_columns': len(result['account_headers']),\n",
    "                'missing_account': len(result['missing_account_attributes']),\n",
    "                'location_columns': len(result['location_headers']),\n",
    "                'missing_location': len(result['missing_location_attributes']),\n",
    "                'status': 'MISSING' if result['has_missing'] else 'OK',\n",
    "                'error': None\n",
    "            })\n",
    "        except Exception as e:\n",
    "            batch_results.append({\n",
    "                'accounts_file': os.path.basename(accounts_path),\n",
    "                'locations_file': os.path.basename(locations_path),\n",
    "                'account_columns': 0,\n",
    "                'missing_account': 0,\n",
    "                'location_columns': 0,\n",
    "                'missing_location': 0,\n",
    "                'status': 'ERROR',\n",
    "                'error': str(e)\n",
    "            })\n",
    "    \n",
    "    # Display results as DataFrame\n",
    "    df = pd.DataFrame(batch_results)\n",
    "    print(\"Batch Check Results:\")\n",
    "    print(\"=\"*80)\n",
    "    display(df)\n",
    "    \n",
    "    # Summary\n",
    "    ok_count = len([r for r in batch_results if r['status'] == 'OK'])\n",
    "    missing_count = len([r for r in batch_results if r['status'] == 'MISSING'])\n",
    "    error_count = len([r for r in batch_results if r['status'] == 'ERROR'])\n",
    "    \n",
    "    print()\n",
    "    print(f\"Summary: {ok_count} OK, {missing_count} with missing attributes, {error_count} errors\")\n",
    "else:\n",
    "    print(\"Skipped - no file pairs configured.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
