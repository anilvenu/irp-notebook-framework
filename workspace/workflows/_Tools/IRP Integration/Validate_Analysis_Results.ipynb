{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# Validate Analysis Results\n",
    "\n",
    "This notebook compares analysis outputs between **production runs** (baseline) and **test runs** to validate that tests produced expected results.\n",
    "\n",
    "**Modes:**\n",
    "- **Single validation**: Compare one production/test pair for one perspective (Section 3A)\n",
    "- **Lookup test IDs**: Populate test analysis IDs by name + EDM lookup (Section 3B)\n",
    "- **Batch validation**: Compare multiple pairs from CSV/XLSX, all perspectives (Section 3C)\n",
    "\n",
    "**Perspectives validated (batch mode):** GR (Gross), GU (Ground-Up), RL (Reinsurance Layer)\n",
    "\n",
    "**Endpoints compared:**\n",
    "- Settings (analysis configuration)\n",
    "- Statistics (`/stats`)\n",
    "- EP Metrics (`/ep`)\n",
    "- Event Loss Table (`/elt`)\n",
    "- Period Loss Table (`/plt`) - HD analyses only\n",
    "\n",
    "**Fields compared per endpoint:**\n",
    "\n",
    "| Endpoint | Fields |\n",
    "|----------|--------|\n",
    "| Settings | engineType, engineVersion, analysisType, analysisMode, analysisFramework, modelProfile, outputProfile, eventRateSchemeNames, peril, perilCode, subPeril, region, regionCode, lossAmplification, insuranceType, vulnerabilityCurve, engineSubType, isMultiEvent |\n",
    "| Statistics | epType, purePremium, totalStdDev, cv, netPurePremium, activation, exhaustion, totalLossRatio, limit, premium, netStdDev, exhaustAllReinstatements |\n",
    "| EP Metrics | epType, value (contains returnPeriods and positionValues arrays) |\n",
    "| ELT | eventId, sourceId, positionValue, stdDevI, stdDevC, expValue, rate, peril, region, oepWUC |\n",
    "| PLT | periodId, eventId, weight, eventDate, lossDate, positionValue, peril, region |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup-header",
   "metadata": {},
   "source": [
    "## 1. Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from helpers.analysis_results_validator import (\n",
    "    AnalysisResultsValidator,\n",
    "    # Single validation output\n",
    "    print_validation_summary,\n",
    "    print_validation_details,\n",
    "    # Batch validation output\n",
    "    batch_results_to_dataframe,\n",
    "    print_batch_summary,\n",
    "    export_batch_failures_to_json,\n",
    "    export_batch_summary_to_csv,\n",
    ")\n",
    "\n",
    "validator = AnalysisResultsValidator()\n",
    "print(\"Setup complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "config-header",
   "metadata": {},
   "source": [
    "## 2. Configuration\n",
    "\n",
    "**Common settings** apply to both single and batch validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "config",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Common Settings ===\n",
    "\n",
    "# Comparison settings\n",
    "RELATIVE_TOLERANCE = 1e-4  # For floating-point comparison (0.01% relative difference)\n",
    "DECIMAL_PLACES = 0         # Values must match when rounded to this many decimal places\n",
    "MAX_DIFF = 100             # Maximum allowed difference between rounded values\n",
    "MAX_DIFFERENCES_TO_SHOW = 10  # Limit output for large datasets\n",
    "\n",
    "# Note: PLT comparison is automatically included for HD analyses only (based on engineType)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compare-header",
   "metadata": {},
   "source": [
    "## 3A. Single Validation (One Pair, One Perspective)\n",
    "\n",
    "Use this section to validate a single production/test pair for a specific perspective.\n",
    "\n",
    "Enter the **appAnalysisId** values - these are the IDs shown in the Moody's RiskModeler UI (e.g., 35810)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compare",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single validation configuration\n",
    "PRODUCTION_APP_ANALYSIS_ID = 1660  # Replace with your production analysis ID\n",
    "TEST_APP_ANALYSIS_ID = 4987        # Replace with your test analysis ID\n",
    "PERSPECTIVE_CODE = 'RL'            # 'GR' (Gross), 'GU' (Ground-Up), 'RL' (Reinsurance Layer)\n",
    "\n",
    "# Run single validation\n",
    "result = validator.validate(\n",
    "    production_app_analysis_id=PRODUCTION_APP_ANALYSIS_ID,\n",
    "    test_app_analysis_id=TEST_APP_ANALYSIS_ID,\n",
    "    perspective_code=PERSPECTIVE_CODE,\n",
    "    relative_tolerance=RELATIVE_TOLERANCE,\n",
    "    decimal_places=DECIMAL_PLACES,\n",
    "    max_diff=MAX_DIFF,\n",
    ")\n",
    "\n",
    "print_validation_summary(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "results-header",
   "metadata": {},
   "source": [
    "### Single Validation Details (if failed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "details",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_validation_details(result, max_differences=MAX_DIFFERENCES_TO_SHOW)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hb4829gvuqj",
   "metadata": {},
   "source": [
    "## 3B. Lookup Test Analysis IDs (Optional)\n",
    "\n",
    "Populate `test_app_analysis_id` by looking up analyses using `test_analysis_name` + `test_edm_name` columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hlyst9m5vz",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.irp_integration import IRPClient\n",
    "import pandas as pd\n",
    "\n",
    "# === Configuration ===\n",
    "LOOKUP_FILE_PATH = 'analysis_results/big_config_ALL_Inc_USIF_results.xlsx'\n",
    "SAVE_OUTPUT = True  # Set to True to save updated file\n",
    "\n",
    "# Load and process\n",
    "df = pd.read_excel(LOOKUP_FILE_PATH)\n",
    "if 'test_app_analysis_id' not in df.columns:\n",
    "    df['test_app_analysis_id'] = pd.NA\n",
    "\n",
    "client = IRPClient()\n",
    "found, errors = 0, 0\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    analysis_name, edm_name = row.get('test_analysis_name'), row.get('test_edm_name')\n",
    "    if pd.isna(analysis_name) or pd.isna(edm_name) or pd.notna(row.get('test_app_analysis_id')):\n",
    "        continue\n",
    "    try:\n",
    "        analysis = client.analysis.get_analysis_by_name(str(analysis_name).strip(), str(edm_name).strip())\n",
    "        if app_id := analysis.get('appAnalysisId'):\n",
    "            df.at[idx, 'test_app_analysis_id'] = int(app_id)\n",
    "            found += 1\n",
    "            print(f\"[OK] {analysis_name} -> {app_id}\")\n",
    "    except Exception as e:\n",
    "        errors += 1\n",
    "        print(f\"[ERROR] {analysis_name}: {e}\")\n",
    "\n",
    "print(f\"\\nFound: {found}, Errors: {errors}\")\n",
    "\n",
    "if SAVE_OUTPUT:\n",
    "    df.to_excel(LOOKUP_FILE_PATH, index=False)\n",
    "    print(f\"Saved to: {LOOKUP_FILE_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mvdxvsp17i",
   "metadata": {},
   "source": [
    "## 3C. Batch Validation (Multiple Pairs, All Perspectives)\n",
    "\n",
    "Use this section to validate multiple production/test pairs from a CSV or XLSX file.\n",
    "All three perspectives (GR, GU, RL) are validated automatically.\n",
    "\n",
    "**File format (CSV or XLSX):**\n",
    "```\n",
    "production_app_analysis_id,test_app_analysis_id,name\n",
    "1575,4342,USFL_Other\n",
    "1576,4343,USEQ_Primary\n",
    "1577,4344,USHU_Full\n",
    "```\n",
    "\n",
    "Required columns:\n",
    "- `production_app_analysis_id`: App analysis ID for production (baseline)\n",
    "- `test_app_analysis_id`: App analysis ID for test run\n",
    "- `name` (optional): Label for this analysis pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5gshlakwaej",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to CSV or XLSX file with analysis pairs\n",
    "FILE_PATH = 'analysis_results/big_config_ALL_Inc_USIF_results.xlsx'  # Replace with your file path (.csv or .xlsx)\n",
    "\n",
    "# Progress callback (optional)\n",
    "def show_progress(current, total, name, perspective):\n",
    "    print(f\"[{current}/{total}] {name} - {perspective}\")\n",
    "\n",
    "# Run batch validation (validates all perspectives: GR, GU, RL)\n",
    "# PLT is automatically included for HD analyses only\n",
    "batch_result = validator.validate_batch_from_file(\n",
    "    file_path=FILE_PATH,\n",
    "    relative_tolerance=RELATIVE_TOLERANCE,\n",
    "    decimal_places=DECIMAL_PLACES,\n",
    "    max_diff=MAX_DIFF,\n",
    "    progress_callback=show_progress,\n",
    ")\n",
    "\n",
    "print()\n",
    "print_batch_summary(batch_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "k2gpk3j77km",
   "metadata": {},
   "source": [
    "### Batch Results Summary Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86xq6dqqwr",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display results as a DataFrame\n",
    "df = batch_results_to_dataframe(batch_result)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vv0n2bh78l",
   "metadata": {},
   "source": [
    "### Export Results (Optional)\n",
    "\n",
    "Export the summary to CSV and detailed failures to JSON."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08kna0xubvmk",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export summary to CSV (saved to validation_outputs folder)\n",
    "summary_path = export_batch_summary_to_csv(batch_result)\n",
    "print(f\"Summary exported to: {summary_path}\")\n",
    "\n",
    "# Export detailed failures to JSON (only if there are failures)\n",
    "if batch_result.failed_count > 0:\n",
    "    failures_path = export_batch_failures_to_json(\n",
    "        batch_result,\n",
    "        max_differences=MAX_DIFFERENCES_TO_SHOW\n",
    "    )\n",
    "    print(f\"Failure details exported to: {failures_path}\")\n",
    "else:\n",
    "    print(\"No failures to export.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c01fab-5a64-452e-a8f1-ec0ce9e4e8bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
