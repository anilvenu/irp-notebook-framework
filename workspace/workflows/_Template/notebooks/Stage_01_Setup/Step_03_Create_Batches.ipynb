{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "notebook_header",
   "metadata": {},
   "source": [
    "# Step 03: Create Batches\n",
    "\n",
    "This notebook creates batches and jobs from the loaded configuration.\n",
    "\n",
    "**Tasks:**\n",
    "- Verify configuration is loaded and valid\n",
    "- Identify batch types to create based on configuration data\n",
    "- Preview databases and job configurations\n",
    "- Create batches (EDM Creation, etc.)\n",
    "- Display batch and job summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": "%load_ext autoreload\n%autoreload 2\n\nfrom helpers.notebook_setup import initialize_notebook_context\nfrom helpers import ux\nfrom helpers.configuration import read_configuration, get_base_portfolios, classify_groupings\nfrom helpers.batch import create_batch\nfrom helpers.database import execute_query\nfrom helpers.constants import BatchType"
  },
  {
   "cell_type": "markdown",
   "id": "context_setup",
   "metadata": {},
   "source": [
    "## 1) Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "context_init",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize notebook context and step tracking\n",
    "context, step = initialize_notebook_context('Step_03_Create_Batches.ipynb', allow_rerun=True)\n",
    "\n",
    "# Display context\n",
    "ux.header(\"Batch Creation\")\n",
    "ux.info(f\"Cycle: {context.cycle_name}\")\n",
    "ux.info(f\"Stage: {context.stage_name}\")\n",
    "ux.info(f\"Step: {context.step_name}\")\n",
    "ux.success(f\"✓ Step tracking initialized for '{context.step_name}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "verify_config_header",
   "metadata": {},
   "source": [
    "## 2) Verify Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verify_config",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify configuration exists and is valid\n",
    "ux.header(\"Configuration Verification\")\n",
    "\n",
    "try:\n",
    "    # Get cycle ID\n",
    "    cycle_result = execute_query(\n",
    "        \"SELECT id FROM irp_cycle WHERE cycle_name = %s\",\n",
    "        (context.cycle_name,)\n",
    "    )\n",
    "    \n",
    "    if cycle_result.empty:\n",
    "        raise ValueError(f\"Cycle not found: {context.cycle_name}\")\n",
    "    \n",
    "    cycle_id = int(cycle_result.iloc[0]['id'])  # Convert numpy.int64 to Python int\n",
    "    \n",
    "    # Get configuration for this cycle\n",
    "    config_result = execute_query(\n",
    "        \"SELECT id, status, created_ts FROM irp_configuration WHERE cycle_id = %s ORDER BY created_ts DESC LIMIT 1\",\n",
    "        (cycle_id,)\n",
    "    )\n",
    "    \n",
    "    if config_result.empty:\n",
    "        ux.error(\"✗ No configuration found for this cycle\")\n",
    "        ux.info(\"Please complete Step 02: Validate Configuration File first\")\n",
    "        step.fail(\"No configuration found for cycle\")\n",
    "        raise ValueError(\"No configuration found for cycle\")\n",
    "    \n",
    "    config_id = int(config_result.iloc[0]['id'])  # Convert numpy.int64 to Python int\n",
    "    config_status = config_result.iloc[0]['status']\n",
    "    config_created = config_result.iloc[0]['created_ts']\n",
    "    \n",
    "    # Verify status is VALID or ACTIVE\n",
    "    if config_status not in ['VALID', 'ACTIVE']:\n",
    "        ux.error(f\"✗ Configuration status is '{config_status}' (expected VALID or ACTIVE)\")\n",
    "        step.fail(f\"Configuration status invalid: {config_status}\")\n",
    "        raise ValueError(f\"Configuration must be VALID or ACTIVE, found: {config_status}\")\n",
    "    \n",
    "    # Display configuration summary\n",
    "    config_info = [\n",
    "        [\"Configuration ID\", config_id],\n",
    "        [\"Status\", config_status],\n",
    "        [\"Created\", config_created.strftime('%Y-%m-%d %H:%M:%S')]\n",
    "    ]\n",
    "    ux.table(config_info, headers=[\"Property\", \"Value\"])\n",
    "    ux.success(\"✓ Configuration verified\")\n",
    "    \n",
    "    step.log(f\"Configuration verified: ID={config_id}, Status={config_status}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    ux.error(f\"✗ Configuration verification failed: {str(e)}\")\n",
    "    step.fail(f\"Configuration verification failed: {str(e)}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "identify_batches_header",
   "metadata": {},
   "source": [
    "## 3) Identify Batch Types to Create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "identify_batches",
   "metadata": {},
   "outputs": [],
   "source": "# Analyze configuration to determine which batch types are needed\nux.header(\"Batch Type Identification\")\n\ntry:\n    # Read configuration data\n    config_data = read_configuration(config_id)\n    \n    # Extract configuration_data JSONB field\n    configuration_data = config_data.get('configuration_data', {})\n    metadata = configuration_data.get('Metadata', {})\n    \n    # Identify batch types based on configuration content\n    batch_types_info = []\n    batch_types_to_create = []\n    \n    # Check for EDM Creation (Databases sheet)\n    databases = configuration_data.get('Databases', [])\n    if databases:\n        batch_types_info.append([BatchType.EDM_CREATION, len(databases), \"One job per database\"])\n        batch_types_to_create.append(BatchType.EDM_CREATION)\n    \n    # Check for EDM DB Upgrade (Databases sheet + EDM Data Version in Metadata)\n    edm_version = metadata.get('EDM Data Version')\n    if databases and edm_version:\n        target_version = edm_version.split('.')[0] if '.' in edm_version else edm_version\n        batch_types_info.append([BatchType.EDM_DB_UPGRADE, len(databases), f\"One job per database (upgrade to v{target_version})\"])\n        batch_types_to_create.append(BatchType.EDM_DB_UPGRADE)\n    \n    # Check for Base Portfolio Creation and MRI Import configuration(Portfolios sheet)\n    portfolios = configuration_data.get('Portfolios', [])\n    if portfolios:\n        # Base Portfolio Creation and MRI Import only applies to Base Portfolios\n        base_portfolios = get_base_portfolios(portfolios)\n        # Add Portfolio Creation\n        batch_types_info.append([BatchType.PORTFOLIO_CREATION, len(base_portfolios), \"One job per portfolio\"])\n        batch_types_to_create.append(BatchType.PORTFOLIO_CREATION)\n        # Add MRI Import\n        batch_types_info.append([BatchType.MRI_IMPORT, len(base_portfolios), \"One job per portfolio\"])\n        batch_types_to_create.append(BatchType.MRI_IMPORT)\n\n    # Check for GeoHaz (Base Portfolios + Geocode Version in Metadata)\n    geocode_version = metadata.get('Geocode Version')\n    if portfolios and geocode_version:\n        if not base_portfolios:\n            base_portfolios = get_base_portfolios(portfolios)\n        if base_portfolios:\n            batch_types_info.append([BatchType.GEOHAZ, len(base_portfolios), f\"One job per base portfolio (geocode v{geocode_version})\"])\n            batch_types_to_create.append(BatchType.GEOHAZ)\n\n    # Check for Portfolio Mapping (Base Portfolios only)\n    if portfolios:\n        if not base_portfolios:\n            base_portfolios = get_base_portfolios(portfolios)\n        if base_portfolios:\n            batch_types_info.append([BatchType.PORTFOLIO_MAPPING, len(base_portfolios), \"One job per base portfolio (SQL mapping)\"])\n            batch_types_to_create.append(BatchType.PORTFOLIO_MAPPING)\n\n    # Check for Reinsurance Treaties (requires both sheets to determine job count)\n    # Always create this batch if both sheets exist - even with 0 jobs, we need it for chaining\n    treaties = configuration_data.get('Reinsurance Treaties', [])\n    analyses = configuration_data.get('Analysis Table', [])\n    treaty_edm_combinations = set()  # Initialize for use in preview section\n    \n    if analyses:  # Only need analyses sheet - treaties sheet can be empty\n        # Build a set of valid treaty names (may be empty if no treaties defined)\n        valid_treaty_names = {t.get('Treaty Name') for t in treaties if t.get('Treaty Name')} if treaties else set()\n        \n        # Collect unique treaty-EDM combinations from Analysis Table\n        treaty_columns = ['Reinsurance Treaty 1', 'Reinsurance Treaty 2', 'Reinsurance Treaty 3',\n                          'Reinsurance Treaty 4', 'Reinsurance Treaty 5']\n        \n        for analysis in analyses:\n            edm = analysis.get('Database')\n            if not edm:\n                continue\n            for col in treaty_columns:\n                treaty_name = analysis.get(col)\n                if treaty_name and treaty_name in valid_treaty_names:\n                    treaty_edm_combinations.add((treaty_name, edm))\n        \n        # Always create batch for chaining - even if 0 jobs (empty batch completes immediately)\n        job_count = len(treaty_edm_combinations)\n        description = f\"One job per treaty-EDM combination\" if job_count > 0 else \"No treaties to create (empty batch for workflow continuity)\"\n        batch_types_info.append([BatchType.CREATE_REINSURANCE_TREATIES, job_count, description])\n        batch_types_to_create.append(BatchType.CREATE_REINSURANCE_TREATIES)\n\n    # Check for Analysis (Analysis Table sheet)\n    if analyses:\n        batch_types_info.append([BatchType.ANALYSIS, len(analyses), \"One job per analysis\"])\n        batch_types_to_create.append(BatchType.ANALYSIS)\n\n    # Check for Grouping (Groupings sheet) - split into analysis-only and rollup groups\n    groupings = configuration_data.get('Groupings', [])\n    if groupings:\n        analysis_only_groups, rollup_groups = classify_groupings(configuration_data)\n        \n        # Add Grouping batch for analysis-only groups\n        if analysis_only_groups:\n            batch_types_info.append([BatchType.GROUPING, len(analysis_only_groups), \"One job per analysis-only group\"])\n            batch_types_to_create.append(BatchType.GROUPING)\n        \n        # Add Grouping Rollup batch for groups containing other groups\n        if rollup_groups:\n            batch_types_info.append([BatchType.GROUPING_ROLLUP, len(rollup_groups), \"One job per rollup group (groups of groups)\"])\n            batch_types_to_create.append(BatchType.GROUPING_ROLLUP)\n\n    # Check for Export to RDM (requires Export RDM Name in Metadata, Analysis Table, and Groupings)\n    rdm_name = metadata.get('Export RDM Name')\n    if rdm_name and analyses and groupings:\n        # Single job exports all analyses and groups\n        analysis_count = len(analyses)\n        group_count = len(groupings)\n        batch_types_info.append([BatchType.EXPORT_TO_RDM, 1, f\"One job to export {analysis_count} analyses + {group_count} groups to '{rdm_name}'\"])\n        batch_types_to_create.append(BatchType.EXPORT_TO_RDM)\n\n    # Display identified batch types\n    if batch_types_info:\n        ux.info(\"Batch types identified from configuration:\")\n        ux.table(batch_types_info, headers=[\"Batch Type\", \"Job Count\", \"Description\"])\n        ux.success(f\"✓ Found {len(batch_types_to_create)} batch type(s) to create\")\n        \n        step.log(f\"Identified {len(batch_types_to_create)} batch type(s): {', '.join(batch_types_to_create)}\")\n    else:\n        ux.warning(\"⚠ No batch types identified from configuration\")\n        ux.info(\"Configuration may not contain required data sheets (Databases, Portfolios, etc.)\")\n        step.fail(\"No batch types identified in configuration\")\n        raise ValueError(\"No batch types identified in configuration\")\n    \nexcept Exception as e:\n    ux.error(f\"✗ Batch type identification failed: {str(e)}\")\n    step.fail(f\"Batch type identification failed: {str(e)}\")\n    raise"
  },
  {
   "cell_type": "markdown",
   "id": "preview_edm_header",
   "metadata": {},
   "source": [
    "## 4a) Preview: EDM Creation Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "preview_edm",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview databases that will become jobs\n",
    "ux.header(\"EDM Creation Batch Preview\")\n",
    "\n",
    "if BatchType.PORTFOLIO_CREATION in batch_types_to_create:\n",
    "    ux.info(f\"This batch will create {len(databases)} job(s), one for each database:\")\n",
    "    ux.info(\"\")\n",
    "    \n",
    "    # Display databases table\n",
    "    database_rows = []\n",
    "    for db in databases:\n",
    "        database_rows.append([\n",
    "            db.get('Database', 'N/A')\n",
    "        ])\n",
    "    \n",
    "    ux.table(database_rows, headers=[\"EDM Name\"])\n",
    "    \n",
    "    ux.info(\"\")\n",
    "    ux.info(\"Each database will become one job with configuration containing:\")\n",
    "    ux.info(\"  - Metadata from configuration file\")\n",
    "    ux.info(\"  - Database-specific fields (Database, Version, EDM_Type, etc.)\")\n",
    "    \n",
    "    step.log(f\"Previewed EDM Creation batch: {len(databases)} databases\")\n",
    "else:\n",
    "    ux.info(\"EDM Creation batch not needed (no databases in configuration)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0bc817a",
   "metadata": {},
   "source": [
    "## 4b) Preview: Base Portfolio Creation Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e2c52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview portfolios that will become jobs\n",
    "ux.header(\"Base Portfolio Creation Batch Preview\")\n",
    "\n",
    "if BatchType.PORTFOLIO_CREATION in batch_types_to_create:\n",
    "    ux.info(f\"This batch will create {len(base_portfolios)} job(s), one for each base portfolio:\")\n",
    "    ux.info(\"\")\n",
    "    \n",
    "    # Display databases table\n",
    "    portfolio_rows = []\n",
    "    for port in base_portfolios:\n",
    "        portfolio_rows.append([\n",
    "            port.get('Portfolio', 'N/A'),\n",
    "            port.get('Database', 'N/A'),\n",
    "        ])\n",
    "    \n",
    "    ux.table(portfolio_rows, headers=[\"Portfolio\", \"EDM\"])\n",
    "    \n",
    "    ux.info(\"\")\n",
    "    ux.info(\"Each portfolio will become one job with configuration containing:\")\n",
    "    ux.info(\"  - Metadata from configuration file\")\n",
    "    ux.info(\"  - Portfolio-specific fields (Portfolio Name, EDM, etc.)\")\n",
    "    \n",
    "    step.log(f\"Previewed Base Portfolio Creation batch: {len(base_portfolios)} portfolios\")\n",
    "else:\n",
    "    ux.info(\"Portfolio Creation batch not needed (no base portfolios in configuration)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c8088d",
   "metadata": {},
   "source": [
    "## 4c) Preview: MRI Import Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9f523c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview portfolios that will become jobs\n",
    "ux.header(\"MRI Import Batch Preview\")\n",
    "\n",
    "if BatchType.MRI_IMPORT in batch_types_to_create:\n",
    "    ux.info(f\"This batch will create {len(base_portfolios)} job(s), one for each base portfolio:\")\n",
    "    ux.info(\"\")\n",
    "    \n",
    "    # Display databases table\n",
    "    portfolio_rows = []\n",
    "    for port in base_portfolios:\n",
    "        portfolio_rows.append([\n",
    "            port.get('Portfolio', 'N/A'),\n",
    "            port.get('Database', 'N/A'),\n",
    "            port.get('Import File', 'N/A')\n",
    "        ])\n",
    "    \n",
    "    ux.table(portfolio_rows, headers=[\"Portfolio\", \"EDM\", \"Import File\"])\n",
    "    \n",
    "    ux.info(\"\")\n",
    "    ux.info(\"Each portfolio will become one job with configuration containing:\")\n",
    "    ux.info(\"  - Metadata from configuration file\")\n",
    "    ux.info(\"  - Portfolio-specific fields (Portfolio Name, EDM, Import File, etc.)\")\n",
    "    \n",
    "    step.log(f\"Previewed MRI Import batch: {len(base_portfolios)} portfolios\")\n",
    "else:\n",
    "    ux.info(\"MRI Import batch not needed (no base portfolios in configuration)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75242db0",
   "metadata": {},
   "source": [
    "## 4d) Preview: Create Reinsurance Treaties Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d682e9d6",
   "metadata": {},
   "outputs": [],
   "source": "# Preview reinsurance treaties that will become jobs\nux.header(\"Create Reinsurance Treaties Batch Preview\")\n\nif BatchType.CREATE_REINSURANCE_TREATIES in batch_types_to_create:\n    if treaty_edm_combinations:\n        ux.info(f\"This batch will create {len(treaty_edm_combinations)} job(s), one for each unique treaty-EDM combination:\")\n        ux.info(\"\")\n        \n        # Display treaty-EDM combinations table\n        treaty_rows = []\n        for treaty_name, edm in sorted(treaty_edm_combinations):\n            treaty_rows.append([treaty_name, edm])\n        \n        ux.table(treaty_rows, headers=[\"Treaty Name\", \"EDM\"])\n        \n        ux.info(\"\")\n        ux.info(\"Each treaty-EDM combination will become one job with configuration containing:\")\n        ux.info(\"  - Metadata from configuration file\")\n        ux.info(\"  - Database (EDM) where the treaty will be created\")\n        ux.info(\"  - Treaty-specific fields from Reinsurance Treaties sheet\")\n        \n        step.log(f\"Previewed Create Reinsurance Treaties batch: {len(treaty_edm_combinations)} treaty-EDM combinations\")\n    else:\n        ux.info(\"This batch will be created with 0 jobs.\")\n        ux.info(\"\")\n        ux.info(\"No reinsurance treaties are defined in the configuration, or no analyses\")\n        ux.info(\"reference any treaties. The batch will be created for workflow continuity\")\n        ux.info(\"and will immediately complete during submission.\")\n        \n        step.log(\"Previewed Create Reinsurance Treaties batch: 0 jobs (empty batch)\")\nelse:\n    ux.info(\"Create Reinsurance Treaties batch not needed (no Analysis Table in configuration)\")"
  },
  {
   "cell_type": "markdown",
   "id": "euqcxauxahc",
   "metadata": {},
   "source": [
    "## 4e) Preview: EDM DB Upgrade Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "irxpez1qmfs",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview EDM DB Upgrade jobs\n",
    "ux.header(\"EDM DB Upgrade Batch Preview\")\n",
    "\n",
    "if BatchType.EDM_DB_UPGRADE in batch_types_to_create:\n",
    "    target_version = edm_version.split('.')[0] if '.' in edm_version else edm_version\n",
    "    ux.info(f\"This batch will create {len(databases)} job(s), one for each database:\")\n",
    "    ux.info(f\"Target EDM Data Version: {target_version}\")\n",
    "    ux.info(\"\")\n",
    "    \n",
    "    # Display databases table\n",
    "    database_rows = []\n",
    "    for db in databases:\n",
    "        database_rows.append([\n",
    "            db.get('Database', 'N/A'),\n",
    "            target_version\n",
    "        ])\n",
    "    \n",
    "    ux.table(database_rows, headers=[\"EDM Name\", \"Target Version\"])\n",
    "    \n",
    "    ux.info(\"\")\n",
    "    ux.info(\"Each database will become one job with configuration containing:\")\n",
    "    ux.info(\"  - Metadata from configuration file\")\n",
    "    ux.info(\"  - Database-specific fields from Databases sheet\")\n",
    "    ux.info(\"  - target_edm_version: The version to upgrade to\")\n",
    "    \n",
    "    step.log(f\"Previewed EDM DB Upgrade batch: {len(databases)} databases to version {target_version}\")\n",
    "else:\n",
    "    ux.info(\"EDM DB Upgrade batch not needed (no databases or EDM Data Version not specified)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hw4sjkxtnf",
   "source": "## 4f) Preview: GeoHaz Batch",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "39aynq8bfe7",
   "source": "# Preview GeoHaz jobs\nux.header(\"GeoHaz Batch Preview\")\n\nif BatchType.GEOHAZ in batch_types_to_create:\n    ux.info(f\"This batch will create {len(base_portfolios)} job(s), one for each base portfolio:\")\n    ux.info(f\"Geocode Version: {geocode_version}\")\n    ux.info(\"\")\n    \n    # Display portfolios table\n    portfolio_rows = []\n    for port in base_portfolios:\n        portfolio_rows.append([\n            port.get('Portfolio', 'N/A'),\n            port.get('Database', 'N/A'),\n            geocode_version\n        ])\n    \n    ux.table(portfolio_rows, headers=[\"Portfolio\", \"EDM\", \"Geocode Version\"])\n    \n    ux.info(\"\")\n    ux.info(\"Each portfolio will become one job with configuration containing:\")\n    ux.info(\"  - Metadata from configuration file\")\n    ux.info(\"  - Portfolio-specific fields from Portfolios sheet\")\n    ux.info(\"  - geocode_version: The geocode version to use\")\n    \n    step.log(f\"Previewed GeoHaz batch: {len(base_portfolios)} base portfolios with geocode v{geocode_version}\")\nelse:\n    ux.info(\"GeoHaz batch not needed (no base portfolios or Geocode Version not specified)\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "srch4y6r8bi",
   "source": "## 4g) Preview: Portfolio Mapping Batch",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "6ky1v7dw2jk",
   "source": "# Preview Portfolio Mapping jobs\nux.header(\"Portfolio Mapping Batch Preview\")\n\nif BatchType.PORTFOLIO_MAPPING in batch_types_to_create:\n    ux.info(f\"This batch will create {len(base_portfolios)} job(s), one for each base portfolio:\")\n    ux.info(\"\")\n    \n    # Display portfolios table\n    portfolio_rows = []\n    for port in base_portfolios:\n        portfolio_rows.append([\n            port.get('Portfolio', 'N/A'),\n            port.get('Database', 'N/A'),\n            port.get('Import File', 'N/A')\n        ])\n    \n    ux.table(portfolio_rows, headers=[\"Portfolio\", \"EDM\", \"Import File\"])\n    \n    ux.info(\"\")\n    ux.info(\"Each portfolio will become one job with configuration containing:\")\n    ux.info(\"  - Metadata from configuration file\")\n    ux.info(\"  - Portfolio-specific fields from Portfolios sheet\")\n    ux.info(\"  - SQL script: 2b_Query_To_Create_Sub_Portfolios_{Import File}_RMS_BackEnd.sql\")\n    ux.info(\"\")\n    ux.info(\"Note: Portfolio Mapping executes SQL scripts locally (not submitted to Moody's)\")\n    \n    step.log(f\"Previewed Portfolio Mapping batch: {len(base_portfolios)} base portfolios\")\nelse:\n    ux.info(\"Portfolio Mapping batch not needed (no base portfolios in configuration)\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "vuxzv595gdt",
   "source": "## 4h) Preview: Analysis Batch",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "eba5961l56p",
   "source": "# Preview Analysis jobs\nux.header(\"Analysis Batch Preview\")\n\nif BatchType.ANALYSIS in batch_types_to_create:\n    ux.info(f\"This batch will create {len(analyses)} job(s), one for each analysis:\")\n    ux.info(\"\")\n    \n    # Display analysis table\n    analysis_rows = []\n    for analysis in analyses[:10]:  # Show first 10\n        # Collect treaty names\n        treaty_names = []\n        for i in range(1, 6):\n            treaty = analysis.get(f'Reinsurance Treaty {i}')\n            if treaty:\n                treaty_names.append(treaty)\n        treaties_str = ', '.join(treaty_names) if treaty_names else 'None'\n        \n        # Collect tag names\n        tag_names = []\n        for i in range(1, 6):\n            tag = analysis.get(f'Tag {i}')\n            if tag:\n                tag_names.append(tag)\n        tags_str = ', '.join(tag_names) if tag_names else 'None'\n        \n        analysis_rows.append([\n            analysis.get('Analysis Name', 'N/A'),\n            analysis.get('Portfolio', 'N/A'),\n            analysis.get('Database', 'N/A'),\n            analysis.get('Analysis Profile', 'N/A')[:30] + '...' if len(analysis.get('Analysis Profile', '')) > 30 else analysis.get('Analysis Profile', 'N/A'),\n        ])\n    \n    ux.table(analysis_rows, headers=[\"Analysis Name\", \"Portfolio\", \"EDM\", \"Analysis Profile\"])\n    \n    if len(analyses) > 10:\n        ux.info(f\"... and {len(analyses) - 10} more analysis job(s)\")\n    \n    ux.info(\"\")\n    ux.info(\"Each analysis will become one job with configuration containing:\")\n    ux.info(\"  - Metadata from configuration file\")\n    ux.info(\"  - Analysis-specific fields (Name, Portfolio, Database, Profiles, Treaties, Tags)\")\n    \n    step.log(f\"Previewed Analysis batch: {len(analyses)} analyses\")\nelse:\n    ux.info(\"Analysis batch not needed (no analyses in configuration)\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "1cbd3q5nyf8",
   "source": "## 4i) Preview: Grouping Batch (Analysis-only Groups)",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "dspjixzqzcn",
   "source": "# Preview Grouping jobs (analysis-only groups)\nux.header(\"Grouping Batch Preview (Analysis-only Groups)\")\n\nif BatchType.GROUPING in batch_types_to_create:\n    ux.info(f\"This batch will create {len(analysis_only_groups)} job(s), one for each analysis-only group:\")\n    ux.info(\"These groups contain ONLY analysis names (no group references).\")\n    ux.info(\"\")\n    \n    # Display groupings table\n    grouping_rows = []\n    for grouping in analysis_only_groups[:10]:  # Show first 10\n        group_name = grouping.get('Group_Name', 'N/A')\n        items = grouping.get('items', [])\n        items_count = len(items)\n        # Show first few items as preview\n        items_preview = ', '.join(items[:3])\n        if len(items) > 3:\n            items_preview += f', ... (+{len(items) - 3} more)'\n        \n        grouping_rows.append([\n            group_name,\n            items_count,\n            items_preview\n        ])\n    \n    ux.table(grouping_rows, headers=[\"Group Name\", \"# Analyses\", \"Analyses (Preview)\"])\n    \n    if len(analysis_only_groups) > 10:\n        ux.info(f\"... and {len(analysis_only_groups) - 10} more grouping job(s)\")\n    \n    ux.info(\"\")\n    ux.info(\"Each grouping will become one job with configuration containing:\")\n    ux.info(\"  - Metadata from configuration file\")\n    ux.info(\"  - Group_Name: Name of the group\")\n    ux.info(\"  - items: List of analysis names to group together\")\n    \n    step.log(f\"Previewed Grouping batch: {len(analysis_only_groups)} analysis-only groups\")\nelse:\n    ux.info(\"Grouping batch not needed (no analysis-only groups in configuration)\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "5ez4ajgwagk",
   "source": "## 4j) Preview: Grouping Rollup Batch (Groups of Groups)",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "hqws47eziql",
   "source": "# Preview Grouping Rollup jobs (groups of groups)\nux.header(\"Grouping Rollup Batch Preview (Groups of Groups)\")\n\nif BatchType.GROUPING_ROLLUP in batch_types_to_create:\n    ux.info(f\"This batch will create {len(rollup_groups)} job(s), one for each rollup group:\")\n    ux.info(\"These groups contain references to OTHER GROUPS (not just analyses).\")\n    ux.warning(\"⚠ IMPORTANT: Grouping Rollup jobs can only run AFTER the Grouping batch completes.\")\n    ux.info(\"\")\n    \n    # Build set of group names to identify which items are groups\n    group_names_set = {g.get('Group_Name') for g in groupings if g.get('Group_Name')}\n    \n    # Display rollup groupings table\n    grouping_rows = []\n    for grouping in rollup_groups[:10]:  # Show first 10\n        group_name = grouping.get('Group_Name', 'N/A')\n        items = grouping.get('items', [])\n        items_count = len(items)\n        \n        # Identify which items are groups vs analyses\n        group_refs = [item for item in items if item in group_names_set]\n        analysis_refs = [item for item in items if item not in group_names_set]\n        \n        # Show preview with group references marked\n        items_preview = ', '.join(f\"[{item}]\" if item in group_names_set else item for item in items[:3])\n        if len(items) > 3:\n            items_preview += f', ... (+{len(items) - 3} more)'\n        \n        grouping_rows.append([\n            group_name,\n            len(group_refs),\n            len(analysis_refs),\n            items_preview\n        ])\n    \n    ux.table(grouping_rows, headers=[\"Group Name\", \"# Group Refs\", \"# Analysis Refs\", \"Items (Preview, [groups] marked)\"])\n    \n    if len(rollup_groups) > 10:\n        ux.info(f\"... and {len(rollup_groups) - 10} more rollup job(s)\")\n    \n    ux.info(\"\")\n    ux.info(\"Each rollup group will become one job with configuration containing:\")\n    ux.info(\"  - Metadata from configuration file\")\n    ux.info(\"  - Group_Name: Name of the rollup group\")\n    ux.info(\"  - items: List of group names AND/OR analysis names to include\")\n    \n    step.log(f\"Previewed Grouping Rollup batch: {len(rollup_groups)} rollup groups\")\nelse:\n    ux.info(\"Grouping Rollup batch not needed (no groups of groups in configuration)\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "5u8midc8gr2",
   "source": "## 4k) Preview: Export to RDM Batch",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "f46ga80o9uw",
   "source": "# Preview Export to RDM job\nux.header(\"Export to RDM Batch Preview\")\n\nif BatchType.EXPORT_TO_RDM in batch_types_to_create:\n    rdm_name = metadata.get('Export RDM Name')\n    analysis_names = [a.get('Analysis Name') for a in analyses if a.get('Analysis Name')]\n    group_names = [g.get('Group_Name') for g in groupings if g.get('Group_Name')]\n    \n    ux.info(f\"This batch will create 1 job to export all analyses and groups to RDM.\")\n    ux.info(f\"Target RDM: {rdm_name}\")\n    ux.info(f\"Server: databridge-1\")\n    ux.info(\"\")\n    \n    # Display summary\n    summary_rows = [\n        [\"Analyses to export\", len(analysis_names)],\n        [\"Groups to export\", len(group_names)],\n        [\"Total items\", len(analysis_names) + len(group_names)]\n    ]\n    ux.table(summary_rows, headers=[\"Item Type\", \"Count\"])\n    \n    # Show preview of items to export\n    ux.info(\"\")\n    ux.info(\"Analyses to export (first 10):\")\n    for name in analysis_names[:10]:\n        ux.info(f\"  - {name}\")\n    if len(analysis_names) > 10:\n        ux.info(f\"  ... and {len(analysis_names) - 10} more\")\n    \n    ux.info(\"\")\n    ux.info(\"Groups to export (first 10):\")\n    for name in group_names[:10]:\n        ux.info(f\"  - {name}\")\n    if len(group_names) > 10:\n        ux.info(f\"  ... and {len(group_names) - 10} more\")\n    \n    ux.info(\"\")\n    ux.info(\"Job configuration will contain:\")\n    ux.info(\"  - Metadata from configuration file\")\n    ux.info(\"  - rdm_name: Target RDM database name\")\n    ux.info(\"  - server_name: databridge-1\")\n    ux.info(\"  - analysis_names: Combined list of all analysis and group names\")\n    ux.warning(\"⚠ IMPORTANT: Export to RDM can only run AFTER all Grouping batches complete.\")\n    \n    step.log(f\"Previewed Export to RDM batch: {len(analysis_names)} analyses + {len(group_names)} groups to '{rdm_name}'\")\nelse:\n    ux.info(\"Export to RDM batch not needed (Export RDM Name not specified or no analyses/groups)\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "create_batches_header",
   "metadata": {},
   "source": [
    "## 5) Create Batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create_batches",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create batches for identified batch types\n",
    "ux.header(\"Batch Creation\")\n",
    "\n",
    "# Confirm with user\n",
    "batch_summary = \", \".join(batch_types_to_create)\n",
    "ux.info(f\"Ready to create batches: {batch_summary}\")\n",
    "proceed = ux.yes_no(\"Create these batches?\")\n",
    "\n",
    "if not proceed:\n",
    "    ux.info(\"Batch creation cancelled by user\")\n",
    "    step.log(\"User cancelled batch creation\")\n",
    "    raise SystemExit(\"User cancelled batch creation\")\n",
    "\n",
    "# Create batches\n",
    "created_batches = {}\n",
    "\n",
    "try:\n",
    "    for batch_type in batch_types_to_create:\n",
    "        ux.subheader(f\"Creating batch: {batch_type}\")\n",
    "        \n",
    "        # Create batch (this will create jobs atomically)\n",
    "        batch_id = create_batch(\n",
    "            batch_type=batch_type,\n",
    "            configuration_id=config_id,\n",
    "            step_id=step.step_id\n",
    "        )\n",
    "        \n",
    "        # Store batch ID (convert to int to avoid numpy types)\n",
    "        created_batches[batch_type] = int(batch_id)\n",
    "        \n",
    "        # Get job count for this batch\n",
    "        job_count_result = execute_query(\n",
    "            \"SELECT COUNT(*) as count FROM irp_job WHERE batch_id = %s\",\n",
    "            (batch_id,)\n",
    "        )\n",
    "        job_count = int(job_count_result.iloc[0]['count'])\n",
    "        \n",
    "        ux.success(f\"✓ Batch created: ID={batch_id}\")\n",
    "        ux.info(f\"  Jobs created: {job_count}\")\n",
    "        \n",
    "        step.log(f\"Created batch '{batch_type}': ID={batch_id}, Jobs={job_count}\")\n",
    "    \n",
    "    ux.success(f\"\\n✓ All batches created successfully ({len(created_batches)} total)\")\n",
    "    \n",
    "except Exception as e:\n",
    "    ux.error(f\"✗ Batch creation failed: {str(e)}\")\n",
    "    step.fail(f\"Batch creation failed: {str(e)}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "batch_summary_header",
   "metadata": {},
   "source": [
    "## 6) Display Batch Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "batch_summary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display summary of all created batches\n",
    "ux.header(\"Batch Summary\")\n",
    "\n",
    "try:\n",
    "    # Get batch details\n",
    "    batch_ids = list(created_batches.values())\n",
    "    \n",
    "    if batch_ids:\n",
    "        # Build query to get all batches\n",
    "        placeholders = ', '.join(['%s'] * len(batch_ids))\n",
    "        batch_query = f\"\"\"\n",
    "            SELECT \n",
    "                b.id,\n",
    "                b.batch_type,\n",
    "                b.status,\n",
    "                b.created_ts,\n",
    "                COUNT(j.id) as job_count\n",
    "            FROM irp_batch b\n",
    "            LEFT JOIN irp_job j ON b.id = j.batch_id\n",
    "            WHERE b.id IN ({placeholders})\n",
    "            GROUP BY b.id, b.batch_type, b.status, b.created_ts\n",
    "            ORDER BY b.created_ts\n",
    "        \"\"\"\n",
    "        \n",
    "        batch_results = execute_query(batch_query, tuple(batch_ids))\n",
    "        \n",
    "        # Display batch information\n",
    "        batch_rows = []\n",
    "        total_jobs = 0\n",
    "        \n",
    "        for _, batch in batch_results.iterrows():\n",
    "            batch_rows.append([\n",
    "                batch['batch_type'],\n",
    "                batch['id'],\n",
    "                batch['status'],\n",
    "                int(batch['job_count']),\n",
    "                batch['created_ts'].strftime('%Y-%m-%d %H:%M:%S')\n",
    "            ])\n",
    "            total_jobs += int(batch['job_count'])\n",
    "        \n",
    "        ux.table(batch_rows, headers=[\"Batch Type\", \"Batch ID\", \"Status\", \"Jobs\", \"Created\"])\n",
    "        \n",
    "        ux.info(f\"\\nTotal batches: {len(batch_ids)}\")\n",
    "        ux.info(f\"Total jobs: {total_jobs}\")\n",
    "        \n",
    "        step.log(f\"Batch summary: {len(batch_ids)} batches, {total_jobs} total jobs\")\n",
    "    \n",
    "except Exception as e:\n",
    "    ux.error(f\"✗ Failed to display batch summary: {str(e)}\")\n",
    "    # Don't fail step, this is just display\n",
    "    step.log(f\"Warning: Failed to display batch summary: {str(e)}\", level=\"WARNING\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "preview_jobs_header",
   "metadata": {},
   "source": [
    "## 7) Preview Job Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "preview_jobs",
   "metadata": {},
   "outputs": [],
   "source": "# Preview job configurations for created batches\nux.header(\"Job Configuration Preview\")\n\ntry:\n    # Preview EDM Creation jobs\n    if 'EDM Creation' in created_batches:\n        edm_batch_id = created_batches['EDM Creation']\n        \n        ux.subheader(\"EDM Creation Jobs (first 5)\")\n        \n        # Get job configurations\n        job_config_query = \"\"\"\n            SELECT \n                jc.id,\n                jc.job_configuration_data,\n                j.id as job_id,\n                j.status\n            FROM irp_job_configuration jc\n            INNER JOIN irp_job j ON jc.id = j.job_configuration_id\n            WHERE jc.batch_id = %s\n            LIMIT 5\n        \"\"\"\n        \n        job_configs = execute_query(job_config_query, (edm_batch_id,))\n        \n        if not job_configs.empty:\n            # Display job configuration details\n            job_rows = []\n            for _, job_config in job_configs.iterrows():\n                config_data = job_config['job_configuration_data']\n                job_rows.append([\n                    job_config['job_id'],\n                    config_data.get('Database', 'N/A'),\n                    job_config['status']\n                ])\n            \n            ux.table(job_rows, headers=[\"Job ID\", \"Database\", \"Status\"])\n            \n            ux.info(\"\\nEach job configuration contains:\")\n            ux.info(\"  - Full metadata from configuration file\")\n            ux.info(\"  - Database-specific fields from Databases sheet\")\n            ux.info(\"  - Additional fields: Description, Connection details, etc.\")\n        else:\n            ux.warning(\"No job configurations found\")\n    \n    # Preview EDM DB Upgrade jobs\n    if 'EDM DB Upgrade' in created_batches:\n        upgrade_batch_id = created_batches['EDM DB Upgrade']\n        \n        ux.subheader(\"EDM DB Upgrade Jobs (first 5)\")\n        \n        # Get job configurations\n        job_config_query = \"\"\"\n            SELECT \n                jc.id,\n                jc.job_configuration_data,\n                j.id as job_id,\n                j.status\n            FROM irp_job_configuration jc\n            INNER JOIN irp_job j ON jc.id = j.job_configuration_id\n            WHERE jc.batch_id = %s\n            LIMIT 5\n        \"\"\"\n        \n        job_configs = execute_query(job_config_query, (upgrade_batch_id,))\n        \n        if not job_configs.empty:\n            # Display job configuration details\n            job_rows = []\n            for _, job_config in job_configs.iterrows():\n                config_data = job_config['job_configuration_data']\n                job_rows.append([\n                    job_config['job_id'],\n                    config_data.get('Database', 'N/A'),\n                    config_data.get('target_edm_version', 'N/A'),\n                    job_config['status']\n                ])\n            \n            ux.table(job_rows, headers=[\"Job ID\", \"Database\", \"Target Version\", \"Status\"])\n            \n            ux.info(\"\\nEach job configuration contains:\")\n            ux.info(\"  - Full metadata from configuration file\")\n            ux.info(\"  - Database-specific fields from Databases sheet\")\n            ux.info(\"  - target_edm_version: The version to upgrade to\")\n        else:\n            ux.warning(\"No job configurations found\")\n    \n    # Preview Portfolio Creation jobs\n    if 'Portfolio Creation' in created_batches:\n        portfolio_batch_id = created_batches['Portfolio Creation']\n        \n        ux.subheader(\"Portfolio Creation Jobs (first 5)\")\n        \n        # Get job configurations\n        job_config_query = \"\"\"\n            SELECT \n                jc.id,\n                jc.job_configuration_data,\n                j.id as job_id,\n                j.status\n            FROM irp_job_configuration jc\n            INNER JOIN irp_job j ON jc.id = j.job_configuration_id\n            WHERE jc.batch_id = %s\n            LIMIT 5\n        \"\"\"\n        \n        job_configs = execute_query(job_config_query, (portfolio_batch_id,))\n        \n        if not job_configs.empty:\n            # Display job configuration details\n            job_rows = []\n            for _, job_config in job_configs.iterrows():\n                config_data = job_config['job_configuration_data']\n                job_rows.append([\n                    job_config['job_id'],\n                    config_data.get('Portfolio', 'N/A'),\n                    config_data.get('Database', 'N/A'),\n                    job_config['status']\n                ])\n            \n            ux.table(job_rows, headers=[\"Job ID\", \"Portfolio\", \"EDM\", \"Status\"])\n            \n            ux.info(\"\\nEach job configuration contains:\")\n            ux.info(\"  - Full metadata from configuration file\")\n            ux.info(\"  - Portfolio-specific fields from Portfolios sheet\")\n            ux.info(\"  - Additional fields: Portfolio Name, Database, Base Portfolio flag, etc.\")\n        else:\n            ux.warning(\"No job configurations found\")\n    \n    # Preview MRI Import jobs\n    if 'MRI Import' in created_batches:\n        mri_batch_id = created_batches['MRI Import']\n        \n        ux.subheader(\"MRI Import Jobs (first 5)\")\n        \n        # Get job configurations\n        job_config_query = \"\"\"\n            SELECT \n                jc.id,\n                jc.job_configuration_data,\n                j.id as job_id,\n                j.status\n            FROM irp_job_configuration jc\n            INNER JOIN irp_job j ON jc.id = j.job_configuration_id\n            WHERE jc.batch_id = %s\n            LIMIT 5\n        \"\"\"\n        \n        job_configs = execute_query(job_config_query, (mri_batch_id,))\n        \n        if not job_configs.empty:\n            # Display job configuration details\n            job_rows = []\n            for _, job_config in job_configs.iterrows():\n                config_data = job_config['job_configuration_data']\n                job_rows.append([\n                    job_config['job_id'],\n                    config_data.get('Portfolio', 'N/A'),\n                    config_data.get('Database', 'N/A'),\n                    config_data.get('accounts_import_file', 'N/A'),\n                    config_data.get('locations_import_file', 'N/A'),\n                    job_config['status']\n                ])\n            \n            ux.table(job_rows, headers=[\"Job ID\", \"Portfolio\", \"EDM\", \"Accounts File\", \"Locations File\", \"Status\"])\n            \n            ux.info(\"\\nEach job configuration contains:\")\n            ux.info(\"  - Full metadata from configuration file\")\n            ux.info(\"  - Portfolio-specific fields from Portfolios sheet\")\n            ux.info(\"  - CSV import filenames: accounts_import_file, locations_import_file\")\n            ux.info(\"  - Additional fields: Portfolio Name, Database, Import File, etc.\")\n        else:\n            ux.warning(\"No job configurations found\")\n    \n    # Preview GeoHaz jobs\n    if 'GeoHaz' in created_batches:\n        geohaz_batch_id = created_batches['GeoHaz']\n        \n        ux.subheader(\"GeoHaz Jobs (first 5)\")\n        \n        # Get job configurations\n        job_config_query = \"\"\"\n            SELECT \n                jc.id,\n                jc.job_configuration_data,\n                j.id as job_id,\n                j.status\n            FROM irp_job_configuration jc\n            INNER JOIN irp_job j ON jc.id = j.job_configuration_id\n            WHERE jc.batch_id = %s\n            LIMIT 5\n        \"\"\"\n        \n        job_configs = execute_query(job_config_query, (geohaz_batch_id,))\n        \n        if not job_configs.empty:\n            # Display job configuration details\n            job_rows = []\n            for _, job_config in job_configs.iterrows():\n                config_data = job_config['job_configuration_data']\n                job_rows.append([\n                    job_config['job_id'],\n                    config_data.get('Portfolio', 'N/A'),\n                    config_data.get('Database', 'N/A'),\n                    config_data.get('geocode_version', 'N/A'),\n                    job_config['status']\n                ])\n            \n            ux.table(job_rows, headers=[\"Job ID\", \"Portfolio\", \"EDM\", \"Geocode Version\", \"Status\"])\n            \n            ux.info(\"\\nEach job configuration contains:\")\n            ux.info(\"  - Full metadata from configuration file\")\n            ux.info(\"  - Portfolio-specific fields from Portfolios sheet\")\n            ux.info(\"  - geocode_version: The geocode version to use\")\n        else:\n            ux.warning(\"No job configurations found\")\n    \n    # Preview Create Reinsurance Treaties jobs\n    if 'Create Reinsurance Treaties' in created_batches:\n        treaty_batch_id = created_batches['Create Reinsurance Treaties']\n        \n        ux.subheader(\"Create Reinsurance Treaties Jobs (first 5)\")\n        \n        # Get job configurations\n        job_config_query = \"\"\"\n            SELECT \n                jc.id,\n                jc.job_configuration_data,\n                j.id as job_id,\n                j.status\n            FROM irp_job_configuration jc\n            INNER JOIN irp_job j ON jc.id = j.job_configuration_id\n            WHERE jc.batch_id = %s\n            LIMIT 5\n        \"\"\"\n        \n        job_configs = execute_query(job_config_query, (treaty_batch_id,))\n        \n        if not job_configs.empty:\n            # Display job configuration details\n            job_rows = []\n            for _, job_config in job_configs.iterrows():\n                config_data = job_config['job_configuration_data']\n                job_rows.append([\n                    job_config['job_id'],\n                    config_data.get('Treaty Name', 'N/A'),\n                    config_data.get('Database', 'N/A'),\n                    job_config['status']\n                ])\n            \n            ux.table(job_rows, headers=[\"Job ID\", \"Treaty Name\", \"EDM\", \"Status\"])\n            \n            ux.info(\"\\nEach job configuration contains:\")\n            ux.info(\"  - Full metadata from configuration file\")\n            ux.info(\"  - Database (EDM) where the treaty will be created\")\n            ux.info(\"  - Treaty-specific fields from Reinsurance Treaties sheet\")\n        else:\n            ux.warning(\"No job configurations found\")\n    \n    # Preview Analysis jobs\n    if 'Analysis' in created_batches:\n        analysis_batch_id = created_batches['Analysis']\n        \n        ux.subheader(\"Analysis Jobs (first 5)\")\n        \n        # Get job configurations\n        job_config_query = \"\"\"\n            SELECT \n                jc.id,\n                jc.job_configuration_data,\n                j.id as job_id,\n                j.status\n            FROM irp_job_configuration jc\n            INNER JOIN irp_job j ON jc.id = j.job_configuration_id\n            WHERE jc.batch_id = %s\n            LIMIT 5\n        \"\"\"\n        \n        job_configs = execute_query(job_config_query, (analysis_batch_id,))\n        \n        if not job_configs.empty:\n            # Display job configuration details\n            job_rows = []\n            for _, job_config in job_configs.iterrows():\n                config_data = job_config['job_configuration_data']\n                job_rows.append([\n                    job_config['job_id'],\n                    config_data.get('Analysis Name', 'N/A'),\n                    config_data.get('Portfolio', 'N/A'),\n                    config_data.get('Database', 'N/A'),\n                    config_data.get('Analysis Profile', 'N/A')[:25] + '...' if len(config_data.get('Analysis Profile', '')) > 25 else config_data.get('Analysis Profile', 'N/A'),\n                    job_config['status']\n                ])\n            \n            ux.table(job_rows, headers=[\"Job ID\", \"Analysis Name\", \"Portfolio\", \"EDM\", \"Analysis Profile\", \"Status\"])\n            \n            ux.info(\"\\nEach job configuration contains:\")\n            ux.info(\"  - Full metadata from configuration file\")\n            ux.info(\"  - Analysis-specific fields from Analysis Table sheet\")\n            ux.info(\"  - Analysis Profile, Output Profile, Event Rate, Treaties, Tags\")\n        else:\n            ux.warning(\"No job configurations found\")\n\n    # Preview Grouping jobs (analysis-only)\n    if 'Grouping' in created_batches:\n        grouping_batch_id = created_batches['Grouping']\n        \n        ux.subheader(\"Grouping Jobs - Analysis-only (first 5)\")\n        \n        # Get job configurations\n        job_config_query = \"\"\"\n            SELECT \n                jc.id,\n                jc.job_configuration_data,\n                j.id as job_id,\n                j.status\n            FROM irp_job_configuration jc\n            INNER JOIN irp_job j ON jc.id = j.job_configuration_id\n            WHERE jc.batch_id = %s\n            LIMIT 5\n        \"\"\"\n        \n        job_configs = execute_query(job_config_query, (grouping_batch_id,))\n        \n        if not job_configs.empty:\n            # Display job configuration details\n            job_rows = []\n            for _, job_config in job_configs.iterrows():\n                config_data = job_config['job_configuration_data']\n                items = config_data.get('items', [])\n                items_count = len(items)\n                # Show first few items as preview\n                items_preview = ', '.join(items[:2])\n                if len(items) > 2:\n                    items_preview += f', ... (+{len(items) - 2} more)'\n                \n                job_rows.append([\n                    job_config['job_id'],\n                    config_data.get('Group_Name', 'N/A'),\n                    items_count,\n                    items_preview,\n                    job_config['status']\n                ])\n            \n            ux.table(job_rows, headers=[\"Job ID\", \"Group Name\", \"# Analyses\", \"Analyses (Preview)\", \"Status\"])\n            \n            ux.info(\"\\nEach job configuration contains:\")\n            ux.info(\"  - Full metadata from configuration file\")\n            ux.info(\"  - Group_Name: Name of the group\")\n            ux.info(\"  - items: List of analysis names to group together\")\n        else:\n            ux.warning(\"No job configurations found\")\n\n    # Preview Grouping Rollup jobs (groups of groups)\n    if 'Grouping Rollup' in created_batches:\n        rollup_batch_id = created_batches['Grouping Rollup']\n        \n        ux.subheader(\"Grouping Rollup Jobs - Groups of Groups (first 5)\")\n        \n        # Get job configurations\n        job_config_query = \"\"\"\n            SELECT \n                jc.id,\n                jc.job_configuration_data,\n                j.id as job_id,\n                j.status\n            FROM irp_job_configuration jc\n            INNER JOIN irp_job j ON jc.id = j.job_configuration_id\n            WHERE jc.batch_id = %s\n            LIMIT 5\n        \"\"\"\n        \n        job_configs = execute_query(job_config_query, (rollup_batch_id,))\n        \n        if not job_configs.empty:\n            # Display job configuration details\n            job_rows = []\n            for _, job_config in job_configs.iterrows():\n                config_data = job_config['job_configuration_data']\n                items = config_data.get('items', [])\n                items_count = len(items)\n                # Show first few items as preview\n                items_preview = ', '.join(items[:2])\n                if len(items) > 2:\n                    items_preview += f', ... (+{len(items) - 2} more)'\n                \n                job_rows.append([\n                    job_config['job_id'],\n                    config_data.get('Group_Name', 'N/A'),\n                    items_count,\n                    items_preview,\n                    job_config['status']\n                ])\n            \n            ux.table(job_rows, headers=[\"Job ID\", \"Group Name\", \"# Items\", \"Items (Preview)\", \"Status\"])\n            \n            ux.info(\"\\nEach job configuration contains:\")\n            ux.info(\"  - Full metadata from configuration file\")\n            ux.info(\"  - Group_Name: Name of the rollup group\")\n            ux.info(\"  - items: List of group names AND/OR analysis names\")\n            ux.warning(\"⚠ These jobs require Grouping batch to complete first\")\n        else:\n            ux.warning(\"No job configurations found\")\n\n    # Preview Export to RDM jobs\n    if 'Export to RDM' in created_batches:\n        export_batch_id = created_batches['Export to RDM']\n        \n        ux.subheader(\"Export to RDM Jobs\")\n        \n        # Get job configurations\n        job_config_query = \"\"\"\n            SELECT \n                jc.id,\n                jc.job_configuration_data,\n                j.id as job_id,\n                j.status\n            FROM irp_job_configuration jc\n            INNER JOIN irp_job j ON jc.id = j.job_configuration_id\n            WHERE jc.batch_id = %s\n            LIMIT 5\n        \"\"\"\n        \n        job_configs = execute_query(job_config_query, (export_batch_id,))\n        \n        if not job_configs.empty:\n            # Display job configuration details\n            job_rows = []\n            for _, job_config in job_configs.iterrows():\n                config_data = job_config['job_configuration_data']\n                analysis_names_list = config_data.get('analysis_names', [])\n                analysis_count = config_data.get('analysis_count', 0)\n                group_count = config_data.get('group_count', 0)\n                \n                job_rows.append([\n                    job_config['job_id'],\n                    config_data.get('rdm_name', 'N/A'),\n                    config_data.get('server_name', 'N/A'),\n                    analysis_count,\n                    group_count,\n                    len(analysis_names_list),\n                    job_config['status']\n                ])\n            \n            ux.table(job_rows, headers=[\"Job ID\", \"RDM Name\", \"Server\", \"# Analyses\", \"# Groups\", \"Total Items\", \"Status\"])\n            \n            ux.info(\"\\nJob configuration contains:\")\n            ux.info(\"  - Full metadata from configuration file\")\n            ux.info(\"  - rdm_name: Target RDM database name\")\n            ux.info(\"  - server_name: Database server (databridge-1)\")\n            ux.info(\"  - analysis_names: Combined list of all analysis and group names to export\")\n            ux.warning(\"⚠ This job requires all Grouping batches to complete first\")\n        else:\n            ux.warning(\"No job configurations found\")\n    \n    step.log(\"Job configuration preview displayed\")\n    \nexcept Exception as e:\n    ux.error(f\"✗ Failed to preview job configurations: {str(e)}\")\n    # Don't fail step, this is just display\n    step.log(f\"Warning: Failed to preview jobs: {str(e)}\", level=\"WARNING\")"
  },
  {
   "cell_type": "markdown",
   "id": "complete_step_header",
   "metadata": {},
   "source": [
    "## 8) Complete Step Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complete_step",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete step execution\n",
    "ux.header(\"Step Completion\")\n",
    "\n",
    "try:\n",
    "    # Prepare output data\n",
    "    output_data = {\n",
    "        'configuration_id': config_id,\n",
    "        'batches': created_batches,  # {batch_type: batch_id}\n",
    "        'batch_types_created': batch_types_to_create,\n",
    "        'total_job_count': total_jobs\n",
    "    }\n",
    "    \n",
    "    # Complete the step\n",
    "    step.complete(output_data)\n",
    "\n",
    "    ux.success(\"\\n\" + \"=\"*60)\n",
    "    ux.success(\"✓ BATCHES CREATED SUCCESSFULLY\")\n",
    "    ux.success(\"=\"*60)\n",
    "    ux.info(f\"\\nCreated {len(created_batches)} batch(es) with {total_jobs} total job(s)\")\n",
    "    ux.info(\"Batches are in INITIATED status and ready for submission\")\n",
    "    ux.info(\"\\nNext: Stage 02 will handle batch submission and job monitoring\")\n",
    "\n",
    "except Exception as e:\n",
    "    ux.error(f\"✗ Step completion failed: {str(e)}\")\n",
    "    step.fail(str(e))\n",
    "    raise"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}