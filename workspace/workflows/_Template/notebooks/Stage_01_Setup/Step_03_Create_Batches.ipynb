{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "notebook_header",
   "metadata": {},
   "source": [
    "# Step 03: Create Batches\n",
    "\n",
    "This notebook creates batches and jobs from the loaded configuration.\n",
    "\n",
    "**Tasks:**\n",
    "- Verify configuration is loaded and valid\n",
    "- Identify batch types to create based on configuration data\n",
    "- Preview databases and job configurations\n",
    "- Create batches (EDM Creation, etc.)\n",
    "- Display batch and job summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": "%load_ext autoreload\n%autoreload 2\n\nfrom helpers.notebook_setup import initialize_notebook_context\nfrom helpers import ux\nfrom helpers.configuration import read_configuration, get_base_portfolios, classify_groupings\nfrom helpers.batch import create_batch, get_batches_for_configuration, delete_batch\nfrom helpers.batch_preview import (\n    preview_batch_type, preview_export_to_rdm, display_job_preview,\n    trunc, list_preview\n)\nfrom helpers.database import execute_query\nfrom helpers.constants import BatchType"
  },
  {
   "cell_type": "markdown",
   "id": "context_setup",
   "metadata": {},
   "source": [
    "## 1) Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "context_init",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize notebook context and step tracking\n",
    "context, step = initialize_notebook_context('Step_03_Create_Batches.ipynb')\n",
    "\n",
    "# Display context\n",
    "ux.header(\"Batch Creation\")\n",
    "ux.info(f\"Cycle: {context.cycle_name}\")\n",
    "ux.info(f\"Stage: {context.stage_name}\")\n",
    "ux.info(f\"Step: {context.step_name}\")\n",
    "ux.success(f\"✓ Step tracking initialized for '{context.step_name}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "verify_config_header",
   "metadata": {},
   "source": [
    "## 2) Verify Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verify_config",
   "metadata": {},
   "outputs": [],
   "source": "# Verify configuration exists and is valid\nux.header(\"Configuration Verification\")\n\n# Get cycle ID\ncycle_result = execute_query(\n    \"SELECT id FROM irp_cycle WHERE cycle_name = %s\",\n    (context.cycle_name,)\n)\n\nif cycle_result.empty:\n    raise ValueError(f\"Cycle not found: {context.cycle_name}\")\n\ncycle_id = int(cycle_result.iloc[0]['id'])  # Convert numpy.int64 to Python int\n\n# Get configuration for this cycle\nconfig_result = execute_query(\n    \"SELECT id, status, created_ts FROM irp_configuration WHERE cycle_id = %s ORDER BY created_ts DESC LIMIT 1\",\n    (cycle_id,)\n)\n\nif config_result.empty:\n    ux.error(\"✗ No configuration found for this cycle\")\n    ux.info(\"Please complete Step 02: Validate Configuration File first\")\n    raise ValueError(\"No configuration found for cycle\")\n\nconfig_id = int(config_result.iloc[0]['id'])  # Convert numpy.int64 to Python int\nconfig_status = config_result.iloc[0]['status']\nconfig_created = config_result.iloc[0]['created_ts']\n\n# Verify status is VALID or ACTIVE\nif config_status not in ['VALID', 'ACTIVE']:\n    ux.error(f\"✗ Configuration status is '{config_status}' (expected VALID or ACTIVE)\")\n    raise ValueError(f\"Configuration must be VALID or ACTIVE, found: {config_status}\")\n\n# Display configuration summary\nconfig_info = [\n    [\"Configuration ID\", config_id],\n    [\"Status\", config_status],\n    [\"Created\", config_created.strftime('%Y-%m-%d %H:%M:%S')]\n]\nux.table(config_info, headers=[\"Property\", \"Value\"])\nux.success(\"✓ Configuration verified\")\n\nstep.log(f\"Configuration verified: ID={config_id}, Status={config_status}\")"
  },
  {
   "cell_type": "markdown",
   "id": "identify_batches_header",
   "metadata": {},
   "source": [
    "## 3) Identify Batch Types to Create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "identify_batches",
   "metadata": {},
   "outputs": [],
   "source": "# Analyze configuration to determine which batch types are needed\nux.header(\"Batch Type Identification\")\n\n# Read configuration data\nconfig_data = read_configuration(config_id)\n\n# Extract configuration_data JSONB field\nconfiguration_data = config_data.get('configuration_data', {})\nmetadata = configuration_data.get('Metadata', {})\n\n# Identify batch types based on configuration content\n# Order matches step execution: Stage 02 → Stage 03 → Stage 04 → Stage 05 → Stage 06\nbatch_types_info = []\nbatch_types_to_create = []\n\n# Get common data needed for multiple batch types\ndatabases = configuration_data.get('Databases', [])\nportfolios = configuration_data.get('Portfolios', [])\nbase_portfolios = get_base_portfolios(portfolios) if portfolios else []\ntreaties = configuration_data.get('Reinsurance Treaties', [])\nanalyses = configuration_data.get('Analysis Table', [])\ngroupings = configuration_data.get('Groupings', [])\nedm_version = metadata.get('EDM Data Version')\ngeocode_version = metadata.get('Geocode Version')\nrdm_name = metadata.get('Export RDM Name')\n\n# Initialize for use in preview sections\ntreaty_edm_combinations = set()\nanalysis_only_groups = []\nrollup_groups = []\n\n# === STAGE 02: Data Extraction ===\n\n# Step 01: Data Extraction (Base Portfolios only - extracts data from SQL Server to CSV)\nif base_portfolios:\n    batch_types_info.append([BatchType.DATA_EXTRACTION, len(base_portfolios), \"One job per base portfolio (SQL extraction to CSV)\"])\n    batch_types_to_create.append(BatchType.DATA_EXTRACTION)\n\n# === STAGE 03: Data Import ===\n\n# Step 01: EDM Creation (Databases sheet)\nif databases:\n    batch_types_info.append([BatchType.EDM_CREATION, len(databases), \"One job per database\"])\n    batch_types_to_create.append(BatchType.EDM_CREATION)\n\n# Step 02: Portfolio Creation (Base Portfolios only)\nif base_portfolios:\n    batch_types_info.append([BatchType.PORTFOLIO_CREATION, len(base_portfolios), \"One job per portfolio\"])\n    batch_types_to_create.append(BatchType.PORTFOLIO_CREATION)\n\n# Step 03: MRI Import (Base Portfolios only)\nif base_portfolios:\n    batch_types_info.append([BatchType.MRI_IMPORT, len(base_portfolios), \"One job per portfolio\"])\n    batch_types_to_create.append(BatchType.MRI_IMPORT)\n\n# Step 04: Create Reinsurance Treaties (requires Analysis Table)\nif analyses:  # Only need analyses sheet - treaties sheet can be empty\n    # Build a set of valid treaty names (may be empty if no treaties defined)\n    valid_treaty_names = {t.get('Treaty Name') for t in treaties if t.get('Treaty Name')} if treaties else set()\n\n    # Collect unique treaty-EDM combinations from Analysis Table\n    treaty_columns = ['Reinsurance Treaty 1', 'Reinsurance Treaty 2', 'Reinsurance Treaty 3',\n                      'Reinsurance Treaty 4', 'Reinsurance Treaty 5']\n\n    for analysis in analyses:\n        edm = analysis.get('Database')\n        if not edm:\n            continue\n        for col in treaty_columns:\n            treaty_name = analysis.get(col)\n            if treaty_name and treaty_name in valid_treaty_names:\n                treaty_edm_combinations.add((treaty_name, edm))\n\n    # Always create batch for chaining - even if 0 jobs (empty batch completes immediately)\n    job_count = len(treaty_edm_combinations)\n    description = f\"One job per treaty-EDM combination\" if job_count > 0 else \"No treaties to create (empty batch for workflow continuity)\"\n    batch_types_info.append([BatchType.CREATE_REINSURANCE_TREATIES, job_count, description])\n    batch_types_to_create.append(BatchType.CREATE_REINSURANCE_TREATIES)\n\n# Step 05: EDM DB Upgrade (Databases sheet + EDM Data Version in Metadata)\nif databases and edm_version:\n    target_version = edm_version.split('.')[0] if '.' in edm_version else edm_version\n    batch_types_info.append([BatchType.EDM_DB_UPGRADE, len(databases), f\"One job per database (upgrade to v{target_version})\"])\n    batch_types_to_create.append(BatchType.EDM_DB_UPGRADE)\n\n# Step 06: GeoHaz (Base Portfolios + Geocode Version in Metadata)\nif base_portfolios and geocode_version:\n    batch_types_info.append([BatchType.GEOHAZ, len(base_portfolios), f\"One job per base portfolio (geocode v{geocode_version})\"])\n    batch_types_to_create.append(BatchType.GEOHAZ)\n\n# Step 07: Portfolio Mapping (Base Portfolios only)\nif base_portfolios:\n    batch_types_info.append([BatchType.PORTFOLIO_MAPPING, len(base_portfolios), \"One job per base portfolio (SQL mapping)\"])\n    batch_types_to_create.append(BatchType.PORTFOLIO_MAPPING)\n\n# === STAGE 04: Analysis Execution ===\n\n# Step 01: Analysis (Analysis Table sheet)\nif analyses:\n    batch_types_info.append([BatchType.ANALYSIS, len(analyses), \"One job per analysis\"])\n    batch_types_to_create.append(BatchType.ANALYSIS)\n\n# === STAGE 05: Grouping ===\n\n# Classify groupings for Grouping and Grouping Rollup batches\nif groupings:\n    analysis_only_groups, rollup_groups = classify_groupings(configuration_data)\n\n# Step 01: Grouping (analysis-only groups)\nif analysis_only_groups:\n    batch_types_info.append([BatchType.GROUPING, len(analysis_only_groups), \"One job per analysis-only group\"])\n    batch_types_to_create.append(BatchType.GROUPING)\n\n# Step 02: Grouping Rollup (groups containing other groups)\nif rollup_groups:\n    batch_types_info.append([BatchType.GROUPING_ROLLUP, len(rollup_groups), \"One job per rollup group (groups of groups)\"])\n    batch_types_to_create.append(BatchType.GROUPING_ROLLUP)\n\n# === STAGE 06: Data Export ===\n\n# Step 01: Export to RDM (requires Export RDM Name and Analysis Table; Groupings optional)\nif rdm_name and analyses:\n    # One job per analysis/group\n    analysis_count = len(analyses)\n    group_count = len(groupings) if groupings else 0\n    total_jobs = analysis_count + group_count\n    batch_types_info.append([BatchType.EXPORT_TO_RDM, total_jobs, f\"One job per item ({analysis_count} analyses + {group_count} groups) to '{rdm_name}'\"])\n    batch_types_to_create.append(BatchType.EXPORT_TO_RDM)\n\n# Display identified batch types\nif batch_types_info:\n    ux.info(\"Batch types identified from configuration:\")\n    ux.table(batch_types_info, headers=[\"Batch Type\", \"Job Count\", \"Description\"])\n    ux.success(f\"✓ Found {len(batch_types_to_create)} batch type(s) to create\")\n    \n    step.log(f\"Identified {len(batch_types_to_create)} batch type(s): {', '.join(batch_types_to_create)}\")\nelse:\n    ux.warning(\"⚠ No batch types identified from configuration\")\n    ux.info(\"Configuration may not contain required data sheets (Databases, Portfolios, etc.)\")\n    raise ValueError(\"No batch types identified in configuration\")"
  },
  {
   "cell_type": "markdown",
   "id": "preview_edm_header",
   "metadata": {},
   "source": "## 4) Preview Batch Types"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "preview_edm",
   "metadata": {},
   "outputs": [],
   "source": "# Preview all batch types that will be created\n# Each batch type shows what jobs will be generated from configuration data\n\n# === Stage 02: Data Extraction ===\n\n# Data Extraction\ndate_value = metadata.get('Current Date Value', '')\ncycle_type = metadata.get('Cycle Type', '')\n\npreview_batch_type(\n    BatchType.DATA_EXTRACTION, batch_types_to_create, base_portfolios,\n    headers=['Portfolio', 'Import File', 'Account CSV', 'Location CSV'],\n    fields=[\n        'Portfolio',\n        'Import File',\n        lambda x: f\"Modeling_{date_value}_Moodys_{x.get('Import File', 'XXX')}_Account.csv\",\n        lambda x: f\"Modeling_{date_value}_Moodys_{x.get('Import File', 'XXX')}_Location.csv\"\n    ],\n    notes=[\n        'Metadata from configuration file',\n        'Portfolio-specific fields from Portfolios sheet',\n        f'SQL script: import_files/{{{cycle_type.lower() if cycle_type else \"cycle_type\"}}}/2_Create_{{Import File}}_Moodys_ImportFile.sql',\n        'CSV output to: files/data/'\n    ],\n    not_needed_msg='Data Extraction batch not needed (no base portfolios in configuration)',\n    ux_module=ux, step=step,\n    footer='Note: Data Extraction executes SQL scripts locally and exports CSVs to files/data/'\n)\n\n# === Stage 03: Data Import ===\n\n# EDM Creation\npreview_batch_type(\n    BatchType.EDM_CREATION, batch_types_to_create, databases,\n    headers=['EDM Name'],\n    fields=['Database'],\n    notes=['Metadata from configuration file', 'Database-specific fields (Database, Version, EDM_Type, etc.)'],\n    not_needed_msg='EDM Creation batch not needed (no databases in configuration)',\n    ux_module=ux, step=step\n)\n\n# Portfolio Creation  \npreview_batch_type(\n    BatchType.PORTFOLIO_CREATION, batch_types_to_create, base_portfolios,\n    headers=['Portfolio', 'EDM'],\n    fields=['Portfolio', 'Database'],\n    notes=['Metadata from configuration file', 'Portfolio-specific fields (Portfolio Name, EDM, etc.)'],\n    not_needed_msg='Portfolio Creation batch not needed (no base portfolios in configuration)',\n    ux_module=ux, step=step\n)\n\n# MRI Import\npreview_batch_type(\n    BatchType.MRI_IMPORT, batch_types_to_create, base_portfolios,\n    headers=['Portfolio', 'EDM', 'Import File'],\n    fields=['Portfolio', 'Database', 'Import File'],\n    notes=['Metadata from configuration file', 'Portfolio-specific fields (Portfolio Name, EDM, Import File, etc.)'],\n    not_needed_msg='MRI Import batch not needed (no base portfolios in configuration)',\n    ux_module=ux, step=step\n)\n\n# Create Reinsurance Treaties\ntreaty_data = [(t, e) for t, e in sorted(treaty_edm_combinations)] if treaty_edm_combinations else []\npreview_batch_type(\n    BatchType.CREATE_REINSURANCE_TREATIES, batch_types_to_create, treaty_data,\n    headers=['Treaty Name', 'EDM'],\n    fields=[lambda x: x[0], lambda x: x[1]],\n    notes=['Metadata from configuration file', 'Database (EDM) where treaty will be created', \n           'Treaty-specific fields from Reinsurance Treaties sheet'],\n    not_needed_msg='Create Reinsurance Treaties batch not needed (no Analysis Table in configuration)',\n    ux_module=ux, step=step\n)\n\n# EDM DB Upgrade\ntarget_version = edm_version.split('.')[0] if edm_version and '.' in edm_version else edm_version\npreview_batch_type(\n    BatchType.EDM_DB_UPGRADE, batch_types_to_create, databases if edm_version else [],\n    headers=['EDM Name', 'Target Version'],\n    fields=[lambda x: x.get('Database', 'N/A'), lambda x: target_version],\n    notes=['Metadata from configuration file', 'Database-specific fields from Databases sheet',\n           'target_edm_version: The version to upgrade to'],\n    not_needed_msg='EDM DB Upgrade batch not needed (no databases or EDM Data Version not specified)',\n    ux_module=ux, step=step,\n    extra_info=f\"Target EDM Data Version: {target_version}\" if target_version else None\n)\n\n# GeoHaz\npreview_batch_type(\n    BatchType.GEOHAZ, batch_types_to_create, base_portfolios if geocode_version else [],\n    headers=['Portfolio', 'EDM', 'Geocode Version'],\n    fields=[lambda x: x.get('Portfolio', 'N/A'), lambda x: x.get('Database', 'N/A'), lambda x: geocode_version],\n    notes=['Metadata from configuration file', 'Portfolio-specific fields from Portfolios sheet',\n           'geocode_version: The geocode version to use'],\n    not_needed_msg='GeoHaz batch not needed (no base portfolios or Geocode Version not specified)',\n    ux_module=ux, step=step,\n    extra_info=f\"Geocode Version: {geocode_version}\" if geocode_version else None\n)\n\n# Portfolio Mapping\npreview_batch_type(\n    BatchType.PORTFOLIO_MAPPING, batch_types_to_create, base_portfolios,\n    headers=['Portfolio', 'EDM', 'Import File'],\n    fields=['Portfolio', 'Database', 'Import File'],\n    notes=['Metadata from configuration file', 'Portfolio-specific fields from Portfolios sheet',\n           'SQL script: 2b_Query_To_Create_Sub_Portfolios_{Import File}_RMS_BackEnd.sql'],\n    not_needed_msg='Portfolio Mapping batch not needed (no base portfolios in configuration)',\n    ux_module=ux, step=step,\n    footer='Note: Portfolio Mapping executes SQL scripts locally (not submitted to Moody\\'s)'\n)\n\n# === Stage 04: Analysis Execution ===\n\n# Analysis\npreview_batch_type(\n    BatchType.ANALYSIS, batch_types_to_create, analyses,\n    headers=['Analysis Name', 'Portfolio', 'EDM', 'Analysis Profile'],\n    fields=[lambda x: x.get('Analysis Name', 'N/A'), lambda x: x.get('Portfolio', 'N/A'),\n            lambda x: x.get('Database', 'N/A'), lambda x: trunc(x.get('Analysis Profile', 'N/A'), 30)],\n    notes=['Metadata from configuration file', \n           'Analysis-specific fields (Name, Portfolio, Database, Profiles, Treaties, Tags)'],\n    not_needed_msg='Analysis batch not needed (no analyses in configuration)',\n    ux_module=ux, step=step, limit=10\n)\n\n# === Stage 05: Grouping ===\n\n# Grouping (Analysis-only)\npreview_batch_type(\n    BatchType.GROUPING, batch_types_to_create, analysis_only_groups,\n    headers=['Group Name', '# Analyses', 'Analyses (Preview)'],\n    fields=[lambda x: x.get('Group_Name', 'N/A'), lambda x: len(x.get('items', [])),\n            lambda x: list_preview(x.get('items', []), 3)],\n    notes=['Metadata from configuration file', 'Group_Name: Name of the group',\n           'items: List of analysis names to group together'],\n    not_needed_msg='Grouping batch not needed (no analysis-only groups in configuration)',\n    ux_module=ux, step=step, limit=10\n)\n\n# Grouping Rollup\ngroup_names_set = {g.get('Group_Name') for g in groupings if g.get('Group_Name')}\npreview_batch_type(\n    BatchType.GROUPING_ROLLUP, batch_types_to_create, rollup_groups,\n    headers=['Group Name', '# Group Refs', '# Analysis Refs', 'Items (Preview)'],\n    fields=[lambda x: x.get('Group_Name', 'N/A'),\n            lambda x: len([i for i in x.get('items', []) if i in group_names_set]),\n            lambda x: len([i for i in x.get('items', []) if i not in group_names_set]),\n            lambda x: list_preview(x.get('items', []), 3)],\n    notes=['Metadata from configuration file', 'Group_Name: Name of the rollup group',\n           'items: List of group names AND/OR analysis names to include'],\n    not_needed_msg='Grouping Rollup batch not needed (no groups of groups in configuration)',\n    ux_module=ux, step=step, limit=10,\n    warning='IMPORTANT: Grouping Rollup jobs can only run AFTER the Grouping batch completes.'\n)\n\n# === Stage 06: Data Export ===\n\n# Export to RDM (uses special function due to unique structure)\npreview_export_to_rdm(\n    BatchType.EXPORT_TO_RDM, batch_types_to_create, rdm_name, analyses, groupings,\n    ux_module=ux, step=step\n)"
  },
  {
   "cell_type": "markdown",
   "id": "6wtz49n96x",
   "source": "## 4.5) Check for Existing Batches",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "wqmwjno063j",
   "source": "# Check if batches already exist for this configuration\nux.header(\"Existing Batch Check\")\n\n# Get all existing batches for this configuration (exclude COMPLETED and CANCELLED)\nexisting_batches = get_batches_for_configuration(\n    configuration_id=config_id,\n    exclude_statuses=['COMPLETED', 'CANCELLED']\n)\n\nif existing_batches:\n    # Display warning\n    ux.warning(f\"⚠ Found {len(existing_batches)} existing batch(es) for this configuration:\")\n    \n    # Show existing batches\n    batch_display = []\n    for batch in existing_batches:\n        batch_display.append([\n            batch['batch_type'],\n            batch['id'],\n            batch['status'],\n            int(batch['job_count']),\n            batch['created_ts'].strftime('%Y-%m-%d %H:%M:%S')\n        ])\n    \n    ux.table(batch_display, headers=[\"Batch Type\", \"Batch ID\", \"Status\", \"Jobs\", \"Created\"])\n    \n    # Give user options\n    print(\"\\nWhat would you like to do?\")\n    print(\"  1) RECREATE - Delete existing batches and create new ones\")\n    print(\"  2) SKIP     - Keep existing batches and skip creation\")\n    \n    user_choice = input(\"\\nEnter choice (1 or 2): \").strip()\n    \n    if user_choice == \"1\":\n        # User wants to recreate - delete existing batches\n        ux.subheader(\"Deleting Existing Batches\")\n        \n        for batch in existing_batches:\n            batch_id = batch['id']\n            batch_type = batch['batch_type']\n            \n            try:\n                delete_batch(batch_id)\n                ux.success(f\"✓ Deleted batch: {batch_type} (ID={batch_id})\")\n                step.log(f\"Deleted existing batch: {batch_type} (ID={batch_id})\")\n            except Exception as e:\n                ux.error(f\"✗ Failed to delete batch {batch_id}: {str(e)}\")\n                raise\n        \n        ux.success(f\"\\n✓ Deleted {len(existing_batches)} existing batch(es)\")\n        ux.info(\"Proceeding with batch creation...\")\n        \n    elif user_choice == \"2\":\n        # User wants to skip creation\n        ux.info(\"Keeping existing batches - skipping batch creation\")\n        step.log(\"User chose to keep existing batches, skipping creation\")\n        \n        # Set created_batches to existing batches for display purposes\n        created_batches = {b['batch_type']: b['id'] for b in existing_batches}\n        \n        # Calculate total jobs from existing batches\n        total_jobs = sum(int(b['job_count']) for b in existing_batches)\n        \n        # Jump to summary section (skip creation)\n        ux.info(\"\\nSkipping to batch summary...\")\n        \n    else:\n        ux.error(f\"✗ Invalid choice: '{user_choice}'\")\n        ux.info(\"Please enter '1' to recreate or '2' to skip\")\n        raise ValueError(f\"Invalid user choice: {user_choice}\")\n        \nelse:\n    ux.success(\"✓ No existing batches found - ready to create new batches\")\n    step.log(\"No existing batches found for this configuration\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "create_batches_header",
   "metadata": {},
   "source": "## 5) Create Batches"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create_batches",
   "metadata": {},
   "outputs": [],
   "source": "# Create batches for identified batch types\n# Skip if user chose to keep existing batches\nif 'created_batches' in locals() and created_batches:\n    ux.header(\"Batch Creation\")\n    ux.info(\"Using existing batches (creation skipped)\")\nelse:\n    ux.header(\"Batch Creation\")\n    \n    # Confirm with user\n    batch_summary = \", \".join(batch_types_to_create)\n    ux.info(f\"Ready to create batches: {batch_summary}\")\n    proceed = ux.yes_no(\"Create these batches?\")\n    \n    if not proceed:\n        ux.info(\"Batch creation cancelled by user\")\n        step.log(\"User cancelled batch creation\")\n        raise SystemExit(\"User cancelled batch creation\")\n    \n    # Create batches\n    created_batches = {}\n    \n    for batch_type in batch_types_to_create:\n        ux.subheader(f\"Creating batch: {batch_type}\")\n        \n        # Create batch (this will create jobs atomically)\n        batch_id = create_batch(\n            batch_type=batch_type,\n            configuration_id=config_id,\n            step_id=step.step_id\n        )\n        \n        # Store batch ID (convert to int to avoid numpy types)\n        created_batches[batch_type] = int(batch_id)\n        \n        # Get job count for this batch\n        job_count_result = execute_query(\n            \"SELECT COUNT(*) as count FROM irp_job WHERE batch_id = %s\",\n            (batch_id,)\n        )\n        job_count = int(job_count_result.iloc[0]['count'])\n        \n        ux.success(f\"✓ Batch created: ID={batch_id}\")\n        ux.info(f\"  Jobs created: {job_count}\")\n        \n        step.log(f\"Created batch '{batch_type}': ID={batch_id}, Jobs={job_count}\")\n    \n    ux.success(f\"\\n✓ All batches created successfully ({len(created_batches)} total)\")"
  },
  {
   "cell_type": "markdown",
   "id": "batch_summary_header",
   "metadata": {},
   "source": "## 6) Display Batch Summary"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "batch_summary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display summary of all created batches\n",
    "ux.header(\"Batch Summary\")\n",
    "\n",
    "try:\n",
    "    # Get batch details\n",
    "    batch_ids = list(created_batches.values())\n",
    "    \n",
    "    if batch_ids:\n",
    "        # Build query to get all batches\n",
    "        placeholders = ', '.join(['%s'] * len(batch_ids))\n",
    "        batch_query = f\"\"\"\n",
    "            SELECT \n",
    "                b.id,\n",
    "                b.batch_type,\n",
    "                b.status,\n",
    "                b.created_ts,\n",
    "                COUNT(j.id) as job_count\n",
    "            FROM irp_batch b\n",
    "            LEFT JOIN irp_job j ON b.id = j.batch_id\n",
    "            WHERE b.id IN ({placeholders})\n",
    "            GROUP BY b.id, b.batch_type, b.status, b.created_ts\n",
    "            ORDER BY b.created_ts\n",
    "        \"\"\"\n",
    "        \n",
    "        batch_results = execute_query(batch_query, tuple(batch_ids))\n",
    "        \n",
    "        # Display batch information\n",
    "        batch_rows = []\n",
    "        total_jobs = 0\n",
    "        \n",
    "        for _, batch in batch_results.iterrows():\n",
    "            batch_rows.append([\n",
    "                batch['batch_type'],\n",
    "                batch['id'],\n",
    "                batch['status'],\n",
    "                int(batch['job_count']),\n",
    "                batch['created_ts'].strftime('%Y-%m-%d %H:%M:%S')\n",
    "            ])\n",
    "            total_jobs += int(batch['job_count'])\n",
    "        \n",
    "        ux.table(batch_rows, headers=[\"Batch Type\", \"Batch ID\", \"Status\", \"Jobs\", \"Created\"])\n",
    "        \n",
    "        ux.info(f\"\\nTotal batches: {len(batch_ids)}\")\n",
    "        ux.info(f\"Total jobs: {total_jobs}\")\n",
    "        \n",
    "        step.log(f\"Batch summary: {len(batch_ids)} batches, {total_jobs} total jobs\")\n",
    "    \n",
    "except Exception as e:\n",
    "    ux.error(f\"✗ Failed to display batch summary: {str(e)}\")\n",
    "    # Don't fail step, this is just display\n",
    "    step.log(f\"Warning: Failed to display batch summary: {str(e)}\", level=\"WARNING\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "preview_jobs_header",
   "metadata": {},
   "source": "## 7) Preview Job Configurations"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "preview_jobs",
   "metadata": {},
   "outputs": [],
   "source": "# Preview job configurations for created batches\n# Order matches step execution: Stage 02 → Stage 03 → Stage 04 → Stage 05 → Stage 06\nux.header(\"Job Configuration Preview\")\n\n# Define the order of batch types to preview (matches execution order)\nBATCH_PREVIEW_ORDER = [\n    # Stage 02: Data Extraction\n    BatchType.DATA_EXTRACTION,\n    # Stage 03: Data Import\n    BatchType.EDM_CREATION,\n    BatchType.PORTFOLIO_CREATION,\n    BatchType.MRI_IMPORT,\n    BatchType.CREATE_REINSURANCE_TREATIES,\n    BatchType.EDM_DB_UPGRADE,\n    BatchType.GEOHAZ,\n    BatchType.PORTFOLIO_MAPPING,\n    # Stage 04: Analysis Execution\n    BatchType.ANALYSIS,\n    # Stage 05: Grouping\n    BatchType.GROUPING,\n    BatchType.GROUPING_ROLLUP,\n    # Stage 06: Data Export\n    BatchType.EXPORT_TO_RDM,\n]\n\ntry:\n    for batch_type in BATCH_PREVIEW_ORDER:\n        if batch_type in created_batches:\n            batch_id = created_batches[batch_type]\n            display_job_preview(batch_id, batch_type, ux, limit=5)\n    \n    step.log(\"Job configuration preview displayed\")\n    \nexcept Exception as e:\n    ux.error(f\"✗ Failed to preview job configurations: {str(e)}\")\n    # Don't fail step, this is just display\n    step.log(f\"Warning: Failed to preview jobs: {str(e)}\", level=\"WARNING\")"
  },
  {
   "cell_type": "markdown",
   "id": "complete_step_header",
   "metadata": {},
   "source": "## 8) Complete Step Execution"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complete_step",
   "metadata": {},
   "outputs": [],
   "source": "# Complete step execution\nux.header(\"Step Completion\")\n\n# Prepare output data\noutput_data = {\n    'configuration_id': config_id,\n    'batches': created_batches,  # {batch_type: batch_id}\n    'batch_types_created': batch_types_to_create,\n    'total_job_count': total_jobs\n}\n\n# Complete the step\nstep.complete(output_data)\n\nux.success(\"\\n\" + \"=\"*60)\nux.success(\"✓ BATCHES CREATED SUCCESSFULLY\")\nux.success(\"=\"*60)\nux.info(f\"\\nCreated {len(created_batches)} batch(es) with {total_jobs} total job(s)\")\nux.info(\"Batches are in INITIATED status and ready for submission\")\nux.info(\"\\nNext: Stage 02 will handle batch submission and job monitoring\")"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}