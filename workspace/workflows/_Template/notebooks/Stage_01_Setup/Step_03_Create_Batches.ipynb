{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "notebook_header",
   "metadata": {},
   "source": [
    "# Step 03: Create Batches\n",
    "\n",
    "This notebook creates batches and jobs from the loaded configuration.\n",
    "\n",
    "**Tasks:**\n",
    "- Verify configuration is loaded and valid\n",
    "- Identify batch types to create based on configuration data\n",
    "- Preview databases and job configurations\n",
    "- Create batches (EDM Creation, etc.)\n",
    "- Display batch and job summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from helpers.notebook_setup import initialize_notebook_context\n",
    "from helpers import ux\n",
    "from helpers.configuration import read_configuration, get_base_portfolios\n",
    "from helpers.batch import create_batch\n",
    "from helpers.database import execute_query\n",
    "from helpers.constants import BatchType"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "context_setup",
   "metadata": {},
   "source": [
    "## 1) Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "context_init",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize notebook context and step tracking\n",
    "context, step = initialize_notebook_context('Step_03_Create_Batches.ipynb', allow_rerun=True)\n",
    "\n",
    "# Display context\n",
    "ux.header(\"Batch Creation\")\n",
    "ux.info(f\"Cycle: {context.cycle_name}\")\n",
    "ux.info(f\"Stage: {context.stage_name}\")\n",
    "ux.info(f\"Step: {context.step_name}\")\n",
    "ux.success(f\"✓ Step tracking initialized for '{context.step_name}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "verify_config_header",
   "metadata": {},
   "source": [
    "## 2) Verify Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verify_config",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify configuration exists and is valid\n",
    "ux.header(\"Configuration Verification\")\n",
    "\n",
    "try:\n",
    "    # Get cycle ID\n",
    "    cycle_result = execute_query(\n",
    "        \"SELECT id FROM irp_cycle WHERE cycle_name = %s\",\n",
    "        (context.cycle_name,)\n",
    "    )\n",
    "    \n",
    "    if cycle_result.empty:\n",
    "        raise ValueError(f\"Cycle not found: {context.cycle_name}\")\n",
    "    \n",
    "    cycle_id = int(cycle_result.iloc[0]['id'])  # Convert numpy.int64 to Python int\n",
    "    \n",
    "    # Get configuration for this cycle\n",
    "    config_result = execute_query(\n",
    "        \"SELECT id, status, created_ts FROM irp_configuration WHERE cycle_id = %s ORDER BY created_ts DESC LIMIT 1\",\n",
    "        (cycle_id,)\n",
    "    )\n",
    "    \n",
    "    if config_result.empty:\n",
    "        ux.error(\"✗ No configuration found for this cycle\")\n",
    "        ux.info(\"Please complete Step 02: Validate Configuration File first\")\n",
    "        step.fail(\"No configuration found for cycle\")\n",
    "        raise ValueError(\"No configuration found for cycle\")\n",
    "    \n",
    "    config_id = int(config_result.iloc[0]['id'])  # Convert numpy.int64 to Python int\n",
    "    config_status = config_result.iloc[0]['status']\n",
    "    config_created = config_result.iloc[0]['created_ts']\n",
    "    \n",
    "    # Verify status is VALID or ACTIVE\n",
    "    if config_status not in ['VALID', 'ACTIVE']:\n",
    "        ux.error(f\"✗ Configuration status is '{config_status}' (expected VALID or ACTIVE)\")\n",
    "        step.fail(f\"Configuration status invalid: {config_status}\")\n",
    "        raise ValueError(f\"Configuration must be VALID or ACTIVE, found: {config_status}\")\n",
    "    \n",
    "    # Display configuration summary\n",
    "    config_info = [\n",
    "        [\"Configuration ID\", config_id],\n",
    "        [\"Status\", config_status],\n",
    "        [\"Created\", config_created.strftime('%Y-%m-%d %H:%M:%S')]\n",
    "    ]\n",
    "    ux.table(config_info, headers=[\"Property\", \"Value\"])\n",
    "    ux.success(\"✓ Configuration verified\")\n",
    "    \n",
    "    step.log(f\"Configuration verified: ID={config_id}, Status={config_status}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    ux.error(f\"✗ Configuration verification failed: {str(e)}\")\n",
    "    step.fail(f\"Configuration verification failed: {str(e)}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "identify_batches_header",
   "metadata": {},
   "source": [
    "## 3) Identify Batch Types to Create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "identify_batches",
   "metadata": {},
   "outputs": [],
   "source": "# Analyze configuration to determine which batch types are needed\nux.header(\"Batch Type Identification\")\n\ntry:\n    # Read configuration data\n    config_data = read_configuration(config_id)\n    \n    # Extract configuration_data JSONB field\n    configuration_data = config_data.get('configuration_data', {})\n    metadata = configuration_data.get('Metadata', {})\n    \n    # Identify batch types based on configuration content\n    batch_types_info = []\n    batch_types_to_create = []\n    \n    # Check for EDM Creation (Databases sheet)\n    databases = configuration_data.get('Databases', [])\n    if databases:\n        batch_types_info.append([BatchType.EDM_CREATION, len(databases), \"One job per database\"])\n        batch_types_to_create.append(BatchType.EDM_CREATION)\n    \n    # Check for EDM DB Upgrade (Databases sheet + EDM Data Version in Metadata)\n    edm_version = metadata.get('EDM Data Version')\n    if databases and edm_version:\n        target_version = edm_version.split('.')[0] if '.' in edm_version else edm_version\n        batch_types_info.append([BatchType.EDM_DB_UPGRADE, len(databases), f\"One job per database (upgrade to v{target_version})\"])\n        batch_types_to_create.append(BatchType.EDM_DB_UPGRADE)\n    \n    # Check for Base Portfolio Creation and MRI Import configuration(Portfolios sheet)\n    portfolios = configuration_data.get('Portfolios', [])\n    if portfolios:\n        # Base Portfolio Creation and MRI Import only applies to Base Portfolios\n        base_portfolios = get_base_portfolios(portfolios)\n        # Add Portfolio Creation\n        batch_types_info.append([BatchType.PORTFOLIO_CREATION, len(base_portfolios), \"One job per portfolio\"])\n        batch_types_to_create.append(BatchType.PORTFOLIO_CREATION)\n        # Add MRI Import\n        batch_types_info.append([BatchType.MRI_IMPORT, len(base_portfolios), \"One job per portfolio\"])\n        batch_types_to_create.append(BatchType.MRI_IMPORT)\n\n    # Check for GeoHaz (Base Portfolios + Geocode Version in Metadata)\n    geocode_version = metadata.get('Geocode Version')\n    if portfolios and geocode_version:\n        if not base_portfolios:\n            base_portfolios = get_base_portfolios(portfolios)\n        if base_portfolios:\n            batch_types_info.append([BatchType.GEOHAZ, len(base_portfolios), f\"One job per base portfolio (geocode v{geocode_version})\"])\n            batch_types_to_create.append(BatchType.GEOHAZ)\n\n    # Check for Portfolio Mapping (Base Portfolios only)\n    if portfolios:\n        if not base_portfolios:\n            base_portfolios = get_base_portfolios(portfolios)\n        if base_portfolios:\n            batch_types_info.append([BatchType.PORTFOLIO_MAPPING, len(base_portfolios), \"One job per base portfolio (SQL mapping)\"])\n            batch_types_to_create.append(BatchType.PORTFOLIO_MAPPING)\n\n    # Check for Reinsurance Treaties (requires both sheets to determine job count)\n    treaties = configuration_data.get('Reinsurance Treaties', [])\n    analyses = configuration_data.get('Analysis Table', [])\n    if treaties and analyses:\n        # Build a set of valid treaty names\n        valid_treaty_names = {t.get('Treaty Name') for t in treaties if t.get('Treaty Name')}\n        \n        # Collect unique treaty-EDM combinations from Analysis Table\n        treaty_edm_combinations = set()\n        treaty_columns = ['Reinsurance Treaty 1', 'Reinsurance Treaty 2', 'Reinsurance Treaty 3',\n                          'Reinsurance Treaty 4', 'Reinsurance Treaty 5']\n        \n        for analysis in analyses:\n            edm = analysis.get('Database')\n            if not edm:\n                continue\n            for col in treaty_columns:\n                treaty_name = analysis.get(col)\n                if treaty_name and treaty_name in valid_treaty_names:\n                    treaty_edm_combinations.add((treaty_name, edm))\n        \n        if treaty_edm_combinations:\n            batch_types_info.append([BatchType.CREATE_REINSURANCE_TREATIES, len(treaty_edm_combinations), \"One job per treaty-EDM combination\"])\n            batch_types_to_create.append(BatchType.CREATE_REINSURANCE_TREATIES)\n\n    # Check for Analysis (Analysis Table sheet)\n    if analyses:\n        batch_types_info.append([BatchType.ANALYSIS, len(analyses), \"One job per analysis\"])\n        batch_types_to_create.append(BatchType.ANALYSIS)\n    \n    # Display identified batch types\n    if batch_types_info:\n        ux.info(\"Batch types identified from configuration:\")\n        ux.table(batch_types_info, headers=[\"Batch Type\", \"Job Count\", \"Description\"])\n        ux.success(f\"✓ Found {len(batch_types_to_create)} batch type(s) to create\")\n        \n        step.log(f\"Identified {len(batch_types_to_create)} batch type(s): {', '.join(batch_types_to_create)}\")\n    else:\n        ux.warning(\"⚠ No batch types identified from configuration\")\n        ux.info(\"Configuration may not contain required data sheets (Databases, Portfolios, etc.)\")\n        step.fail(\"No batch types identified in configuration\")\n        raise ValueError(\"No batch types identified in configuration\")\n    \nexcept Exception as e:\n    ux.error(f\"✗ Batch type identification failed: {str(e)}\")\n    step.fail(f\"Batch type identification failed: {str(e)}\")\n    raise"
  },
  {
   "cell_type": "markdown",
   "id": "preview_edm_header",
   "metadata": {},
   "source": [
    "## 4a) Preview: EDM Creation Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "preview_edm",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview databases that will become jobs\n",
    "ux.header(\"EDM Creation Batch Preview\")\n",
    "\n",
    "if BatchType.PORTFOLIO_CREATION in batch_types_to_create:\n",
    "    ux.info(f\"This batch will create {len(databases)} job(s), one for each database:\")\n",
    "    ux.info(\"\")\n",
    "    \n",
    "    # Display databases table\n",
    "    database_rows = []\n",
    "    for db in databases:\n",
    "        database_rows.append([\n",
    "            db.get('Database', 'N/A')\n",
    "        ])\n",
    "    \n",
    "    ux.table(database_rows, headers=[\"EDM Name\"])\n",
    "    \n",
    "    ux.info(\"\")\n",
    "    ux.info(\"Each database will become one job with configuration containing:\")\n",
    "    ux.info(\"  - Metadata from configuration file\")\n",
    "    ux.info(\"  - Database-specific fields (Database, Version, EDM_Type, etc.)\")\n",
    "    \n",
    "    step.log(f\"Previewed EDM Creation batch: {len(databases)} databases\")\n",
    "else:\n",
    "    ux.info(\"EDM Creation batch not needed (no databases in configuration)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0bc817a",
   "metadata": {},
   "source": [
    "## 4b) Preview: Base Portfolio Creation Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e2c52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview portfolios that will become jobs\n",
    "ux.header(\"Base Portfolio Creation Batch Preview\")\n",
    "\n",
    "if BatchType.PORTFOLIO_CREATION in batch_types_to_create:\n",
    "    ux.info(f\"This batch will create {len(base_portfolios)} job(s), one for each base portfolio:\")\n",
    "    ux.info(\"\")\n",
    "    \n",
    "    # Display databases table\n",
    "    portfolio_rows = []\n",
    "    for port in base_portfolios:\n",
    "        portfolio_rows.append([\n",
    "            port.get('Portfolio', 'N/A'),\n",
    "            port.get('Database', 'N/A'),\n",
    "        ])\n",
    "    \n",
    "    ux.table(portfolio_rows, headers=[\"Portfolio\", \"EDM\"])\n",
    "    \n",
    "    ux.info(\"\")\n",
    "    ux.info(\"Each portfolio will become one job with configuration containing:\")\n",
    "    ux.info(\"  - Metadata from configuration file\")\n",
    "    ux.info(\"  - Portfolio-specific fields (Portfolio Name, EDM, etc.)\")\n",
    "    \n",
    "    step.log(f\"Previewed Base Portfolio Creation batch: {len(base_portfolios)} portfolios\")\n",
    "else:\n",
    "    ux.info(\"Portfolio Creation batch not needed (no base portfolios in configuration)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c8088d",
   "metadata": {},
   "source": [
    "## 4c) Preview: MRI Import Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9f523c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview portfolios that will become jobs\n",
    "ux.header(\"MRI Import Batch Preview\")\n",
    "\n",
    "if BatchType.MRI_IMPORT in batch_types_to_create:\n",
    "    ux.info(f\"This batch will create {len(base_portfolios)} job(s), one for each base portfolio:\")\n",
    "    ux.info(\"\")\n",
    "    \n",
    "    # Display databases table\n",
    "    portfolio_rows = []\n",
    "    for port in base_portfolios:\n",
    "        portfolio_rows.append([\n",
    "            port.get('Portfolio', 'N/A'),\n",
    "            port.get('Database', 'N/A'),\n",
    "            port.get('Import File', 'N/A')\n",
    "        ])\n",
    "    \n",
    "    ux.table(portfolio_rows, headers=[\"Portfolio\", \"EDM\", \"Import File\"])\n",
    "    \n",
    "    ux.info(\"\")\n",
    "    ux.info(\"Each portfolio will become one job with configuration containing:\")\n",
    "    ux.info(\"  - Metadata from configuration file\")\n",
    "    ux.info(\"  - Portfolio-specific fields (Portfolio Name, EDM, Import File, etc.)\")\n",
    "    \n",
    "    step.log(f\"Previewed MRI Import batch: {len(base_portfolios)} portfolios\")\n",
    "else:\n",
    "    ux.info(\"MRI Import batch not needed (no base portfolios in configuration)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75242db0",
   "metadata": {},
   "source": [
    "## 4d) Preview: Create Reinsurance Treaties Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d682e9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview reinsurance treaties that will become jobs\n",
    "ux.header(\"Create Reinsurance Treaties Batch Preview\")\n",
    "\n",
    "if BatchType.CREATE_REINSURANCE_TREATIES in batch_types_to_create:\n",
    "    ux.info(f\"This batch will create {len(treaty_edm_combinations)} job(s), one for each unique treaty-EDM combination:\")\n",
    "    ux.info(\"\")\n",
    "    \n",
    "    # Display treaty-EDM combinations table\n",
    "    treaty_rows = []\n",
    "    for treaty_name, edm in sorted(treaty_edm_combinations):\n",
    "        treaty_rows.append([treaty_name, edm])\n",
    "    \n",
    "    ux.table(treaty_rows, headers=[\"Treaty Name\", \"EDM\"])\n",
    "    \n",
    "    ux.info(\"\")\n",
    "    ux.info(\"Each treaty-EDM combination will become one job with configuration containing:\")\n",
    "    ux.info(\"  - Metadata from configuration file\")\n",
    "    ux.info(\"  - Database (EDM) where the treaty will be created\")\n",
    "    ux.info(\"  - Treaty-specific fields from Reinsurance Treaties sheet\")\n",
    "    \n",
    "    step.log(f\"Previewed Create Reinsurance Treaties batch: {len(treaty_edm_combinations)} treaty-EDM combinations\")\n",
    "else:\n",
    "    ux.info(\"Create Reinsurance Treaties batch not needed (no treaty-EDM combinations in configuration)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "euqcxauxahc",
   "metadata": {},
   "source": [
    "## 4e) Preview: EDM DB Upgrade Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "irxpez1qmfs",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview EDM DB Upgrade jobs\n",
    "ux.header(\"EDM DB Upgrade Batch Preview\")\n",
    "\n",
    "if BatchType.EDM_DB_UPGRADE in batch_types_to_create:\n",
    "    target_version = edm_version.split('.')[0] if '.' in edm_version else edm_version\n",
    "    ux.info(f\"This batch will create {len(databases)} job(s), one for each database:\")\n",
    "    ux.info(f\"Target EDM Data Version: {target_version}\")\n",
    "    ux.info(\"\")\n",
    "    \n",
    "    # Display databases table\n",
    "    database_rows = []\n",
    "    for db in databases:\n",
    "        database_rows.append([\n",
    "            db.get('Database', 'N/A'),\n",
    "            target_version\n",
    "        ])\n",
    "    \n",
    "    ux.table(database_rows, headers=[\"EDM Name\", \"Target Version\"])\n",
    "    \n",
    "    ux.info(\"\")\n",
    "    ux.info(\"Each database will become one job with configuration containing:\")\n",
    "    ux.info(\"  - Metadata from configuration file\")\n",
    "    ux.info(\"  - Database-specific fields from Databases sheet\")\n",
    "    ux.info(\"  - target_edm_version: The version to upgrade to\")\n",
    "    \n",
    "    step.log(f\"Previewed EDM DB Upgrade batch: {len(databases)} databases to version {target_version}\")\n",
    "else:\n",
    "    ux.info(\"EDM DB Upgrade batch not needed (no databases or EDM Data Version not specified)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hw4sjkxtnf",
   "source": "## 4f) Preview: GeoHaz Batch",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "39aynq8bfe7",
   "source": "# Preview GeoHaz jobs\nux.header(\"GeoHaz Batch Preview\")\n\nif BatchType.GEOHAZ in batch_types_to_create:\n    ux.info(f\"This batch will create {len(base_portfolios)} job(s), one for each base portfolio:\")\n    ux.info(f\"Geocode Version: {geocode_version}\")\n    ux.info(\"\")\n    \n    # Display portfolios table\n    portfolio_rows = []\n    for port in base_portfolios:\n        portfolio_rows.append([\n            port.get('Portfolio', 'N/A'),\n            port.get('Database', 'N/A'),\n            geocode_version\n        ])\n    \n    ux.table(portfolio_rows, headers=[\"Portfolio\", \"EDM\", \"Geocode Version\"])\n    \n    ux.info(\"\")\n    ux.info(\"Each portfolio will become one job with configuration containing:\")\n    ux.info(\"  - Metadata from configuration file\")\n    ux.info(\"  - Portfolio-specific fields from Portfolios sheet\")\n    ux.info(\"  - geocode_version: The geocode version to use\")\n    \n    step.log(f\"Previewed GeoHaz batch: {len(base_portfolios)} base portfolios with geocode v{geocode_version}\")\nelse:\n    ux.info(\"GeoHaz batch not needed (no base portfolios or Geocode Version not specified)\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "srch4y6r8bi",
   "source": "## 4g) Preview: Portfolio Mapping Batch",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "6ky1v7dw2jk",
   "source": "# Preview Portfolio Mapping jobs\nux.header(\"Portfolio Mapping Batch Preview\")\n\nif BatchType.PORTFOLIO_MAPPING in batch_types_to_create:\n    ux.info(f\"This batch will create {len(base_portfolios)} job(s), one for each base portfolio:\")\n    ux.info(\"\")\n    \n    # Display portfolios table\n    portfolio_rows = []\n    for port in base_portfolios:\n        portfolio_rows.append([\n            port.get('Portfolio', 'N/A'),\n            port.get('Database', 'N/A'),\n            port.get('Import File', 'N/A')\n        ])\n    \n    ux.table(portfolio_rows, headers=[\"Portfolio\", \"EDM\", \"Import File\"])\n    \n    ux.info(\"\")\n    ux.info(\"Each portfolio will become one job with configuration containing:\")\n    ux.info(\"  - Metadata from configuration file\")\n    ux.info(\"  - Portfolio-specific fields from Portfolios sheet\")\n    ux.info(\"  - SQL script: 2b_Query_To_Create_Sub_Portfolios_{Import File}_RMS_BackEnd.sql\")\n    ux.info(\"\")\n    ux.info(\"Note: Portfolio Mapping executes SQL scripts locally (not submitted to Moody's)\")\n    \n    step.log(f\"Previewed Portfolio Mapping batch: {len(base_portfolios)} base portfolios\")\nelse:\n    ux.info(\"Portfolio Mapping batch not needed (no base portfolios in configuration)\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "vuxzv595gdt",
   "source": "## 4h) Preview: Analysis Batch",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "eba5961l56p",
   "source": "# Preview Analysis jobs\nux.header(\"Analysis Batch Preview\")\n\nif BatchType.ANALYSIS in batch_types_to_create:\n    ux.info(f\"This batch will create {len(analyses)} job(s), one for each analysis:\")\n    ux.info(\"\")\n    \n    # Display analysis table\n    analysis_rows = []\n    for analysis in analyses[:10]:  # Show first 10\n        # Collect treaty names\n        treaty_names = []\n        for i in range(1, 6):\n            treaty = analysis.get(f'Reinsurance Treaty {i}')\n            if treaty:\n                treaty_names.append(treaty)\n        treaties_str = ', '.join(treaty_names) if treaty_names else 'None'\n        \n        # Collect tag names\n        tag_names = []\n        for i in range(1, 6):\n            tag = analysis.get(f'Tag {i}')\n            if tag:\n                tag_names.append(tag)\n        tags_str = ', '.join(tag_names) if tag_names else 'None'\n        \n        analysis_rows.append([\n            analysis.get('Analysis Name', 'N/A'),\n            analysis.get('Portfolio', 'N/A'),\n            analysis.get('Database', 'N/A'),\n            analysis.get('Analysis Profile', 'N/A')[:30] + '...' if len(analysis.get('Analysis Profile', '')) > 30 else analysis.get('Analysis Profile', 'N/A'),\n        ])\n    \n    ux.table(analysis_rows, headers=[\"Analysis Name\", \"Portfolio\", \"EDM\", \"Analysis Profile\"])\n    \n    if len(analyses) > 10:\n        ux.info(f\"... and {len(analyses) - 10} more analysis job(s)\")\n    \n    ux.info(\"\")\n    ux.info(\"Each analysis will become one job with configuration containing:\")\n    ux.info(\"  - Metadata from configuration file\")\n    ux.info(\"  - Analysis-specific fields (Name, Portfolio, Database, Profiles, Treaties, Tags)\")\n    \n    step.log(f\"Previewed Analysis batch: {len(analyses)} analyses\")\nelse:\n    ux.info(\"Analysis batch not needed (no analyses in configuration)\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "create_batches_header",
   "metadata": {},
   "source": [
    "## 5) Create Batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create_batches",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create batches for identified batch types\n",
    "ux.header(\"Batch Creation\")\n",
    "\n",
    "# Confirm with user\n",
    "batch_summary = \", \".join(batch_types_to_create)\n",
    "ux.info(f\"Ready to create batches: {batch_summary}\")\n",
    "proceed = ux.yes_no(\"Create these batches?\")\n",
    "\n",
    "if not proceed:\n",
    "    ux.info(\"Batch creation cancelled by user\")\n",
    "    step.log(\"User cancelled batch creation\")\n",
    "    raise SystemExit(\"User cancelled batch creation\")\n",
    "\n",
    "# Create batches\n",
    "created_batches = {}\n",
    "\n",
    "try:\n",
    "    for batch_type in batch_types_to_create:\n",
    "        ux.subheader(f\"Creating batch: {batch_type}\")\n",
    "        \n",
    "        # Create batch (this will create jobs atomically)\n",
    "        batch_id = create_batch(\n",
    "            batch_type=batch_type,\n",
    "            configuration_id=config_id,\n",
    "            step_id=step.step_id\n",
    "        )\n",
    "        \n",
    "        # Store batch ID (convert to int to avoid numpy types)\n",
    "        created_batches[batch_type] = int(batch_id)\n",
    "        \n",
    "        # Get job count for this batch\n",
    "        job_count_result = execute_query(\n",
    "            \"SELECT COUNT(*) as count FROM irp_job WHERE batch_id = %s\",\n",
    "            (batch_id,)\n",
    "        )\n",
    "        job_count = int(job_count_result.iloc[0]['count'])\n",
    "        \n",
    "        ux.success(f\"✓ Batch created: ID={batch_id}\")\n",
    "        ux.info(f\"  Jobs created: {job_count}\")\n",
    "        \n",
    "        step.log(f\"Created batch '{batch_type}': ID={batch_id}, Jobs={job_count}\")\n",
    "    \n",
    "    ux.success(f\"\\n✓ All batches created successfully ({len(created_batches)} total)\")\n",
    "    \n",
    "except Exception as e:\n",
    "    ux.error(f\"✗ Batch creation failed: {str(e)}\")\n",
    "    step.fail(f\"Batch creation failed: {str(e)}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "batch_summary_header",
   "metadata": {},
   "source": [
    "## 6) Display Batch Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "batch_summary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display summary of all created batches\n",
    "ux.header(\"Batch Summary\")\n",
    "\n",
    "try:\n",
    "    # Get batch details\n",
    "    batch_ids = list(created_batches.values())\n",
    "    \n",
    "    if batch_ids:\n",
    "        # Build query to get all batches\n",
    "        placeholders = ', '.join(['%s'] * len(batch_ids))\n",
    "        batch_query = f\"\"\"\n",
    "            SELECT \n",
    "                b.id,\n",
    "                b.batch_type,\n",
    "                b.status,\n",
    "                b.created_ts,\n",
    "                COUNT(j.id) as job_count\n",
    "            FROM irp_batch b\n",
    "            LEFT JOIN irp_job j ON b.id = j.batch_id\n",
    "            WHERE b.id IN ({placeholders})\n",
    "            GROUP BY b.id, b.batch_type, b.status, b.created_ts\n",
    "            ORDER BY b.created_ts\n",
    "        \"\"\"\n",
    "        \n",
    "        batch_results = execute_query(batch_query, tuple(batch_ids))\n",
    "        \n",
    "        # Display batch information\n",
    "        batch_rows = []\n",
    "        total_jobs = 0\n",
    "        \n",
    "        for _, batch in batch_results.iterrows():\n",
    "            batch_rows.append([\n",
    "                batch['batch_type'],\n",
    "                batch['id'],\n",
    "                batch['status'],\n",
    "                int(batch['job_count']),\n",
    "                batch['created_ts'].strftime('%Y-%m-%d %H:%M:%S')\n",
    "            ])\n",
    "            total_jobs += int(batch['job_count'])\n",
    "        \n",
    "        ux.table(batch_rows, headers=[\"Batch Type\", \"Batch ID\", \"Status\", \"Jobs\", \"Created\"])\n",
    "        \n",
    "        ux.info(f\"\\nTotal batches: {len(batch_ids)}\")\n",
    "        ux.info(f\"Total jobs: {total_jobs}\")\n",
    "        \n",
    "        step.log(f\"Batch summary: {len(batch_ids)} batches, {total_jobs} total jobs\")\n",
    "    \n",
    "except Exception as e:\n",
    "    ux.error(f\"✗ Failed to display batch summary: {str(e)}\")\n",
    "    # Don't fail step, this is just display\n",
    "    step.log(f\"Warning: Failed to display batch summary: {str(e)}\", level=\"WARNING\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "preview_jobs_header",
   "metadata": {},
   "source": [
    "## 7) Preview Job Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "preview_jobs",
   "metadata": {},
   "outputs": [],
   "source": "# Preview job configurations for created batches\nux.header(\"Job Configuration Preview\")\n\ntry:\n    # Preview EDM Creation jobs\n    if 'EDM Creation' in created_batches:\n        edm_batch_id = created_batches['EDM Creation']\n        \n        ux.subheader(\"EDM Creation Jobs (first 5)\")\n        \n        # Get job configurations\n        job_config_query = \"\"\"\n            SELECT \n                jc.id,\n                jc.job_configuration_data,\n                j.id as job_id,\n                j.status\n            FROM irp_job_configuration jc\n            INNER JOIN irp_job j ON jc.id = j.job_configuration_id\n            WHERE jc.batch_id = %s\n            LIMIT 5\n        \"\"\"\n        \n        job_configs = execute_query(job_config_query, (edm_batch_id,))\n        \n        if not job_configs.empty:\n            # Display job configuration details\n            job_rows = []\n            for _, job_config in job_configs.iterrows():\n                config_data = job_config['job_configuration_data']\n                job_rows.append([\n                    job_config['job_id'],\n                    config_data.get('Database', 'N/A'),\n                    job_config['status']\n                ])\n            \n            ux.table(job_rows, headers=[\"Job ID\", \"Database\", \"Status\"])\n            \n            ux.info(\"\\nEach job configuration contains:\")\n            ux.info(\"  - Full metadata from configuration file\")\n            ux.info(\"  - Database-specific fields from Databases sheet\")\n            ux.info(\"  - Additional fields: Description, Connection details, etc.\")\n        else:\n            ux.warning(\"No job configurations found\")\n    \n    # Preview EDM DB Upgrade jobs\n    if 'EDM DB Upgrade' in created_batches:\n        upgrade_batch_id = created_batches['EDM DB Upgrade']\n        \n        ux.subheader(\"EDM DB Upgrade Jobs (first 5)\")\n        \n        # Get job configurations\n        job_config_query = \"\"\"\n            SELECT \n                jc.id,\n                jc.job_configuration_data,\n                j.id as job_id,\n                j.status\n            FROM irp_job_configuration jc\n            INNER JOIN irp_job j ON jc.id = j.job_configuration_id\n            WHERE jc.batch_id = %s\n            LIMIT 5\n        \"\"\"\n        \n        job_configs = execute_query(job_config_query, (upgrade_batch_id,))\n        \n        if not job_configs.empty:\n            # Display job configuration details\n            job_rows = []\n            for _, job_config in job_configs.iterrows():\n                config_data = job_config['job_configuration_data']\n                job_rows.append([\n                    job_config['job_id'],\n                    config_data.get('Database', 'N/A'),\n                    config_data.get('target_edm_version', 'N/A'),\n                    job_config['status']\n                ])\n            \n            ux.table(job_rows, headers=[\"Job ID\", \"Database\", \"Target Version\", \"Status\"])\n            \n            ux.info(\"\\nEach job configuration contains:\")\n            ux.info(\"  - Full metadata from configuration file\")\n            ux.info(\"  - Database-specific fields from Databases sheet\")\n            ux.info(\"  - target_edm_version: The version to upgrade to\")\n        else:\n            ux.warning(\"No job configurations found\")\n    \n    # Preview Portfolio Creation jobs\n    if 'Portfolio Creation' in created_batches:\n        portfolio_batch_id = created_batches['Portfolio Creation']\n        \n        ux.subheader(\"Portfolio Creation Jobs (first 5)\")\n        \n        # Get job configurations\n        job_config_query = \"\"\"\n            SELECT \n                jc.id,\n                jc.job_configuration_data,\n                j.id as job_id,\n                j.status\n            FROM irp_job_configuration jc\n            INNER JOIN irp_job j ON jc.id = j.job_configuration_id\n            WHERE jc.batch_id = %s\n            LIMIT 5\n        \"\"\"\n        \n        job_configs = execute_query(job_config_query, (portfolio_batch_id,))\n        \n        if not job_configs.empty:\n            # Display job configuration details\n            job_rows = []\n            for _, job_config in job_configs.iterrows():\n                config_data = job_config['job_configuration_data']\n                job_rows.append([\n                    job_config['job_id'],\n                    config_data.get('Portfolio', 'N/A'),\n                    config_data.get('Database', 'N/A'),\n                    job_config['status']\n                ])\n            \n            ux.table(job_rows, headers=[\"Job ID\", \"Portfolio\", \"EDM\", \"Status\"])\n            \n            ux.info(\"\\nEach job configuration contains:\")\n            ux.info(\"  - Full metadata from configuration file\")\n            ux.info(\"  - Portfolio-specific fields from Portfolios sheet\")\n            ux.info(\"  - Additional fields: Portfolio Name, Database, Base Portfolio flag, etc.\")\n        else:\n            ux.warning(\"No job configurations found\")\n    \n    # Preview MRI Import jobs\n    if 'MRI Import' in created_batches:\n        mri_batch_id = created_batches['MRI Import']\n        \n        ux.subheader(\"MRI Import Jobs (first 5)\")\n        \n        # Get job configurations\n        job_config_query = \"\"\"\n            SELECT \n                jc.id,\n                jc.job_configuration_data,\n                j.id as job_id,\n                j.status\n            FROM irp_job_configuration jc\n            INNER JOIN irp_job j ON jc.id = j.job_configuration_id\n            WHERE jc.batch_id = %s\n            LIMIT 5\n        \"\"\"\n        \n        job_configs = execute_query(job_config_query, (mri_batch_id,))\n        \n        if not job_configs.empty:\n            # Display job configuration details\n            job_rows = []\n            for _, job_config in job_configs.iterrows():\n                config_data = job_config['job_configuration_data']\n                job_rows.append([\n                    job_config['job_id'],\n                    config_data.get('Portfolio', 'N/A'),\n                    config_data.get('Database', 'N/A'),\n                    config_data.get('accounts_import_file', 'N/A'),\n                    config_data.get('locations_import_file', 'N/A'),\n                    job_config['status']\n                ])\n            \n            ux.table(job_rows, headers=[\"Job ID\", \"Portfolio\", \"EDM\", \"Accounts File\", \"Locations File\", \"Status\"])\n            \n            ux.info(\"\\nEach job configuration contains:\")\n            ux.info(\"  - Full metadata from configuration file\")\n            ux.info(\"  - Portfolio-specific fields from Portfolios sheet\")\n            ux.info(\"  - CSV import filenames: accounts_import_file, locations_import_file\")\n            ux.info(\"  - Additional fields: Portfolio Name, Database, Import File, etc.\")\n        else:\n            ux.warning(\"No job configurations found\")\n    \n    # Preview GeoHaz jobs\n    if 'GeoHaz' in created_batches:\n        geohaz_batch_id = created_batches['GeoHaz']\n        \n        ux.subheader(\"GeoHaz Jobs (first 5)\")\n        \n        # Get job configurations\n        job_config_query = \"\"\"\n            SELECT \n                jc.id,\n                jc.job_configuration_data,\n                j.id as job_id,\n                j.status\n            FROM irp_job_configuration jc\n            INNER JOIN irp_job j ON jc.id = j.job_configuration_id\n            WHERE jc.batch_id = %s\n            LIMIT 5\n        \"\"\"\n        \n        job_configs = execute_query(job_config_query, (geohaz_batch_id,))\n        \n        if not job_configs.empty:\n            # Display job configuration details\n            job_rows = []\n            for _, job_config in job_configs.iterrows():\n                config_data = job_config['job_configuration_data']\n                job_rows.append([\n                    job_config['job_id'],\n                    config_data.get('Portfolio', 'N/A'),\n                    config_data.get('Database', 'N/A'),\n                    config_data.get('geocode_version', 'N/A'),\n                    job_config['status']\n                ])\n            \n            ux.table(job_rows, headers=[\"Job ID\", \"Portfolio\", \"EDM\", \"Geocode Version\", \"Status\"])\n            \n            ux.info(\"\\nEach job configuration contains:\")\n            ux.info(\"  - Full metadata from configuration file\")\n            ux.info(\"  - Portfolio-specific fields from Portfolios sheet\")\n            ux.info(\"  - geocode_version: The geocode version to use\")\n        else:\n            ux.warning(\"No job configurations found\")\n    \n    # Preview Create Reinsurance Treaties jobs\n    if 'Create Reinsurance Treaties' in created_batches:\n        treaty_batch_id = created_batches['Create Reinsurance Treaties']\n        \n        ux.subheader(\"Create Reinsurance Treaties Jobs (first 5)\")\n        \n        # Get job configurations\n        job_config_query = \"\"\"\n            SELECT \n                jc.id,\n                jc.job_configuration_data,\n                j.id as job_id,\n                j.status\n            FROM irp_job_configuration jc\n            INNER JOIN irp_job j ON jc.id = j.job_configuration_id\n            WHERE jc.batch_id = %s\n            LIMIT 5\n        \"\"\"\n        \n        job_configs = execute_query(job_config_query, (treaty_batch_id,))\n        \n        if not job_configs.empty:\n            # Display job configuration details\n            job_rows = []\n            for _, job_config in job_configs.iterrows():\n                config_data = job_config['job_configuration_data']\n                job_rows.append([\n                    job_config['job_id'],\n                    config_data.get('Treaty Name', 'N/A'),\n                    config_data.get('Database', 'N/A'),\n                    job_config['status']\n                ])\n            \n            ux.table(job_rows, headers=[\"Job ID\", \"Treaty Name\", \"EDM\", \"Status\"])\n            \n            ux.info(\"\\nEach job configuration contains:\")\n            ux.info(\"  - Full metadata from configuration file\")\n            ux.info(\"  - Database (EDM) where the treaty will be created\")\n            ux.info(\"  - Treaty-specific fields from Reinsurance Treaties sheet\")\n        else:\n            ux.warning(\"No job configurations found\")\n    \n    # Preview Analysis jobs\n    if 'Analysis' in created_batches:\n        analysis_batch_id = created_batches['Analysis']\n        \n        ux.subheader(\"Analysis Jobs (first 5)\")\n        \n        # Get job configurations\n        job_config_query = \"\"\"\n            SELECT \n                jc.id,\n                jc.job_configuration_data,\n                j.id as job_id,\n                j.status\n            FROM irp_job_configuration jc\n            INNER JOIN irp_job j ON jc.id = j.job_configuration_id\n            WHERE jc.batch_id = %s\n            LIMIT 5\n        \"\"\"\n        \n        job_configs = execute_query(job_config_query, (analysis_batch_id,))\n        \n        if not job_configs.empty:\n            # Display job configuration details\n            job_rows = []\n            for _, job_config in job_configs.iterrows():\n                config_data = job_config['job_configuration_data']\n                job_rows.append([\n                    job_config['job_id'],\n                    config_data.get('Analysis Name', 'N/A'),\n                    config_data.get('Portfolio', 'N/A'),\n                    config_data.get('Database', 'N/A'),\n                    config_data.get('Analysis Profile', 'N/A')[:25] + '...' if len(config_data.get('Analysis Profile', '')) > 25 else config_data.get('Analysis Profile', 'N/A'),\n                    job_config['status']\n                ])\n            \n            ux.table(job_rows, headers=[\"Job ID\", \"Analysis Name\", \"Portfolio\", \"EDM\", \"Analysis Profile\", \"Status\"])\n            \n            ux.info(\"\\nEach job configuration contains:\")\n            ux.info(\"  - Full metadata from configuration file\")\n            ux.info(\"  - Analysis-specific fields from Analysis Table sheet\")\n            ux.info(\"  - Analysis Profile, Output Profile, Event Rate, Treaties, Tags\")\n        else:\n            ux.warning(\"No job configurations found\")\n    \n    step.log(\"Job configuration preview displayed\")\n    \nexcept Exception as e:\n    ux.error(f\"✗ Failed to preview job configurations: {str(e)}\")\n    # Don't fail step, this is just display\n    step.log(f\"Warning: Failed to preview jobs: {str(e)}\", level=\"WARNING\")"
  },
  {
   "cell_type": "markdown",
   "id": "complete_step_header",
   "metadata": {},
   "source": [
    "## 8) Complete Step Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complete_step",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete step execution\n",
    "ux.header(\"Step Completion\")\n",
    "\n",
    "try:\n",
    "    # Prepare output data\n",
    "    output_data = {\n",
    "        'configuration_id': config_id,\n",
    "        'batches': created_batches,  # {batch_type: batch_id}\n",
    "        'batch_types_created': batch_types_to_create,\n",
    "        'total_job_count': total_jobs\n",
    "    }\n",
    "    \n",
    "    # Complete the step\n",
    "    step.complete(output_data)\n",
    "\n",
    "    ux.success(\"\\n\" + \"=\"*60)\n",
    "    ux.success(\"✓ BATCHES CREATED SUCCESSFULLY\")\n",
    "    ux.success(\"=\"*60)\n",
    "    ux.info(f\"\\nCreated {len(created_batches)} batch(es) with {total_jobs} total job(s)\")\n",
    "    ux.info(\"Batches are in INITIATED status and ready for submission\")\n",
    "    ux.info(\"\\nNext: Stage 02 will handle batch submission and job monitoring\")\n",
    "\n",
    "except Exception as e:\n",
    "    ux.error(f\"✗ Step completion failed: {str(e)}\")\n",
    "    step.fail(str(e))\n",
    "    raise"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}