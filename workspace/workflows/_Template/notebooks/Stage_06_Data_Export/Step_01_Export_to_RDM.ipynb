{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "notebook_header",
   "metadata": {},
   "source": [
    "# Step 01: Export to RDM\n",
    "\n",
    "This notebook exports all analysis results and groups to a Results Data Mart (RDM).\n",
    "\n",
    "**Tasks:**\n",
    "- Retrieve Export to RDM batch from Stage_01/Step_03\n",
    "- Review export job configuration\n",
    "- Submit export job to Moody's API\n",
    "- Track job completion status\n",
    "\n",
    "**Prerequisites:**\n",
    "- All Analysis jobs must be complete\n",
    "- All Grouping and Grouping Rollup jobs must be complete\n",
    "- Export RDM Name must be configured in Metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup_header",
   "metadata": {},
   "source": [
    "## 1) Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": "%load_ext autoreload\n%autoreload 2\n\nfrom helpers.notebook_setup import initialize_notebook_context\nfrom helpers import ux\nfrom helpers.batch import submit_batch, get_batch_jobs, read_batch, validate_batch\nfrom helpers.database import execute_query\nfrom helpers.irp_integration import IRPClient\nfrom helpers.constants import BatchType\n\n# Flag to track validation state - allows notebook to complete gracefully on failure\nvalidation_failed = False\nvalidation_errors = []"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "context_init",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize notebook context and step tracking\n",
    "context, step = initialize_notebook_context('Step_01_Export_to_RDM.ipynb')\n",
    "\n",
    "# Display context\n",
    "ux.header(\"Export to RDM\")\n",
    "ux.info(f\"Cycle: {context.cycle_name}\")\n",
    "ux.info(f\"Stage: {context.stage_name}\")\n",
    "ux.info(f\"Step: {context.step_name}\")\n",
    "ux.success(f\"Step tracking initialized for '{context.step_name}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "retrieve_header",
   "metadata": {},
   "source": [
    "## 2) Retrieve Export to RDM Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "retrieve_batch",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve Export to RDM batch from Stage_01/Step_03\n",
    "ux.subheader(\"Retrieve Export to RDM Batch\")\n",
    "\n",
    "# Query for Stage_01/Step_03 step run\n",
    "query = \"\"\"\n",
    "    SELECT sr.id, sr.step_id, sr.run_num, sr.output_data, sr.completed_ts\n",
    "    FROM irp_step_run sr\n",
    "    INNER JOIN irp_step s ON sr.step_id = s.id\n",
    "    INNER JOIN irp_stage sg ON s.stage_id = sg.id\n",
    "    INNER JOIN irp_cycle c ON sg.cycle_id = c.id\n",
    "    WHERE c.cycle_name = %s\n",
    "      AND sg.stage_num = 1\n",
    "      AND s.step_num = 3\n",
    "      AND sr.status = 'COMPLETED'\n",
    "    ORDER BY sr.completed_ts DESC\n",
    "    LIMIT 1\n",
    "\"\"\"\n",
    "\n",
    "result = execute_query(query, (context.cycle_name,))\n",
    "\n",
    "if result.empty:\n",
    "    raise ValueError(\"Batch creation step not found - please complete Stage_01/Step_03 first\")\n",
    "\n",
    "output_data = result.iloc[0]['output_data']\n",
    "batches = output_data.get('batches', {})\n",
    "\n",
    "if BatchType.EXPORT_TO_RDM not in batches:\n",
    "    raise ValueError(f\"Export to RDM batch not found. Available: {list(batches.keys())}\")\n",
    "\n",
    "export_batch_id = int(batches[BatchType.EXPORT_TO_RDM])\n",
    "\n",
    "ux.success(f\"Retrieved Export to RDM batch: ID={export_batch_id}\")\n",
    "step.log(f\"Retrieved Export to RDM batch: ID={export_batch_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "review_header",
   "metadata": {},
   "source": [
    "## 3) Review Export Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "review_config",
   "metadata": {},
   "outputs": [],
   "source": "# Verify batch status and display job information\nux.subheader(\"Verify Batch Status\")\n\n# Read batch details\nbatch = read_batch(export_batch_id)\n\nbatch_info = [\n    [\"Batch ID\", batch['id']],\n    [\"Batch Type\", batch['batch_type']],\n    [\"Status\", batch['status']],\n    [\"Created\", batch['created_ts'].strftime('%Y-%m-%d %H:%M:%S')]\n]\nux.table(batch_info, headers=[\"Property\", \"Value\"])\n\n# Get jobs in batch (should be 1 job)\njobs = get_batch_jobs(export_batch_id)\njob_count = len(jobs)\n\nux.info(f\"\\nTotal jobs: {job_count}\")\n\n# Check entity existence for FINISHED jobs to show what will be resubmitted\nfrom helpers.entity_validator import EntityValidator\nfrom helpers.constants import JobStatus\n\nvalidator = EntityValidator()\n\n# Categorize jobs by status and entity existence\npending_jobs = []      # INITIATED jobs - will be submitted\nskipped_jobs = []      # FINISHED jobs where entity still exists - will be skipped\nresubmit_jobs = []     # FINISHED jobs where entity is missing - will be resubmitted\nother_jobs = []        # Jobs in other states (SUBMITTED, RUNNING, etc.)\n\n# Store config for display\nrdm_name = 'N/A'\nserver_name = 'N/A'\nanalysis_names = []\nanalysis_count = 0\ngroup_count = 0\n\nfor job in jobs:\n    config_query = \"SELECT job_configuration_data FROM irp_job_configuration WHERE id = %s\"\n    config_result = execute_query(config_query, (job['job_configuration_id'],))\n    config_data = config_result.iloc[0]['job_configuration_data'] if not config_result.empty else {}\n    \n    rdm_name = config_data.get('rdm_name', 'N/A')\n    server_name = config_data.get('server_name', 'N/A')\n    analysis_names = config_data.get('analysis_names', [])\n    analysis_count = config_data.get('analysis_count', 0)\n    group_count = config_data.get('group_count', 0)\n    \n    display_name = f\"Export to {rdm_name} ({len(analysis_names)} items)\"\n    \n    if job['status'] == JobStatus.INITIATED:\n        pending_jobs.append(display_name)\n    elif job['status'] == JobStatus.FINISHED:\n        entity_exists = validator.check_entity_exists_for_job(config_data, batch['batch_type'])\n        if entity_exists:\n            skipped_jobs.append(display_name)\n        else:\n            resubmit_jobs.append(display_name)\n    else:\n        other_jobs.append((display_name, job['status']))\n\n# Display categorized job summary\nux.subheader(\"Job Summary\")\n\nif pending_jobs:\n    ux.info(f\"\\nðŸ†• Jobs to submit ({len(pending_jobs)}):\")\n    for name in pending_jobs[:10]:\n        ux.info(f\"  â€¢ {name}\")\n\nif resubmit_jobs:\n    ux.warning(f\"\\nðŸ”„ Jobs to resubmit - RDM data missing ({len(resubmit_jobs)}):\")\n    for name in resubmit_jobs[:10]:\n        ux.warning(f\"  â€¢ {name}\")\n\nif skipped_jobs:\n    ux.success(f\"\\nâœ“ Jobs to skip - RDM data exists ({len(skipped_jobs)}):\")\n    for name in skipped_jobs[:10]:\n        ux.success(f\"  â€¢ {name}\")\n\nif other_jobs:\n    ux.info(f\"\\nâ³ Jobs in progress ({len(other_jobs)}):\")\n    for name, status in other_jobs[:5]:\n        ux.info(f\"  â€¢ {name} ({status})\")\n\n# Summary line\ntotal_to_process = len(pending_jobs) + len(resubmit_jobs)\nux.info(f\"\\nðŸ“Š Summary: {total_to_process} job(s) will be submitted, {len(skipped_jobs)} will be skipped\")\n\n# Show export configuration details\nux.subheader(\"Export Configuration\")\nexport_info = [\n    [\"Target RDM\", rdm_name],\n    [\"Server\", server_name],\n    [\"Analyses to Export\", analysis_count],\n    [\"Groups to Export\", group_count],\n    [\"Total Items\", len(analysis_names)]\n]\nux.table(export_info, headers=[\"Property\", \"Value\"])\n\n# Show preview of items to export\nif analysis_names:\n    ux.info(\"\\nItems to export (first 15):\")\n    for name in analysis_names[:15]:\n        ux.info(f\"  - {name}\")\n    if len(analysis_names) > 15:\n        ux.info(f\"  ... and {len(analysis_names) - 15} more\")\n\n# Validate batch before submission\nux.subheader(\"Validate Batch\")\nvalidation_errors = validate_batch(export_batch_id)\n\nif validation_errors:\n    validation_failed = True\n    ux.error(\"âœ— Batch validation failed:\")\n    for error in validation_errors:\n        ux.error(f\"  {error}\")\n    step.log(f\"Batch validation failed: {len(validation_errors)} error(s)\")\nelse:\n    ux.success(\"âœ“ Batch validation passed\")\n    step.log(f\"Verified batch: {total_to_process} job(s) to submit, {len(skipped_jobs)} to skip\")"
  },
  {
   "cell_type": "markdown",
   "id": "submit_header",
   "metadata": {},
   "source": [
    "## 4) Submit Export to RDM Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "submit_batch",
   "metadata": {},
   "outputs": [],
   "source": "# Submit batch to Moody's API\nif validation_failed:\n    ux.warning(\"â­ Skipping submission due to validation failure\")\n    submit_result = None\n    failed_count = 0\nelse:\n    ux.subheader(\"Submit Batch to Moody's\")\n\n    ux.info(\"\")\n    ux.info(\"Submission Process:\")\n    ux.info(\"  - Analysis and group names will be resolved to URIs\")\n    ux.info(\"  - Results will be exported to the configured RDM\")\n    ux.info(f\"  - Target RDM: {rdm_name}\")\n    ux.info(f\"  - Server: {server_name}\")\n    ux.info(\"  - Job will transition to SUBMITTED status\")\n    ux.info(\"  - Batch will transition to ACTIVE status\")\n    ux.info(\"\")\n\n    # Submit\n    ux.info(\"\\nSubmitting batch...\")\n\n    # Pass step.step_id to associate batch with this step (not the creation step)\n    submit_result = submit_batch(export_batch_id, IRPClient(), step_id=step.step_id)\n\n    # Display results\n    ux.success(f\"\\nBatch submission completed\")\n    ux.info(f\"  Submitted: {submit_result['submitted_jobs']} job(s)\")\n    ux.info(f\"  Status: {submit_result['batch_status']}\")\n\n    # Check for errors\n    failed_count = len([j for j in submit_result['jobs'] if 'error' in j])\n    if failed_count > 0:\n        ux.warning(f\"\\n{failed_count} job(s) failed to submit\")\n        for job_result in submit_result['jobs']:\n            if 'error' in job_result:\n                ux.error(f\"  Job {job_result['job_id']}: {job_result['error']}\")\n\n    step.log(f\"Batch submitted: {submit_result['submitted_jobs']} job(s), {failed_count} failed\")"
  },
  {
   "cell_type": "markdown",
   "id": "complete_header",
   "metadata": {},
   "source": [
    "## 5) Complete Step Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complete_step",
   "metadata": {},
   "outputs": [],
   "source": "# Complete step execution\nux.header(\"Step Completion\")\n\nif validation_failed:\n    # Handle validation failure\n    from helpers.step import update_step_run\n    from helpers.constants import StepStatus\n    \n    error_message = \"\\n\".join(validation_errors)\n    update_step_run(step.run_id, StepStatus.FAILED, error_message=error_message)\n    \n    ux.error(\"\\n\" + \"=\"*60)\n    ux.error(\"BATCH VALIDATION FAILED\")\n    ux.error(\"=\"*60)\n    ux.info(f\"\\nBatch ID: {export_batch_id}\")\n    ux.error(f\"\\nValidation errors ({len(validation_errors)}):\")\n    for error in validation_errors:\n        ux.error(f\"  {error}\")\n    ux.info(\"\\nPlease fix the validation errors and retry.\")\n\nelif failed_count > 0:\n    # Handle submission failures\n    failed_job_errors = [\n        f\"Job {j['job_id']}: {j['error']}\" \n        for j in submit_result['jobs'] if 'error' in j\n    ]\n    error_message = f\"{failed_count} job(s) failed to submit:\\n\" + \"\\n\".join(failed_job_errors)\n    \n    from helpers.step import update_step_run\n    from helpers.constants import StepStatus\n    update_step_run(step.run_id, StepStatus.FAILED, error_message=error_message)\n    \n    ux.error(\"\\n\" + \"=\"*60)\n    ux.error(\"BATCH SUBMISSION FAILED\")\n    ux.error(\"=\"*60)\n    ux.info(f\"\\nBatch ID: {export_batch_id}\")\n    ux.info(f\"Target RDM: {rdm_name}\")\n    ux.info(f\"Submitted: {submit_result['submitted_jobs']} job(s)\")\n    ux.error(f\"Failed: {failed_count} job(s)\")\n    ux.info(\"\\nFailed jobs:\")\n    for error in failed_job_errors:\n        ux.error(f\"  {error}\")\n    ux.info(\"\\nPlease review the errors and resubmit failed jobs.\")\n\nelse:\n    # Complete the step successfully\n    output_data = {\n        'batch_id': export_batch_id,\n        'batch_type': batch['batch_type'],\n        'batch_status': submit_result['batch_status'],\n        'submitted_jobs': submit_result['submitted_jobs'],\n        'failed_jobs': failed_count,\n        'rdm_name': rdm_name,\n        'server_name': server_name,\n        'total_items_exported': len(analysis_names)\n    }\n    step.complete(output_data)\n\n    ux.success(\"\\n\" + \"=\"*60)\n    ux.success(\"EXPORT TO RDM SUBMITTED SUCCESSFULLY\")\n    ux.success(\"=\"*60)\n    ux.info(f\"\\nSubmitted {submit_result['submitted_jobs']} job(s) to Moody's API\")\n    ux.info(f\"Target RDM: {rdm_name}\")\n    ux.info(f\"Items to export: {len(analysis_names)} ({analysis_count} analyses + {group_count} groups)\")\n    ux.info(f\"Batch status: {submit_result['batch_status']}\")\n    ux.info(\"\\nMonitor job progress and verify export completion in Moody's.\")"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}