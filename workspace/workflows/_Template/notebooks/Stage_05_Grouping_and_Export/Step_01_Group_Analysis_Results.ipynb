{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0c72b1a",
   "metadata": {},
   "source": "# Step 01: Group Analysis Results (Analysis-only Groups)\n\nThis notebook submits analysis grouping jobs to Moody's Risk Modeler for **analysis-only groups**.\n\nAnalysis-only groups contain ONLY analysis names (no references to other groups). These can be created immediately since all analyses already exist.\n\n**Tasks:**\n- Retrieve Grouping batch from Stage_01/Step_03\n- Review grouping job configurations\n- Submit grouping jobs to Moody's API\n- Track job completion status\n\n**Note:** If you have groups that contain OTHER groups (rollup groups), those are handled separately in Step_02_Group_Rollup.ipynb AFTER this step completes."
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "id": "4af9ee11",
   "metadata": {},
   "outputs": [],
   "source": "## 1) Setup"
  },
  {
   "cell_type": "code",
   "id": "wp316yt12gf",
   "source": "%load_ext autoreload\n%autoreload 2\n\nimport sys\nfrom pathlib import Path\n\nfrom helpers.notebook_setup import initialize_notebook_context\nfrom helpers import ux\nfrom helpers.batch import submit_batch, get_batch_jobs, read_batch, validate_batch\nfrom helpers.database import execute_query\nfrom helpers.step import get_last_step_run\nfrom helpers.irp_integration import IRPClient\nfrom helpers.constants import BatchType\n\n# Flag to track validation state - allows notebook to complete gracefully on failure\nvalidation_failed = False\nvalidation_errors = []",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "4ej9v0v5rkp",
   "source": "# Initialize notebook context and step tracking\ncontext, step = initialize_notebook_context('Step_01_Group_Analysis_Results.ipynb')\n\n# Display context\nux.header(\"Group Analysis Results Batch (Analysis-only Groups)\")\nux.info(f\"Cycle: {context.cycle_name}\")\nux.info(f\"Stage: {context.stage_name}\")\nux.info(f\"Step: {context.step_name}\")\nux.success(f\"Step tracking initialized for '{context.step_name}'\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "rskp2iaalc8",
   "source": "## 2) Retrieve Grouping Batch",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "o3s77ulvu7r",
   "source": "# Retrieve Grouping batch from Stage_01/Step_03\nux.subheader(\"Retrieve Grouping Batch\")\n\n# Query for Stage_01/Step_03 step run\nquery = \"\"\"\n    SELECT sr.id, sr.step_id, sr.run_num, sr.output_data, sr.completed_ts\n    FROM irp_step_run sr\n    INNER JOIN irp_step s ON sr.step_id = s.id\n    INNER JOIN irp_stage sg ON s.stage_id = sg.id\n    INNER JOIN irp_cycle c ON sg.cycle_id = c.id\n    WHERE c.cycle_name = %s\n      AND sg.stage_num = 1\n      AND s.step_num = 3\n      AND sr.status = 'COMPLETED'\n    ORDER BY sr.completed_ts DESC\n    LIMIT 1\n\"\"\"\n\nresult = execute_query(query, (context.cycle_name,))\n\nif result.empty:\n    raise ValueError(\"Batch creation step not found - please complete Stage_01/Step_03 first\")\n\noutput_data = result.iloc[0]['output_data']\nbatches = output_data.get('batches', {})\n\nif BatchType.GROUPING not in batches:\n    raise ValueError(f\"Grouping batch not found. Available: {list(batches.keys())}\")\n\ngrouping_batch_id = int(batches[BatchType.GROUPING])\n\nux.success(f\"Retrieved Grouping batch: ID={grouping_batch_id}\")\nstep.log(f\"Retrieved Grouping batch: ID={grouping_batch_id}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "tadk4fhcg0b",
   "source": "## 3) Review Grouping Batch Configuration",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "n8ddbk9w4jf",
   "source": "# Verify batch status and display job information\nux.subheader(\"Verify Batch Status\")\n\n# Read batch details\nbatch = read_batch(grouping_batch_id)\n\nbatch_info = [\n    [\"Batch ID\", batch['id']],\n    [\"Batch Type\", batch['batch_type']],\n    [\"Status\", batch['status']],\n    [\"Created\", batch['created_ts'].strftime('%Y-%m-%d %H:%M:%S')]\n]\nux.table(batch_info, headers=[\"Property\", \"Value\"])\n\n# Get jobs in batch\njobs = get_batch_jobs(grouping_batch_id)\njob_count = len(jobs)\n\nux.info(f\"\\nTotal jobs: {job_count}\")\n\n# Check entity existence for FINISHED jobs to show what will be resubmitted\nfrom helpers.entity_validator import EntityValidator\nfrom helpers.constants import JobStatus\n\nvalidator = EntityValidator()\n\n# Categorize jobs by status and entity existence\npending_jobs = []      # INITIATED jobs - will be submitted\nskipped_jobs = []      # FINISHED jobs where entity still exists - will be skipped\nresubmit_jobs = []     # FINISHED jobs where entity is missing - will be resubmitted\nother_jobs = []        # Jobs in other states (SUBMITTED, RUNNING, etc.)\n\nfor job in jobs:\n    config_query = \"SELECT job_configuration_data FROM irp_job_configuration WHERE id = %s\"\n    config_result = execute_query(config_query, (job['job_configuration_id'],))\n    config_data = config_result.iloc[0]['job_configuration_data'] if not config_result.empty else {}\n    group_name = config_data.get('Group_Name', 'N/A')\n    items_count = len(config_data.get('items', []))\n    display_name = f\"{group_name} ({items_count} analyses)\"\n    \n    if job['status'] == JobStatus.INITIATED:\n        pending_jobs.append(display_name)\n    elif job['status'] == JobStatus.FINISHED:\n        entity_exists = validator.check_entity_exists_for_job(config_data, batch['batch_type'])\n        if entity_exists:\n            skipped_jobs.append(display_name)\n        else:\n            resubmit_jobs.append(display_name)\n    else:\n        other_jobs.append((display_name, job['status']))\n\n# Display categorized job summary\nux.subheader(\"Job Summary\")\n\nif pending_jobs:\n    ux.info(f\"\\nðŸ†• Jobs to submit ({len(pending_jobs)}):\")\n    for name in pending_jobs[:10]:\n        ux.info(f\"  â€¢ {name}\")\n    if len(pending_jobs) > 10:\n        ux.info(f\"  ... and {len(pending_jobs) - 10} more\")\n\nif resubmit_jobs:\n    ux.warning(f\"\\nðŸ”„ Jobs to resubmit - group missing ({len(resubmit_jobs)}):\")\n    for name in resubmit_jobs[:10]:\n        ux.warning(f\"  â€¢ {name}\")\n    if len(resubmit_jobs) > 10:\n        ux.warning(f\"  ... and {len(resubmit_jobs) - 10} more\")\n\nif skipped_jobs:\n    ux.success(f\"\\nâœ“ Jobs to skip - group exists ({len(skipped_jobs)}):\")\n    for name in skipped_jobs[:10]:\n        ux.success(f\"  â€¢ {name}\")\n    if len(skipped_jobs) > 10:\n        ux.success(f\"  ... and {len(skipped_jobs) - 10} more\")\n\nif other_jobs:\n    ux.info(f\"\\nâ³ Jobs in progress ({len(other_jobs)}):\")\n    for name, status in other_jobs[:5]:\n        ux.info(f\"  â€¢ {name} ({status})\")\n\n# Summary line\ntotal_to_process = len(pending_jobs) + len(resubmit_jobs)\nux.info(f\"\\nðŸ“Š Summary: {total_to_process} job(s) will be submitted, {len(skipped_jobs)} will be skipped\")\n\n# Validate batch before submission\nux.subheader(\"Validate Batch\")\nvalidation_messages = validate_batch(grouping_batch_id)\n\n# Separate warnings from errors - warnings start with \"WARN-\"\nvalidation_warnings = [m for m in validation_messages if m.startswith(\"WARN-\")]\nvalidation_errors = [m for m in validation_messages if not m.startswith(\"WARN-\")]\n\nif validation_warnings:\n    ux.warning(\"âš  Validation warnings (submission will proceed):\")\n    for warning in validation_warnings:\n        ux.warning(f\"  {warning}\")\n    step.log(f\"Validation warnings: {len(validation_warnings)}\")\n\nif validation_errors:\n    validation_failed = True\n    ux.error(\"âœ— Batch validation failed:\")\n    for error in validation_errors:\n        ux.error(f\"  {error}\")\n    step.log(f\"Batch validation failed: {len(validation_errors)} error(s)\")\nelif not validation_warnings:\n    ux.success(\"âœ“ Batch validation passed\")\n    step.log(f\"Verified batch: {total_to_process} jobs to submit, {len(skipped_jobs)} to skip\")\nelse:\n    ux.success(\"âœ“ Batch validation passed (with warnings)\")\n    step.log(f\"Verified batch: {total_to_process} jobs to submit, {len(skipped_jobs)} to skip (with {len(validation_warnings)} warning(s))\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "d91n5ejnfkv",
   "source": "## 4) Submit Grouping Batch to Moody's",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "yg7ok9mu2z",
   "source": "# Submit batch to Moody's API\nif validation_failed:\n    ux.warning(\"â­ Skipping submission due to validation failure\")\n    result = None\n    failed_count = 0\nelse:\n    ux.subheader(\"Submit Batch to Moody's\")\n\n    ux.info(\"\")\n    ux.info(\"Submission Process:\")\n    ux.info(\"  - Each job will group the specified analysis results\")\n    ux.info(\"  - Analysis names in the group will be resolved to analysis URIs\")\n    ux.info(\"  - Grouped results will be created in Moody's Risk Modeler\")\n    ux.info(\"  - Jobs will transition to SUBMITTED status\")\n    ux.info(\"  - Batch will transition to ACTIVE status\")\n    ux.info(\"\")\n\n    # Submit\n    ux.info(\"\\nSubmitting batch...\")\n\n    # Pass step.step_id to associate batch with this step (not the creation step)\n    result = submit_batch(grouping_batch_id, IRPClient(), step_id=step.step_id)\n\n    # Display results\n    ux.success(f\"\\nBatch submission completed\")\n    ux.info(f\"  Submitted: {result['submitted_jobs']} jobs\")\n    ux.info(f\"  Status: {result['batch_status']}\")\n\n    # Check for errors\n    failed_count = len([j for j in result['jobs'] if 'error' in j])\n    if failed_count > 0:\n        ux.warning(f\"\\n{failed_count} job(s) failed to submit\")\n        for job_result in result['jobs']:\n            if 'error' in job_result:\n                ux.error(f\"  Job {job_result['job_id']}: {job_result['error']}\")\n\n    step.log(f\"Batch submitted: {result['submitted_jobs']} jobs, {failed_count} failed\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "w1cblgl8jjd",
   "source": "## 5) Complete Step Execution",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "e71vaq74868",
   "source": "# Complete step execution\nux.header(\"Step Completion\")\n\nif validation_failed:\n    # Handle validation failure\n    from helpers.step import update_step_run\n    from helpers.constants import StepStatus\n    \n    error_message = \"\\n\".join(validation_errors)\n    update_step_run(step.run_id, StepStatus.FAILED, error_message=error_message)\n    \n    ux.error(\"\\n\" + \"=\"*60)\n    ux.error(\"BATCH VALIDATION FAILED\")\n    ux.error(\"=\"*60)\n    ux.info(f\"\\nBatch ID: {grouping_batch_id}\")\n    ux.error(f\"\\nValidation errors ({len(validation_errors)}):\")\n    for error in validation_errors:\n        ux.error(f\"  {error}\")\n    ux.info(\"\\nPlease fix the validation errors and retry.\")\n\nelif failed_count > 0:\n    # Handle submission failures\n    failed_job_errors = [\n        f\"Job {j['job_id']}: {j['error']}\" \n        for j in result['jobs'] if 'error' in j\n    ]\n    error_message = f\"{failed_count} job(s) failed to submit:\\n\" + \"\\n\".join(failed_job_errors)\n    \n    from helpers.step import update_step_run\n    from helpers.constants import StepStatus\n    update_step_run(step.run_id, StepStatus.FAILED, error_message=error_message)\n    \n    ux.error(\"\\n\" + \"=\"*60)\n    ux.error(\"BATCH SUBMISSION FAILED\")\n    ux.error(\"=\"*60)\n    ux.info(f\"\\nBatch ID: {grouping_batch_id}\")\n    ux.info(f\"Submitted: {result['submitted_jobs']} job(s)\")\n    ux.error(f\"Failed: {failed_count} job(s)\")\n    ux.info(\"\\nFailed jobs:\")\n    for error in failed_job_errors:\n        ux.error(f\"  {error}\")\n    ux.info(\"\\nPlease review the errors and resubmit failed jobs.\")\n\nelse:\n    # Complete the step successfully\n    output_data = {\n        'batch_id': grouping_batch_id,\n        'batch_type': batch['batch_type'],\n        'batch_status': result['batch_status'],\n        'submitted_jobs': result['submitted_jobs'],\n        'failed_jobs': failed_count\n    }\n    step.complete(output_data)\n\n    ux.success(\"\\n\" + \"=\"*60)\n    ux.success(\"GROUPING BATCH (ANALYSIS-ONLY) SUBMITTED SUCCESSFULLY\")\n    ux.success(\"=\"*60)\n    ux.info(f\"\\nSubmitted {result['submitted_jobs']} job(s) to Moody's API\")\n    ux.info(f\"Batch status: {result['batch_status']}\")\n    ux.info(\"\\nNext steps:\")\n    ux.info(\"  - Monitor job progress\")\n    ux.info(\"  - If you have rollup groups: Run Step_02_Group_Rollup.ipynb\")\n    ux.info(\"  - Otherwise: Proceed to Export stage\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}