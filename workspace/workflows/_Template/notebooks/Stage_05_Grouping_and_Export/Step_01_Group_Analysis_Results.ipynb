{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0c72b1a",
   "metadata": {},
   "source": "# Step 01: Group Analysis Results (Analysis-only Groups)\n\nThis notebook submits analysis grouping jobs to Moody's Risk Modeler for **analysis-only groups**.\n\nAnalysis-only groups contain ONLY analysis names (no references to other groups).\n\n**Tasks:**\n- Retrieve Grouping batch from Stage_01/Step_03\n- Review grouping job configurations\n- Submit grouping jobs to Moody's API\n- Track job completion status\n\n**Note:** If you have groups that contain OTHER groups (rollup groups), those are handled separately in Step_02_Group_Rollup.ipynb."
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "id": "4af9ee11",
   "metadata": {},
   "outputs": [],
   "source": "## 1) Setup"
  },
  {
   "cell_type": "code",
   "id": "wp316yt12gf",
   "source": "%load_ext autoreload\n%autoreload 2\n\nfrom helpers.notebook_setup import initialize_notebook_context\nfrom helpers import ux\nfrom helpers.batch import get_batch_jobs, read_batch, activate_batch, update_batch_step\nfrom helpers.database import execute_query\nfrom helpers.irp_integration import IRPClient\nfrom helpers.constants import BatchType, JobStatus\n\n# Flags to track state\nvalidation_failed = False\nvalidation_errors = []\nexisting_groups = set()  # Set of group names that already exist",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "4ej9v0v5rkp",
   "source": "# Initialize notebook context and step tracking\ncontext, step = initialize_notebook_context('Step_01_Group_Analysis_Results.ipynb')\n\n# Display context\nux.header(\"Group Analysis Results Batch (Analysis-only Groups)\")\nux.info(f\"Cycle: {context.cycle_name}\")\nux.info(f\"Stage: {context.stage_name}\")\nux.info(f\"Step: {context.step_name}\")\nux.success(f\"Step tracking initialized for '{context.step_name}'\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "rskp2iaalc8",
   "source": "## 2) Retrieve Grouping Batch",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "o3s77ulvu7r",
   "source": "# Retrieve Grouping batch from Stage_01/Step_03\nux.subheader(\"Retrieve Grouping Batch\")\n\nquery = \"\"\"\n    SELECT sr.id, sr.step_id, sr.run_num, sr.output_data, sr.completed_ts\n    FROM irp_step_run sr\n    INNER JOIN irp_step s ON sr.step_id = s.id\n    INNER JOIN irp_stage sg ON s.stage_id = sg.id\n    INNER JOIN irp_cycle c ON sg.cycle_id = c.id\n    WHERE c.cycle_name = %s\n      AND sg.stage_num = 1\n      AND s.step_num = 3\n      AND sr.status = 'COMPLETED'\n    ORDER BY sr.completed_ts DESC\n    LIMIT 1\n\"\"\"\n\nresult = execute_query(query, (context.cycle_name,))\n\nif result.empty:\n    raise ValueError(\"Batch creation step not found - please complete Stage_01/Step_03 first\")\n\noutput_data = result.iloc[0]['output_data']\nbatches = output_data.get('batches', {})\n\nif BatchType.GROUPING not in batches:\n    raise ValueError(f\"Grouping batch not found. Available: {list(batches.keys())}\")\n\ngrouping_batch_id = int(batches[BatchType.GROUPING])\nux.success(f\"Retrieved Grouping batch: ID={grouping_batch_id}\")\nstep.log(f\"Retrieved Grouping batch: ID={grouping_batch_id}\")\n\n# Validate batch using EntityValidator directly to get structured output\nfrom helpers.entity_validator import EntityValidator\n\nux.subheader(\"Validate Batch\")\n\n# Get job configurations for validation\njobs = get_batch_jobs(grouping_batch_id)\ngroupings = []\nfor job in jobs:\n    config_query = \"SELECT job_configuration_data FROM irp_job_configuration WHERE id = %s\"\n    config_result = execute_query(config_query, (job['job_configuration_id'],))\n    if not config_result.empty:\n        groupings.append(config_result.iloc[0]['job_configuration_data'])\n\n# Run validation - returns (messages, existing_groups_list)\nvalidator = EntityValidator()\nall_messages, existing_groups_list = validator.validate_grouping_batch(groupings)\nexisting_groups = set(existing_groups_list)  # Convert to set for easy lookup\n\n# Separate pre-requisite errors from \"groups exist\" errors\n# ENT-GROUP-001 is the code for \"groups already exist\" - this is recoverable\nprereq_errors = [e for e in all_messages if \"ENT-GROUP-001\" not in e and not e.startswith(\"WARN-\")]\nwarnings = [e for e in all_messages if e.startswith(\"WARN-\")]\n\nif prereq_errors:\n    validation_failed = True\n    ux.error(\"Pre-requisite validation failed:\")\n    for error in prereq_errors:\n        ux.error(f\"  {error}\")\n    step.log(f\"Pre-requisite validation failed: {len(prereq_errors)} error(s)\")\nelif existing_groups:\n    ux.warning(f\"Found {len(existing_groups)} existing group(s) - will prompt for action\")\n    if warnings:\n        for w in warnings:\n            ux.warning(f\"  {w}\")\n    ux.success(\"Pre-requisite validation passed\")\nelse:\n    if warnings:\n        for w in warnings:\n            ux.warning(f\"  {w}\")\n    ux.success(\"Batch validation passed\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "tadk4fhcg0b",
   "source": "## 3) Build Submission Plan\n\nDetermine action for each job based on status and whether group exists.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "n8ddbk9w4jf",
   "source": "# Build submission plan based on whether groups exist\n#\n# Core question: Which groups are missing and need to be created?\n# - Missing group → Need to create (submit/resubmit based on job status)\n# - Existing group → Already done, but offer option to delete and re-run\n\n# Categorize jobs by whether group exists\njobs_missing_group = []   # Group doesn't exist - need to create\njobs_with_group = []      # Group exists - already done\njobs_in_progress = []     # Currently running - skip\n\nIN_PROGRESS_STATUSES = {JobStatus.SUBMITTED, JobStatus.QUEUED, JobStatus.PENDING, JobStatus.RUNNING}\n\nirp_client = IRPClient()\n\nif validation_failed:\n    ux.warning(\"Skipping submission plan due to validation failure\")\nelse:\n    ux.subheader(\"Build Submission Plan\")\n\n    for job in jobs:\n        config_query = \"SELECT job_configuration_data FROM irp_job_configuration WHERE id = %s\"\n        config_result = execute_query(config_query, (job['job_configuration_id'],))\n        config = config_result.iloc[0]['job_configuration_data'] if not config_result.empty else {}\n\n        group_name = config.get('Group_Name', '')\n        items_count = len(config.get('items', []))\n        group_exists = group_name in existing_groups\n\n        job_info = {\n            'job_id': job['id'],\n            'status': job['status'],\n            'group_name': group_name,\n            'items_count': items_count\n        }\n\n        if job['status'] in IN_PROGRESS_STATUSES:\n            jobs_in_progress.append(job_info)\n        elif group_exists:\n            jobs_with_group.append(job_info)\n        else:\n            jobs_missing_group.append(job_info)\n\n    # Display summary\n    ux.info(f\"Total jobs: {len(jobs)}\")\n\n    if jobs_missing_group:\n        ux.warning(f\"  Missing Moody's group: {len(jobs_missing_group)}\")\n    if jobs_with_group:\n        ux.success(f\"  Moody's group exists: {len(jobs_with_group)}\")\n    if jobs_in_progress:\n        ux.info(f\"  In progress: {len(jobs_in_progress)}\")\n\n# Determine if this is a fresh run (all missing + all INITIATED = no prompts needed)\nis_fresh_run = (\n    not validation_failed\n    and len(jobs_missing_group) > 0\n    and len(jobs_with_group) == 0\n    and len(jobs_in_progress) == 0\n    and all(j['status'] == JobStatus.INITIATED for j in jobs_missing_group)\n)\n\n# Jobs to process\njobs_to_create = []      # Jobs where we'll create the group\njobs_to_delete = []      # Jobs where we'll delete existing group and re-run\n\nif validation_failed:\n    pass  # Skip all processing\n\nelif is_fresh_run:\n    # Fresh run - all jobs are INITIATED with no existing groups\n    ux.success(\"\\nFresh run - all groups will be created.\")\n    jobs_to_create = jobs_missing_group\n\nelse:\n    # Need user input for missing and/or existing groups\n\n    # Prompt for missing groups (if any, and not all INITIATED)\n    if jobs_missing_group:\n        ux.info(\"\\n\" + \"-\"*50)\n        ux.warning(f\"Missing Moody's groups ({len(jobs_missing_group)}):\")\n        for j in jobs_missing_group[:10]:\n            ux.warning(f\"  - {j['group_name']} ({j['items_count']} analyses, job: {j['status']})\")\n        if len(jobs_missing_group) > 10:\n            ux.warning(f\"  ... and {len(jobs_missing_group) - 10} more\")\n\n        choice = input(f\"\\nCreate these {len(jobs_missing_group)} missing group(s)? (y/n): \").strip().lower()\n        if choice in ['y', 'yes']:\n            jobs_to_create = jobs_missing_group\n            ux.success(\"Will create missing groups in Moody's.\")\n        else:\n            ux.info(\"Skipping missing groups.\")\n\n    # Prompt for existing groups (if any)\n    if jobs_with_group:\n        ux.info(\"\\n\" + \"-\"*50)\n        ux.success(f\"Existing groups ({len(jobs_with_group)}):\")\n        for j in jobs_with_group[:10]:\n            ux.success(f\"  - {j['group_name']} ({j['items_count']} analyses, job: {j['status']})\")\n        if len(jobs_with_group) > 10:\n            ux.success(f\"  ... and {len(jobs_with_group) - 10} more\")\n\n        choice = input(f\"\\nDelete and re-create these {len(jobs_with_group)} existing group(s)? (y/n): \").strip().lower()\n        if choice in ['y', 'yes']:\n            jobs_to_delete = jobs_with_group\n            ux.warning(\"Will delete and re-create existing groups.\")\n        else:\n            ux.success(\"Keeping existing groups.\")\n\n    # Handle case where nothing to do\n    if not jobs_to_create and not jobs_to_delete:\n        if jobs_in_progress:\n            ux.info(\"\\nNo action needed - jobs are in progress.\")\n        elif jobs_with_group and not jobs_missing_group:\n            ux.success(\"\\nAll groups already exist.\")\n\nstep.log(f\"Plan: create={len(jobs_to_create)}, delete_and_recreate={len(jobs_to_delete)}, in_progress={len(jobs_in_progress)}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "d91n5ejnfkv",
   "source": "## 4) Submit Grouping Batch to Moody's",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "yg7ok9mu2z",
   "source": "# Execute the submission plan\nfrom helpers.job import resubmit_job, submit_job, delete_groups_for_jobs\n\nux.subheader(\"Submit Groups to Moody's\")\n\ndeletion_errors = []\nsubmission_results = []\nfailed_count = 0\n\nif validation_failed:\n    ux.warning(\"Skipping submission due to validation failure\")\n    result = {'submitted_jobs': 0, 'batch_status': 'INITIATED', 'jobs': []}\n\nelif not jobs_to_create and not jobs_to_delete:\n    ux.info(\"No jobs to submit.\")\n    batch = read_batch(grouping_batch_id)\n    result = {'submitted_jobs': 0, 'batch_status': batch['status'], 'jobs': []}\n\nelse:\n    # Step 1: Delete existing groups for jobs_to_delete\n    if jobs_to_delete:\n        ux.info(f\"\\nDeleting {len(jobs_to_delete)} existing group(s)...\")\n\n        # delete_groups_for_jobs expects list of dicts with 'group_name' key\n        deletion_errors = delete_groups_for_jobs(jobs_to_delete, irp_client)\n\n        if deletion_errors:\n            ux.error(f\"  Failed to delete {len(deletion_errors)} group(s):\")\n            for err in deletion_errors:\n                ux.error(f\"    - {err}\")\n        else:\n            ux.success(f\"  Deleted {len(jobs_to_delete)} group(s)\")\n\n    # Step 2: Submit/resubmit jobs\n    if deletion_errors:\n        ux.error(\"\\nCannot proceed with submission due to deletion failures.\")\n        result = {'submitted_jobs': 0, 'batch_status': 'INITIATED', 'jobs': []}\n    else:\n        all_jobs_to_process = jobs_to_create + jobs_to_delete\n        ux.info(f\"\\nSubmitting {len(all_jobs_to_process)} job(s)...\")\n\n        for job_info in all_jobs_to_process:\n            job_id = job_info['job_id']\n            status = job_info['status']\n\n            try:\n                if status == JobStatus.INITIATED:\n                    # Fresh job - submit directly\n                    submit_job(job_id, BatchType.GROUPING, irp_client)\n                    submission_results.append({'job_id': job_id, 'action': 'submitted'})\n                    ux.info(f\"  Submitted: {job_info['group_name']}\")\n                else:\n                    # Terminal job - resubmit (creates new job and submits it)\n                    new_job_id = resubmit_job(job_id, irp_client, BatchType.GROUPING)\n                    submission_results.append({'job_id': new_job_id, 'action': 'resubmitted', 'original_job_id': job_id})\n                    ux.info(f\"  Resubmitted: {job_info['group_name']}\")\n            except Exception as e:\n                failed_count += 1\n                submission_results.append({'job_id': job_id, 'error': str(e)})\n                ux.error(f\"  Failed: {job_info['group_name']} - {e}\")\n\n        success_count = len(all_jobs_to_process) - failed_count\n\n        # Update batch status to ACTIVE if any jobs were submitted\n        if success_count > 0:\n            activate_batch(grouping_batch_id)\n            # Update batch step_id to this step (needed for step chaining)\n            update_batch_step(grouping_batch_id, step.step_id)\n            ux.success(f\"Batch {grouping_batch_id} activated\")\n\n        result = {\n            'submitted_jobs': success_count,\n            'batch_status': 'ACTIVE' if success_count > 0 else 'INITIATED',\n            'jobs': submission_results\n        }\n\n        ux.info(f\"\\nSubmission complete: {success_count} succeeded, {failed_count} failed\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "w1cblgl8jjd",
   "source": "## 5) Complete Step Execution",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "e71vaq74868",
   "source": "# Complete step execution\nux.header(\"Step Completion\")\n\n# Prepare output data\noutput_data = {\n    'batch_id': grouping_batch_id,\n    'batch_type': BatchType.GROUPING,\n    'batch_status': result['batch_status'],\n    'submitted_jobs': result['submitted_jobs'],\n    'failed_jobs': failed_count,\n    'deletion_errors': len(deletion_errors) if deletion_errors else 0\n}\n\nif validation_failed:\n    # Handle validation failure\n    from helpers.step import update_step_run\n    from helpers.constants import StepStatus\n\n    error_message = \"\\n\".join(prereq_errors)\n    update_step_run(step.run_id, StepStatus.FAILED, error_message=error_message)\n\n    ux.error(\"\\n\" + \"=\"*60)\n    ux.error(\"VALIDATION FAILED\")\n    ux.error(\"=\"*60)\n    for error in prereq_errors:\n        ux.error(f\"  {error}\")\n\nelif deletion_errors:\n    # Handle deletion failure\n    from helpers.step import update_step_run\n    from helpers.constants import StepStatus\n\n    error_message = f\"{len(deletion_errors)} group deletion(s) failed:\\n\" + \"\\n\".join(deletion_errors)\n    update_step_run(step.run_id, StepStatus.FAILED, error_message=error_message)\n\n    ux.error(\"\\n\" + \"=\"*60)\n    ux.error(\"GROUP DELETION FAILED\")\n    ux.error(\"=\"*60)\n    ux.info(f\"\\nBatch ID: {grouping_batch_id}\")\n    ux.error(f\"Failed deletions: {len(deletion_errors)}\")\n    ux.info(\"\\nPlease manually delete these groups in Moody's Risk Modeler,\")\n    ux.info(\"then re-run this notebook.\")\n\nelif failed_count > 0:\n    # Handle submission failures\n    from helpers.step import update_step_run\n    from helpers.constants import StepStatus\n\n    failed_job_errors = [f\"Job {j['job_id']}: {j['error']}\" for j in submission_results if 'error' in j]\n    error_message = f\"{failed_count} job(s) failed to submit:\\n\" + \"\\n\".join(failed_job_errors)\n    update_step_run(step.run_id, StepStatus.FAILED, error_message=error_message)\n\n    ux.error(\"\\n\" + \"=\"*60)\n    ux.error(\"BATCH SUBMISSION FAILED\")\n    ux.error(\"=\"*60)\n    ux.info(f\"\\nBatch ID: {grouping_batch_id}\")\n    ux.info(f\"Submitted: {result['submitted_jobs']} job(s)\")\n    ux.error(f\"Failed: {failed_count} job(s)\")\n    for error in failed_job_errors:\n        ux.error(f\"  {error}\")\n\nelse:\n    # Success\n    step.complete(output_data)\n\n    ux.success(\"\\n\" + \"=\"*60)\n    if result['submitted_jobs'] == 0:\n        ux.success(\"STEP COMPLETED - NO SUBMISSION NEEDED\")\n    else:\n        ux.success(\"GROUPING BATCH SUBMITTED SUCCESSFULLY\")\n    ux.success(\"=\"*60)\n    ux.info(f\"\\nBatch ID: {grouping_batch_id}\")\n    ux.info(f\"Submitted: {result['submitted_jobs']} job(s)\")\n    ux.info(f\"Batch status: {result['batch_status']}\")\n    ux.info(\"\\nNext: Monitor job progress or proceed to next step\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}