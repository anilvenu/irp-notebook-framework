{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c401ea2",
   "metadata": {},
   "source": [
    "# Step 01: Execute Analysis\n",
    "\n",
    "This notebook submits analysis jobs to Moody's Risk Modeler.\n",
    "\n",
    "**Tasks:**\n",
    "- Retrieve Analysis batch from Stage_01/Step_03\n",
    "- Review analysis job configurations\n",
    "- Submit analysis jobs to Moody's API\n",
    "- Track job completion status"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6qp37wipth8",
   "metadata": {},
   "source": [
    "## 1) Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4v2su4d26l",
   "metadata": {},
   "outputs": [],
   "source": "%load_ext autoreload\n%autoreload 2\n\nfrom helpers.notebook_setup import initialize_notebook_context\nfrom helpers import ux\nfrom helpers.batch import get_batch_jobs, read_batch, activate_batch\nfrom helpers.database import execute_query\nfrom helpers.irp_integration import IRPClient\nfrom helpers.constants import BatchType, JobStatus\n\n# Flags to track state\nvalidation_failed = False\nvalidation_errors = []\nexisting_analyses = set()  # Set of \"EDM/AnalysisName\" that already exist"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pdj01sne68j",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize notebook context and step tracking\n",
    "context, step = initialize_notebook_context('Step_01_Execute_Analysis.ipynb')\n",
    "\n",
    "# Display context\n",
    "ux.header(\"Execute Analysis Batch\")\n",
    "ux.info(f\"Cycle: {context.cycle_name}\")\n",
    "ux.info(f\"Stage: {context.stage_name}\")\n",
    "ux.info(f\"Step: {context.step_name}\")\n",
    "ux.success(f\"Step tracking initialized for '{context.step_name}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fykytjfak95",
   "metadata": {},
   "source": [
    "## 2) Retrieve Analysis Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5r01087u4i4",
   "metadata": {},
   "outputs": [],
   "source": "# Retrieve Analysis batch from Stage_01/Step_03\nux.subheader(\"Retrieve Analysis Batch\")\n\nquery = \"\"\"\n    SELECT sr.id, sr.step_id, sr.run_num, sr.output_data, sr.completed_ts\n    FROM irp_step_run sr\n    INNER JOIN irp_step s ON sr.step_id = s.id\n    INNER JOIN irp_stage sg ON s.stage_id = sg.id\n    INNER JOIN irp_cycle c ON sg.cycle_id = c.id\n    WHERE c.cycle_name = %s\n      AND sg.stage_num = 1\n      AND s.step_num = 3\n      AND sr.status = 'COMPLETED'\n    ORDER BY sr.completed_ts DESC\n    LIMIT 1\n\"\"\"\n\nresult = execute_query(query, (context.cycle_name,))\n\nif result.empty:\n    raise ValueError(\"Batch creation step not found - please complete Stage_01/Step_03 first\")\n\noutput_data = result.iloc[0]['output_data']\nbatches = output_data.get('batches', {})\n\nif BatchType.ANALYSIS not in batches:\n    raise ValueError(f\"Analysis batch not found. Available: {list(batches.keys())}\")\n\nanalysis_batch_id = int(batches[BatchType.ANALYSIS])\nux.success(f\"Retrieved Analysis batch: ID={analysis_batch_id}\")\nstep.log(f\"Retrieved Analysis batch: ID={analysis_batch_id}\")\n\n# Validate batch using EntityValidator directly to get structured output\nfrom helpers.entity_validator import EntityValidator\n\nux.subheader(\"Validate Batch\")\n\n# Get job configurations for validation\njobs = get_batch_jobs(analysis_batch_id)\nanalyses = []\nfor job in jobs:\n    config_query = \"SELECT job_configuration_data FROM irp_job_configuration WHERE id = %s\"\n    config_result = execute_query(config_query, (job['job_configuration_id'],))\n    if not config_result.empty:\n        analyses.append(config_result.iloc[0]['job_configuration_data'])\n\n# Run validation - returns (errors, existing_analyses_list)\nvalidator = EntityValidator()\nall_errors, existing_analyses_list = validator.validate_analysis_batch(analyses)\nexisting_analyses = set(existing_analyses_list)  # Convert to set for easy lookup\n\n# Separate pre-requisite errors from \"analyses exist\" errors\n# ENT-ANALYSIS-001 is the code for \"analyses already exist\" - this is recoverable\nprereq_errors = [e for e in all_errors if \"ENT-ANALYSIS-001\" not in e]\n\nif prereq_errors:\n    validation_failed = True\n    ux.error(\"Pre-requisite validation failed:\")\n    for error in prereq_errors:\n        ux.error(f\"  {error}\")\n    step.log(f\"Pre-requisite validation failed: {len(prereq_errors)} error(s)\")\nelif existing_analyses:\n    ux.warning(f\"Found {len(existing_analyses)} existing analysis(es) - will prompt for action\")\n    ux.success(\"Pre-requisite validation passed\")\nelse:\n    ux.success(\"Batch validation passed\")"
  },
  {
   "cell_type": "markdown",
   "id": "wrebi0s4agr",
   "metadata": {},
   "source": [
    "## 3) Build Submission Plan\n",
    "\n",
    "Determine action for each job based on status and whether analysis exists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ulap2i72x1q",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build submission plan based on whether analyses exist\n",
    "# \n",
    "# Core question: Which analyses are missing and need to be created?\n",
    "# - Missing analysis → Need to create (submit/resubmit based on job status)\n",
    "# - Existing analysis → Already done, but offer option to delete and re-run\n",
    "\n",
    "# Categorize jobs by whether analysis exists\n",
    "jobs_missing_analysis = []  # Analysis doesn't exist - need to create\n",
    "jobs_with_analysis = []     # Analysis exists - already done\n",
    "jobs_in_progress = []       # Currently running - skip\n",
    "\n",
    "IN_PROGRESS_STATUSES = {JobStatus.SUBMITTED, JobStatus.QUEUED, JobStatus.PENDING, JobStatus.RUNNING}\n",
    "\n",
    "irp_client = IRPClient()\n",
    "\n",
    "if validation_failed:\n",
    "    ux.warning(\"Skipping submission plan due to validation failure\")\n",
    "else:\n",
    "    ux.subheader(\"Build Submission Plan\")\n",
    "    \n",
    "    for job in jobs:\n",
    "        config_query = \"SELECT job_configuration_data FROM irp_job_configuration WHERE id = %s\"\n",
    "        config_result = execute_query(config_query, (job['job_configuration_id'],))\n",
    "        config = config_result.iloc[0]['job_configuration_data'] if not config_result.empty else {}\n",
    "        \n",
    "        edm = config.get('Database', '')\n",
    "        analysis_name = config.get('Analysis Name', '')\n",
    "        analysis_key = f\"{edm}/{analysis_name}\"\n",
    "        analysis_exists = analysis_key in existing_analyses\n",
    "        \n",
    "        job_info = {\n",
    "            'job_id': job['id'],\n",
    "            'status': job['status'],\n",
    "            'edm': edm,\n",
    "            'analysis_name': analysis_name,\n",
    "            'analysis_key': analysis_key\n",
    "        }\n",
    "        \n",
    "        if job['status'] in IN_PROGRESS_STATUSES:\n",
    "            jobs_in_progress.append(job_info)\n",
    "        elif analysis_exists:\n",
    "            jobs_with_analysis.append(job_info)\n",
    "        else:\n",
    "            jobs_missing_analysis.append(job_info)\n",
    "    \n",
    "    # Display summary\n",
    "    ux.info(f\"Total jobs: {len(jobs)}\")\n",
    "    \n",
    "    if jobs_missing_analysis:\n",
    "        ux.warning(f\"  Missing Moody's analysis: {len(jobs_missing_analysis)}\")\n",
    "    if jobs_with_analysis:\n",
    "        ux.success(f\"  Moody's analysis exists: {len(jobs_with_analysis)}\")\n",
    "    if jobs_in_progress:\n",
    "        ux.info(f\"  In progress: {len(jobs_in_progress)}\")\n",
    "\n",
    "# Determine if this is a fresh run (all missing + all INITIATED = no prompts needed)\n",
    "is_fresh_run = (\n",
    "    not validation_failed\n",
    "    and len(jobs_missing_analysis) > 0\n",
    "    and len(jobs_with_analysis) == 0\n",
    "    and len(jobs_in_progress) == 0\n",
    "    and all(j['status'] == JobStatus.INITIATED for j in jobs_missing_analysis)\n",
    ")\n",
    "\n",
    "# Jobs to process\n",
    "jobs_to_create = []      # Jobs where we'll create the analysis\n",
    "jobs_to_delete = []      # Jobs where we'll delete existing analysis and re-run\n",
    "\n",
    "if validation_failed:\n",
    "    pass  # Skip all processing\n",
    "\n",
    "elif is_fresh_run:\n",
    "    # Fresh run - all jobs are INITIATED with no existing analyses\n",
    "    ux.success(\"\\nFresh run - all analyses will be created.\")\n",
    "    jobs_to_create = jobs_missing_analysis\n",
    "\n",
    "else:\n",
    "    # Need user input for missing and/or existing analyses\n",
    "    \n",
    "    # Prompt for missing analyses (if any, and not all INITIATED)\n",
    "    if jobs_missing_analysis:\n",
    "        ux.info(\"\\n\" + \"-\"*50)\n",
    "        ux.warning(f\"Missing Moody's analyses ({len(jobs_missing_analysis)}):\")\n",
    "        for j in jobs_missing_analysis:\n",
    "            ux.warning(f\"  - {j['analysis_name']} (job: {j['status']})\")\n",
    "        \n",
    "        choice = input(f\"\\nCreate these {len(jobs_missing_analysis)} missing analysis(es)? (y/n): \").strip().lower()\n",
    "        if choice in ['y', 'yes']:\n",
    "            jobs_to_create = jobs_missing_analysis\n",
    "            ux.success(\"Will create missing analyses in Moody's.\")\n",
    "        else:\n",
    "            ux.info(\"Skipping missing analyses.\")\n",
    "    \n",
    "    # Prompt for existing analyses (if any)\n",
    "    if jobs_with_analysis:\n",
    "        ux.info(\"\\n\" + \"-\"*50)\n",
    "        ux.success(f\"Existing analyses ({len(jobs_with_analysis)}):\")\n",
    "        for j in jobs_with_analysis:\n",
    "            ux.success(f\"  - {j['analysis_name']} (job: {j['status']})\")\n",
    "        \n",
    "        choice = input(f\"\\nDelete and re-run these {len(jobs_with_analysis)} existing analysis(es)? (y/n): \").strip().lower()\n",
    "        if choice in ['y', 'yes']:\n",
    "            jobs_to_delete = jobs_with_analysis\n",
    "            ux.warning(\"Will delete and re-run existing analyses.\")\n",
    "        else:\n",
    "            ux.success(\"Keeping existing analyses.\")\n",
    "\n",
    "    # Handle case where nothing to do\n",
    "    if not jobs_to_create and not jobs_to_delete:\n",
    "        if jobs_in_progress:\n",
    "            ux.info(\"\\nNo action needed - jobs are in progress.\")\n",
    "        elif jobs_with_analysis and not jobs_missing_analysis:\n",
    "            ux.success(\"\\nAll analyses already exist.\")\n",
    "\n",
    "step.log(f\"Plan: create={len(jobs_to_create)}, delete_and_rerun={len(jobs_to_delete)}, in_progress={len(jobs_in_progress)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ai75qtfzf5",
   "metadata": {},
   "source": [
    "## 4) Submit Analysis Batch to Moody's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "npui3uxx0ds",
   "metadata": {},
   "outputs": [],
   "source": "# Execute the submission plan\nfrom helpers.job import resubmit_job, submit_job, delete_analyses_for_jobs\n\nux.subheader(\"Submit Analyses to Moody's\")\n\ndeletion_errors = []\nsubmission_results = []\nfailed_count = 0\n\nif validation_failed:\n    ux.warning(\"Skipping submission due to validation failure\")\n    result = {'submitted_jobs': 0, 'batch_status': 'INITIATED', 'jobs': []}\n\nelif not jobs_to_create and not jobs_to_delete:\n    ux.info(\"No jobs to submit.\")\n    batch = read_batch(analysis_batch_id)\n    result = {'submitted_jobs': 0, 'batch_status': batch['status'], 'jobs': []}\n\nelse:\n    # Step 1: Delete existing analyses for jobs_to_delete\n    if jobs_to_delete:\n        ux.info(f\"\\nDeleting {len(jobs_to_delete)} existing analysis(es)...\")\n        \n        deletion_errors = delete_analyses_for_jobs(\n            [j['job_id'] for j in jobs_to_delete],\n            existing_analyses,\n            irp_client\n        )\n        \n        if deletion_errors:\n            ux.error(f\"  Failed to delete {len(deletion_errors)} analysis(es):\")\n            for err in deletion_errors:\n                ux.error(f\"    - {err}\")\n        else:\n            ux.success(f\"  Deleted {len(jobs_to_delete)} analysis(es)\")\n    \n    # Step 2: Submit/resubmit jobs\n    if deletion_errors:\n        ux.error(\"\\nCannot proceed with submission due to deletion failures.\")\n        result = {'submitted_jobs': 0, 'batch_status': 'INITIATED', 'jobs': []}\n    else:\n        all_jobs_to_process = jobs_to_create + jobs_to_delete\n        ux.info(f\"\\nSubmitting {len(all_jobs_to_process)} job(s)...\")\n        \n        for job_info in all_jobs_to_process:\n            job_id = job_info['job_id']\n            status = job_info['status']\n            \n            try:\n                if status == JobStatus.INITIATED:\n                    # Fresh job - submit directly\n                    submit_job(job_id, BatchType.ANALYSIS, irp_client)\n                    submission_results.append({'job_id': job_id, 'action': 'submitted'})\n                    ux.info(f\"  Submitted: {job_info['analysis_name']}\")\n                else:\n                    # Terminal job - resubmit (creates new job and submits it)\n                    new_job_id = resubmit_job(job_id, irp_client, BatchType.ANALYSIS)\n                    submission_results.append({'job_id': new_job_id, 'action': 'resubmitted', 'original_job_id': job_id})\n                    ux.info(f\"  Resubmitted: {job_info['analysis_name']}\")\n            except Exception as e:\n                failed_count += 1\n                submission_results.append({'job_id': job_id, 'error': str(e)})\n                ux.error(f\"  Failed: {job_info['analysis_name']} - {e}\")\n        \n        success_count = len(all_jobs_to_process) - failed_count\n        \n        # Update batch status to ACTIVE if any jobs were submitted\n        if success_count > 0:\n            activate_batch(analysis_batch_id)\n            ux.success(f\"Batch {analysis_batch_id} activated\")\n        \n        result = {\n            'submitted_jobs': success_count,\n            'batch_status': 'ACTIVE' if success_count > 0 else 'INITIATED',\n            'jobs': submission_results\n        }\n        \n        ux.info(f\"\\nSubmission complete: {success_count} succeeded, {failed_count} failed\")"
  },
  {
   "cell_type": "markdown",
   "id": "cvp66q6gppn",
   "metadata": {},
   "source": [
    "## 5) Complete Step Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "u9rfsfbu45l",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete step execution\n",
    "ux.header(\"Step Completion\")\n",
    "\n",
    "# Prepare output data\n",
    "output_data = {\n",
    "    'batch_id': analysis_batch_id,\n",
    "    'batch_type': BatchType.ANALYSIS,\n",
    "    'batch_status': result['batch_status'],\n",
    "    'submitted_jobs': result['submitted_jobs'],\n",
    "    'failed_jobs': failed_count,\n",
    "    'deletion_errors': len(deletion_errors) if deletion_errors else 0\n",
    "}\n",
    "\n",
    "if validation_failed:\n",
    "    # Handle validation failure\n",
    "    from helpers.step import update_step_run\n",
    "    from helpers.constants import StepStatus\n",
    "    \n",
    "    error_message = \"\\n\".join(prereq_errors)\n",
    "    update_step_run(step.run_id, StepStatus.FAILED, error_message=error_message)\n",
    "    \n",
    "    ux.error(\"\\n\" + \"=\"*60)\n",
    "    ux.error(\"VALIDATION FAILED\")\n",
    "    ux.error(\"=\"*60)\n",
    "    for error in prereq_errors:\n",
    "        ux.error(f\"  {error}\")\n",
    "\n",
    "elif deletion_errors:\n",
    "    # Handle deletion failure\n",
    "    from helpers.step import update_step_run\n",
    "    from helpers.constants import StepStatus\n",
    "    \n",
    "    error_message = f\"{len(deletion_errors)} analysis deletion(s) failed:\\n\" + \"\\n\".join(deletion_errors)\n",
    "    update_step_run(step.run_id, StepStatus.FAILED, error_message=error_message)\n",
    "    \n",
    "    ux.error(\"\\n\" + \"=\"*60)\n",
    "    ux.error(\"ANALYSIS DELETION FAILED\")\n",
    "    ux.error(\"=\"*60)\n",
    "    ux.info(f\"\\nBatch ID: {analysis_batch_id}\")\n",
    "    ux.error(f\"Failed deletions: {len(deletion_errors)}\")\n",
    "    ux.info(\"\\nPlease manually delete these analyses in Moody's Risk Modeler,\")\n",
    "    ux.info(\"then re-run this notebook.\")\n",
    "\n",
    "elif failed_count > 0:\n",
    "    # Handle submission failures\n",
    "    from helpers.step import update_step_run\n",
    "    from helpers.constants import StepStatus\n",
    "    \n",
    "    failed_job_errors = [f\"Job {j['job_id']}: {j['error']}\" for j in submission_results if 'error' in j]\n",
    "    error_message = f\"{failed_count} job(s) failed to submit:\\n\" + \"\\n\".join(failed_job_errors)\n",
    "    update_step_run(step.run_id, StepStatus.FAILED, error_message=error_message)\n",
    "    \n",
    "    ux.error(\"\\n\" + \"=\"*60)\n",
    "    ux.error(\"BATCH SUBMISSION FAILED\")\n",
    "    ux.error(\"=\"*60)\n",
    "    ux.info(f\"\\nBatch ID: {analysis_batch_id}\")\n",
    "    ux.info(f\"Submitted: {result['submitted_jobs']} job(s)\")\n",
    "    ux.error(f\"Failed: {failed_count} job(s)\")\n",
    "    for error in failed_job_errors:\n",
    "        ux.error(f\"  {error}\")\n",
    "\n",
    "else:\n",
    "    # Success\n",
    "    step.complete(output_data)\n",
    "    \n",
    "    ux.success(\"\\n\" + \"=\"*60)\n",
    "    if result['submitted_jobs'] == 0:\n",
    "        ux.success(\"STEP COMPLETED - NO SUBMISSION NEEDED\")\n",
    "    else:\n",
    "        ux.success(\"ANALYSIS BATCH SUBMITTED SUCCESSFULLY\")\n",
    "    ux.success(\"=\"*60)\n",
    "    ux.info(f\"\\nBatch ID: {analysis_batch_id}\")\n",
    "    ux.info(f\"Submitted: {result['submitted_jobs']} job(s)\")\n",
    "    ux.info(f\"Batch status: {result['batch_status']}\")\n",
    "    ux.info(\"\\nNext: Monitor job progress or proceed to next stage\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}