{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c401ea2",
   "metadata": {},
   "source": [
    "# Step 01: Execute Analysis\n",
    "\n",
    "This notebook submits analysis jobs to Moody's Risk Modeler.\n",
    "\n",
    "**Tasks:**\n",
    "- Retrieve Analysis batch from Stage_01/Step_03\n",
    "- Review analysis job configurations\n",
    "- Submit analysis jobs to Moody's API\n",
    "- Track job completion status"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6qp37wipth8",
   "metadata": {},
   "source": [
    "## 1) Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4v2su4d26l",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "from helpers.notebook_setup import initialize_notebook_context\n",
    "from helpers import ux\n",
    "from helpers.batch import submit_batch, get_batch_jobs, read_batch\n",
    "from helpers.database import execute_query\n",
    "from helpers.step import get_last_step_run\n",
    "from helpers.irp_integration import IRPClient\n",
    "from helpers.constants import BatchType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pdj01sne68j",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize notebook context and step tracking\n",
    "context, step = initialize_notebook_context('Step_01_Execute_Analysis.ipynb')\n",
    "\n",
    "# Display context\n",
    "ux.header(\"Execute Analysis Batch\")\n",
    "ux.info(f\"Cycle: {context.cycle_name}\")\n",
    "ux.info(f\"Stage: {context.stage_name}\")\n",
    "ux.info(f\"Step: {context.step_name}\")\n",
    "ux.success(f\"Step tracking initialized for '{context.step_name}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fykytjfak95",
   "metadata": {},
   "source": [
    "## 2) Retrieve Analysis Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5r01087u4i4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve Analysis batch from Stage_01/Step_03\n",
    "ux.subheader(\"Retrieve Analysis Batch\")\n",
    "\n",
    "# Query for Stage_01/Step_03 step run\n",
    "query = \"\"\"\n",
    "    SELECT sr.id, sr.step_id, sr.run_num, sr.output_data, sr.completed_ts\n",
    "    FROM irp_step_run sr\n",
    "    INNER JOIN irp_step s ON sr.step_id = s.id\n",
    "    INNER JOIN irp_stage sg ON s.stage_id = sg.id\n",
    "    INNER JOIN irp_cycle c ON sg.cycle_id = c.id\n",
    "    WHERE c.cycle_name = %s\n",
    "      AND sg.stage_num = 1\n",
    "      AND s.step_num = 3\n",
    "      AND sr.status = 'COMPLETED'\n",
    "    ORDER BY sr.completed_ts DESC\n",
    "    LIMIT 1\n",
    "\"\"\"\n",
    "\n",
    "result = execute_query(query, (context.cycle_name,))\n",
    "\n",
    "if result.empty:\n",
    "    raise ValueError(\"Batch creation step not found - please complete Stage_01/Step_03 first\")\n",
    "\n",
    "output_data = result.iloc[0]['output_data']\n",
    "batches = output_data.get('batches', {})\n",
    "\n",
    "if BatchType.ANALYSIS not in batches:\n",
    "    raise ValueError(f\"Analysis batch not found. Available: {list(batches.keys())}\")\n",
    "\n",
    "analysis_batch_id = int(batches[BatchType.ANALYSIS])\n",
    "\n",
    "ux.success(f\"Retrieved Analysis batch: ID={analysis_batch_id}\")\n",
    "step.log(f\"Retrieved Analysis batch: ID={analysis_batch_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wrebi0s4agr",
   "metadata": {},
   "source": "## 3) Reconcile Batch State\n\nCheck if any analyses already exist in Moody's for the jobs in this batch."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ulap2i72x1q",
   "metadata": {},
   "outputs": [],
   "source": "# Reconcile batch state with Moody's\nfrom helpers.batch import reconcile_analysis_batch\n\nux.subheader(\"Reconcile Batch State\")\n\nirp_client = IRPClient()\nrecon = reconcile_analysis_batch(analysis_batch_id, irp_client)\n\n# Extract categories\njobs_successful = recon['jobs_successful']\njobs_failed = recon['jobs_failed']\njobs_missing_analysis = recon['jobs_missing_analysis']\njobs_pending = recon['jobs_pending']\njobs_fresh = recon['jobs_fresh']\njobs_blocked = recon['jobs_blocked']\nexisting_analyses = recon['existing_analyses']\n\n# Store for later use\nRESUBMIT_ACTION = None\nJOBS_TO_RESUBMIT = []\nJOBS_TO_SUBMIT = []\nJOBS_TO_DELETE_ANALYSIS = []\n\n# --- Display Summary ---\nux.info(f\"Batch ID: {recon['batch_id']}  |  Status: {recon['batch_status']}  |  Total Jobs: {recon['total_jobs']}\")\n\n# Build a compact status line\nstatus_parts = []\nif jobs_successful:\n    status_parts.append(f\"{len(jobs_successful)} successful\")\nif jobs_failed:\n    status_parts.append(f\"{len(jobs_failed)} failed\")\nif jobs_missing_analysis:\n    status_parts.append(f\"{len(jobs_missing_analysis)} missing analysis\")\nif jobs_pending:\n    status_parts.append(f\"{len(jobs_pending)} pending\")\nif jobs_fresh:\n    status_parts.append(f\"{len(jobs_fresh)} ready\")\nif jobs_blocked:\n    status_parts.append(f\"{len(jobs_blocked)} blocked\")\n\nif status_parts:\n    ux.info(f\"Jobs: {', '.join(status_parts)}\")\n\n# --- Determine Action ---\nif len(jobs_fresh) == recon['total_jobs']:\n    ux.success(\"\\nAll jobs ready for initial submission.\")\n    RESUBMIT_ACTION = 'fresh'\n\nelif len(jobs_fresh) > 0 and not jobs_failed and not jobs_missing_analysis and not jobs_successful and not jobs_blocked:\n    ux.success(f\"\\n{len(jobs_fresh)} job(s) ready for initial submission.\")\n    RESUBMIT_ACTION = 'fresh'\n\nelif jobs_pending and not jobs_failed and not jobs_missing_analysis and not jobs_fresh and not jobs_blocked:\n    ux.info(\"\\nAll jobs are either successful or still processing. Nothing to submit.\")\n    RESUBMIT_ACTION = 'skip'\n\nelif jobs_failed or jobs_missing_analysis or jobs_successful or jobs_blocked:\n    # Show issues that need attention\n    if jobs_failed:\n        ux.error(f\"\\nFailed ({len(jobs_failed)}):\")\n        for job in jobs_failed:\n            ux.error(f\"  {job['analysis_name']} - {job['status']}\")\n    \n    if jobs_missing_analysis:\n        ux.warning(f\"\\nMissing Analysis ({len(jobs_missing_analysis)}):\")\n        for job in jobs_missing_analysis:\n            ux.warning(f\"  {job['analysis_name']} - job finished but analysis not found\")\n    \n    if jobs_blocked:\n        ux.warning(f\"\\nBlocked ({len(jobs_blocked)}):\")\n        for job in jobs_blocked:\n            ux.warning(f\"  {job['analysis_name']} - analysis already exists, not yet submitted\")\n    \n    if jobs_successful:\n        ux.success(f\"\\nSuccessful ({len(jobs_successful)}):\")\n        for job in jobs_successful:\n            ux.success(f\"  {job['analysis_name']}\")\n    \n    # Show fresh jobs that will be submitted alongside any resubmission\n    if jobs_fresh:\n        ux.info(f\"\\nReady for submission ({len(jobs_fresh)}):\")\n        for job in jobs_fresh:\n            ux.info(f\"  {job['analysis_name']}\")\n    \n    # Calculate groups\n    jobs_without_analysis = jobs_failed + jobs_missing_analysis\n    jobs_with_existing_analysis = jobs_successful + jobs_blocked\n    all_actionable_jobs = jobs_failed + jobs_missing_analysis + jobs_successful + jobs_blocked\n    all_need_action = len(jobs_successful) == 0 and len(all_actionable_jobs) == recon['total_jobs'] - len(jobs_pending) - len(jobs_fresh)\n    \n    # Build options\n    ux.info(\"\\n\" + \"-\"*40)\n    option_num = 1\n    options_map = {}\n    \n    # Note about fresh jobs if they exist\n    fresh_note = f\" + submit {len(jobs_fresh)} ready\" if jobs_fresh else \"\"\n    \n    if all_need_action and all_actionable_jobs:\n        # Single option when all jobs need action\n        if jobs_with_existing_analysis:\n            ux.info(f\"  {option_num}. Resubmit all ({len(all_actionable_jobs)} jobs, delete {len(jobs_with_existing_analysis)} analyses){fresh_note}\")\n            options_map[str(option_num)] = 'submit_all'\n        else:\n            ux.info(f\"  {option_num}. Resubmit all ({len(all_actionable_jobs)} jobs){fresh_note}\")\n            options_map[str(option_num)] = 'resubmit'\n        option_num += 1\n    else:\n        # Granular options\n        if jobs_failed:\n            ux.info(f\"  {option_num}. Resubmit failed only ({len(jobs_failed)} jobs){fresh_note}\")\n            options_map[str(option_num)] = 'resubmit_failed'\n            option_num += 1\n        \n        if jobs_without_analysis and len(jobs_without_analysis) != len(jobs_failed):\n            ux.info(f\"  {option_num}. Resubmit all without analysis ({len(jobs_without_analysis)} jobs){fresh_note}\")\n            options_map[str(option_num)] = 'resubmit_no_analysis'\n            option_num += 1\n        \n        if jobs_with_existing_analysis:\n            ux.info(f\"  {option_num}. Resubmit ALL ({len(all_actionable_jobs)} jobs, delete {len(jobs_with_existing_analysis)} analyses){fresh_note}\")\n            options_map[str(option_num)] = 'submit_all'\n            option_num += 1\n        \n        if jobs_blocked and not jobs_failed and not jobs_missing_analysis and not jobs_successful:\n            ux.info(f\"  {option_num}. Submit blocked ({len(jobs_blocked)} jobs, delete analyses first){fresh_note}\")\n            options_map[str(option_num)] = 'submit_blocked'\n            option_num += 1\n    \n    ux.info(f\"  {option_num}. Skip\")\n    options_map[str(option_num)] = 'skip'\n    \n    choice = input(f\"\\nSelect option (1-{option_num}): \").strip()\n    selected_action = options_map.get(choice, 'skip')\n    \n    # Prepare jobs and show what will happen\n    if selected_action == 'resubmit_failed':\n        JOBS_TO_RESUBMIT = [j['job_id'] for j in jobs_failed]\n        jobs_to_show = jobs_failed\n    elif selected_action == 'resubmit_no_analysis':\n        JOBS_TO_RESUBMIT = [j['job_id'] for j in jobs_without_analysis]\n        jobs_to_show = jobs_without_analysis\n    elif selected_action == 'resubmit':\n        JOBS_TO_RESUBMIT = [j['job_id'] for j in all_actionable_jobs]\n        jobs_to_show = all_actionable_jobs\n    elif selected_action == 'submit_all':\n        JOBS_TO_RESUBMIT = [j['job_id'] for j in (jobs_failed + jobs_missing_analysis + jobs_successful)]\n        JOBS_TO_SUBMIT = [j['job_id'] for j in jobs_blocked]\n        JOBS_TO_DELETE_ANALYSIS = jobs_successful + jobs_blocked\n        jobs_to_show = all_actionable_jobs\n    elif selected_action == 'submit_blocked':\n        JOBS_TO_SUBMIT = [j['job_id'] for j in jobs_blocked]\n        JOBS_TO_DELETE_ANALYSIS = jobs_blocked\n        jobs_to_show = jobs_blocked\n    else:\n        selected_action = 'skip'\n        jobs_to_show = []\n    \n    # Confirm if not skipping\n    if selected_action != 'skip':\n        ux.info(f\"\\nJobs to resubmit ({len(jobs_to_show)}):\")\n        for job in jobs_to_show:\n            ux.info(f\"  - {job['analysis_name']} (EDM: {job['edm_name']})\")\n        \n        # Show fresh jobs that will also be submitted\n        if jobs_fresh:\n            ux.info(f\"\\nJobs to submit ({len(jobs_fresh)}):\")\n            for job in jobs_fresh:\n                ux.info(f\"  - {job['analysis_name']} (EDM: {job['edm_name']})\")\n        \n        if JOBS_TO_DELETE_ANALYSIS:\n            ux.warning(f\"\\n{len(JOBS_TO_DELETE_ANALYSIS)} analysis(es) will be deleted first.\")\n        \n        confirm = input(\"\\nProceed? (yes/no): \").strip().lower()\n        if confirm in ['yes', 'y']:\n            # Normalize action to what submission cell expects\n            if selected_action in ['resubmit_failed', 'resubmit_no_analysis', 'resubmit']:\n                RESUBMIT_ACTION = 'resubmit'\n            else:\n                RESUBMIT_ACTION = selected_action\n            ux.success(\"Confirmed.\")\n        else:\n            RESUBMIT_ACTION = 'skip'\n            JOBS_TO_RESUBMIT = []\n            JOBS_TO_SUBMIT = []\n            JOBS_TO_DELETE_ANALYSIS = []\n            ux.info(\"Cancelled.\")\n    else:\n        RESUBMIT_ACTION = 'skip'\n        ux.info(\"\\nSkipped.\")\n\nelse:\n    ux.info(\"\\nNo jobs available for submission.\")\n    RESUBMIT_ACTION = 'skip'\n\nstep.log(f\"Reconciliation: action={RESUBMIT_ACTION}, resubmit={len(JOBS_TO_RESUBMIT)}, submit={len(JOBS_TO_SUBMIT)}, fresh={len(jobs_fresh)}\")"
  },
  {
   "cell_type": "markdown",
   "id": "3ai75qtfzf5",
   "metadata": {},
   "source": "## 4) Submit Analysis Batch to Moody's"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "npui3uxx0ds",
   "metadata": {},
   "outputs": [],
   "source": "# Submit batch based on reconciliation action\nfrom helpers.job import resubmit_jobs, submit_job\n\nux.subheader(\"Submit Batch to Moody's\")\n\ndeletion_errors = []\nfailed_count = 0\n\ndef delete_analyses_for_jobs(jobs_to_delete, existing_analyses, irp_client):\n    \"\"\"Delete analyses for jobs that have existing analyses. Returns list of errors.\"\"\"\n    errors = []\n    for job in jobs_to_delete:\n        # Find the matching analysis from existing_analyses\n        matching_analysis = None\n        for item in existing_analyses:\n            if (item['job_config'].get('Analysis Name') == job['analysis_name'] and\n                item['job_config'].get('Database') == job['edm_name']):\n                matching_analysis = item\n                break\n\n        if matching_analysis:\n            analysis_id = matching_analysis['analysis']['analysisId']\n            analysis_name = job['analysis_name']\n            try:\n                irp_client.analysis.delete_analysis(analysis_id)\n                ux.info(f\"  Deleted: {analysis_name} (ID: {analysis_id})\")\n            except Exception as e:\n                error_msg = f\"{analysis_name} (ID: {analysis_id}): {e}\"\n                errors.append(error_msg)\n                ux.error(f\"  Failed to delete {analysis_name}: {e}\")\n    return errors\n\n\nif RESUBMIT_ACTION == 'skip':\n    ux.info(\"Submission skipped by user.\")\n    result = {'submitted_jobs': 0, 'batch_status': recon['batch_status'], 'jobs': []}\n\nelif RESUBMIT_ACTION == 'fresh':\n    # Fresh submission - use normal submit_batch\n    ux.info(\"Submitting fresh batch...\")\n    result = submit_batch(analysis_batch_id, irp_client, step_id=step.step_id)\n    failed_count = len([j for j in result['jobs'] if 'error' in j])\n\n    ux.success(f\"\\nBatch submission completed\")\n    ux.info(f\"  Submitted: {result['submitted_jobs']} jobs\")\n    ux.info(f\"  Status: {result['batch_status']}\")\n\nelif RESUBMIT_ACTION == 'resubmit':\n    # Delete existing analyses first (only for jobs that have them)\n    if JOBS_TO_DELETE_ANALYSIS:\n        ux.info(f\"Deleting {len(JOBS_TO_DELETE_ANALYSIS)} existing analyses...\")\n        deletion_errors = delete_analyses_for_jobs(JOBS_TO_DELETE_ANALYSIS, existing_analyses, irp_client)\n\n    # Check if any deletions failed\n    if deletion_errors:\n        ux.error(f\"\\n{len(deletion_errors)} analysis deletion(s) failed. Cannot proceed with resubmission.\")\n        ux.info(\"\\nPlease manually delete the following analyses in Moody's before retrying:\")\n        for error in deletion_errors:\n            ux.error(f\"  - {error}\")\n\n        result = {'submitted_jobs': 0, 'batch_status': recon['batch_status'], 'jobs': []}\n    else:\n        # All deletions succeeded (or none needed) - now resubmit jobs\n        ux.info(f\"\\nResubmitting {len(JOBS_TO_RESUBMIT)} jobs...\")\n        resubmit_result = resubmit_jobs(JOBS_TO_RESUBMIT, irp_client, BatchType.ANALYSIS)\n\n        result = {\n            'submitted_jobs': resubmit_result['success_count'],\n            'batch_status': 'ACTIVE',\n            'jobs': resubmit_result['successful'] + [{'job_id': f['job_id'], 'error': f['error']} for f in resubmit_result['failed']]\n        }\n        failed_count = resubmit_result['failure_count']\n\n        ux.success(f\"\\nResubmission completed\")\n        ux.info(f\"  Submitted: {resubmit_result['success_count']} jobs\")\n        ux.info(f\"  Failed: {resubmit_result['failure_count']} jobs\")\n\nelif RESUBMIT_ACTION == 'submit_all':\n    # Delete existing analyses first, then resubmit terminal jobs and submit blocked jobs\n    if JOBS_TO_DELETE_ANALYSIS:\n        ux.info(f\"Deleting {len(JOBS_TO_DELETE_ANALYSIS)} existing analyses...\")\n        deletion_errors = delete_analyses_for_jobs(JOBS_TO_DELETE_ANALYSIS, existing_analyses, irp_client)\n\n    if deletion_errors:\n        ux.error(f\"\\n{len(deletion_errors)} analysis deletion(s) failed. Cannot proceed.\")\n        ux.info(\"\\nPlease manually delete the following analyses in Moody's before retrying:\")\n        for error in deletion_errors:\n            ux.error(f\"  - {error}\")\n\n        result = {'submitted_jobs': 0, 'batch_status': recon['batch_status'], 'jobs': []}\n    else:\n        all_jobs = []\n        total_submitted = 0\n        total_failed = 0\n\n        # Resubmit terminal jobs (failed, missing_analysis, successful)\n        if JOBS_TO_RESUBMIT:\n            ux.info(f\"\\nResubmitting {len(JOBS_TO_RESUBMIT)} terminal jobs...\")\n            resubmit_result = resubmit_jobs(JOBS_TO_RESUBMIT, irp_client, BatchType.ANALYSIS)\n            total_submitted += resubmit_result['success_count']\n            total_failed += resubmit_result['failure_count']\n            all_jobs.extend(resubmit_result['successful'])\n            all_jobs.extend([{'job_id': f['job_id'], 'error': f['error']} for f in resubmit_result['failed']])\n\n            ux.info(f\"  Resubmitted: {resubmit_result['success_count']}, Failed: {resubmit_result['failure_count']}\")\n\n        # Submit blocked jobs (INITIATED jobs with now-deleted analyses) using submit_batch\n        if JOBS_TO_SUBMIT:\n            ux.info(f\"\\nSubmitting {len(JOBS_TO_SUBMIT)} blocked jobs...\")\n            # submit_batch will only submit INITIATED jobs, which is exactly what we have\n            submit_result = submit_batch(analysis_batch_id, irp_client, step_id=step.step_id)\n            submit_success = submit_result['submitted_jobs']\n            submit_failed = len([j for j in submit_result['jobs'] if 'error' in j])\n            \n            total_submitted += submit_success\n            total_failed += submit_failed\n            all_jobs.extend(submit_result['jobs'])\n            ux.info(f\"  Submitted: {submit_success}, Failed: {submit_failed}\")\n\n        result = {\n            'submitted_jobs': total_submitted,\n            'batch_status': 'ACTIVE',\n            'jobs': all_jobs\n        }\n        failed_count = total_failed\n\n        ux.success(f\"\\nSubmission completed\")\n        ux.info(f\"  Total submitted: {total_submitted} jobs\")\n        ux.info(f\"  Total failed: {total_failed} jobs\")\n\nelif RESUBMIT_ACTION == 'submit_blocked':\n    # Delete existing analyses for blocked jobs, then submit them using submit_batch\n    if JOBS_TO_DELETE_ANALYSIS:\n        ux.info(f\"Deleting {len(JOBS_TO_DELETE_ANALYSIS)} existing analyses...\")\n        deletion_errors = delete_analyses_for_jobs(JOBS_TO_DELETE_ANALYSIS, existing_analyses, irp_client)\n\n    if deletion_errors:\n        ux.error(f\"\\n{len(deletion_errors)} analysis deletion(s) failed. Cannot proceed.\")\n        ux.info(\"\\nPlease manually delete the following analyses in Moody's before retrying:\")\n        for error in deletion_errors:\n            ux.error(f\"  - {error}\")\n\n        result = {'submitted_jobs': 0, 'batch_status': recon['batch_status'], 'jobs': []}\n    else:\n        # Submit blocked jobs using submit_batch (they are INITIATED, so submit_batch handles them)\n        ux.info(f\"\\nSubmitting {len(JOBS_TO_SUBMIT)} blocked jobs...\")\n        result = submit_batch(analysis_batch_id, irp_client, step_id=step.step_id)\n        failed_count = len([j for j in result['jobs'] if 'error' in j])\n\n        ux.success(f\"\\nSubmission completed\")\n        ux.info(f\"  Submitted: {result['submitted_jobs']} jobs\")\n        ux.info(f\"  Failed: {failed_count} jobs\")\n\n# Check for errors\nif failed_count > 0:\n    ux.warning(f\"\\n{failed_count} job(s) failed to submit\")\n    for job_result in result['jobs']:\n        if 'error' in job_result:\n            ux.error(f\"  Job {job_result['job_id']}: {job_result['error']}\")"
  },
  {
   "cell_type": "markdown",
   "id": "cvp66q6gppn",
   "metadata": {},
   "source": "## 5) Complete Step Execution"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "u9rfsfbu45l",
   "metadata": {},
   "outputs": [],
   "source": "# Complete step execution\nux.header(\"Step Completion\")\n\n# Prepare output data\noutput_data = {\n    'batch_id': analysis_batch_id,\n    'batch_type': BatchType.ANALYSIS,\n    'batch_status': result['batch_status'],\n    'submitted_jobs': result['submitted_jobs'],\n    'failed_jobs': failed_count,\n    'deletion_errors': len(deletion_errors),\n    'action': RESUBMIT_ACTION if RESUBMIT_ACTION != 'fresh' else 'submit'\n}\n\n# Check if any deletions failed\nif deletion_errors:\n    error_message = f\"{len(deletion_errors)} analysis deletion(s) failed:\\n\" + \"\\n\".join(deletion_errors)\n    \n    # Mark step as failed in database\n    from helpers.step import update_step_run\n    from helpers.constants import StepStatus\n    update_step_run(step.run_id, StepStatus.FAILED, error_message=error_message)\n    \n    ux.error(\"\\n\" + \"=\"*60)\n    ux.error(\"ANALYSIS DELETION FAILED\")\n    ux.error(\"=\"*60)\n    ux.info(f\"\\nBatch ID: {analysis_batch_id}\")\n    ux.error(f\"Failed deletions: {len(deletion_errors)}\")\n    ux.info(\"\\nThe following analyses could not be deleted:\")\n    for error in deletion_errors:\n        ux.error(f\"  - {error}\")\n    ux.info(\"\\nPlease manually delete these analyses in Moody's Risk Modeler,\")\n    ux.info(\"then re-run this notebook to retry submission.\")\n\n# Check if any jobs failed to submit\nelif failed_count > 0:\n    failed_job_errors = [\n        f\"Job {j['job_id']}: {j['error']}\"\n        for j in result['jobs'] if 'error' in j\n    ]\n    error_message = f\"{failed_count} job(s) failed to submit:\\n\" + \"\\n\".join(failed_job_errors)\n\n    # Note: Teams notification already sent from batch.py for each failed job\n    # Mark step as failed in database (skip duplicate notification)\n    from helpers.step import update_step_run\n    from helpers.constants import StepStatus\n    update_step_run(step.run_id, StepStatus.FAILED, error_message=error_message)\n\n    ux.error(\"\\n\" + \"=\"*60)\n    ux.error(\"BATCH SUBMISSION FAILED\")\n    ux.error(\"=\"*60)\n    ux.info(f\"\\nBatch ID: {analysis_batch_id}\")\n    ux.info(f\"Submitted: {result['submitted_jobs']} job(s)\")\n    ux.error(f\"Failed: {failed_count} job(s)\")\n    ux.info(\"\\nFailed jobs:\")\n    for error in failed_job_errors:\n        ux.error(f\"  {error}\")\n    ux.info(\"\\nPlease review the errors and resubmit failed jobs.\")\nelse:\n    # Complete the step successfully (includes skip case)\n    step.complete(output_data)\n\n    ux.success(\"\\n\" + \"=\"*60)\n    if RESUBMIT_ACTION == 'skip':\n        ux.success(\"STEP COMPLETED - SUBMISSION SKIPPED\")\n    else:\n        ux.success(\"ANALYSIS BATCH SUBMITTED SUCCESSFULLY\")\n    ux.success(\"=\"*60)\n    ux.info(f\"\\nBatch ID: {analysis_batch_id}\")\n    ux.info(f\"Submitted {result['submitted_jobs']} job(s) to Moody's API\")\n    ux.info(f\"Batch status: {result['batch_status']}\")\n    ux.info(\"\\nNext: Monitor job progress in Step_02 or proceed to Grouping stage\")"
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}