{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8cac9f1d",
   "metadata": {},
   "source": [
    "# Step 02: Analysis Summary\n",
    "\n",
    "This notebook provides an overview of the analysis batch jobs submitted in Step 01.\n",
    "\n",
    "**Tasks:**\n",
    "- Retrieve Analysis batch from Step 01\n",
    "- Fetch job status from Moody's API\n",
    "- Display summary of completed, failed, and in-progress jobs\n",
    "- Show detailed job information including locations modeled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup-header",
   "metadata": {},
   "source": [
    "## 1) Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "from helpers.notebook_setup import initialize_notebook_context\n",
    "from helpers import ux\n",
    "from helpers.batch import read_batch, get_batch_jobs\n",
    "from helpers.database import execute_query\n",
    "from helpers.irp_integration import IRPClient\n",
    "from helpers.constants import BatchType, JobStatus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "context-init",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize notebook context and step tracking\n",
    "context, step = initialize_notebook_context('Step_02_Analysis_Summary.ipynb', allow_rerun=True)\n",
    "\n",
    "# Display context\n",
    "ux.header(\"Analysis Batch Summary\")\n",
    "ux.info(f\"Cycle: {context.cycle_name}\")\n",
    "ux.info(f\"Stage: {context.stage_name}\")\n",
    "ux.info(f\"Step: {context.step_name}\")\n",
    "ux.success(f\"Step tracking initialized for '{context.step_name}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "retrieve-header",
   "metadata": {},
   "source": [
    "## 2) Retrieve Analysis Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "retrieve-batch",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve Analysis batch from Step 01 output\n",
    "ux.subheader(\"Retrieve Analysis Batch\")\n",
    "\n",
    "# Query for Step 01 step run to get batch ID\n",
    "query = \"\"\"\n",
    "    SELECT sr.id, sr.step_id, sr.run_num, sr.output_data, sr.completed_ts\n",
    "    FROM irp_step_run sr\n",
    "    INNER JOIN irp_step s ON sr.step_id = s.id\n",
    "    INNER JOIN irp_stage sg ON s.stage_id = sg.id\n",
    "    INNER JOIN irp_cycle c ON sg.cycle_id = c.id\n",
    "    WHERE c.cycle_name = %s\n",
    "      AND sg.stage_num = 4\n",
    "      AND s.step_num = 1\n",
    "      AND sr.status = 'COMPLETED'\n",
    "    ORDER BY sr.completed_ts DESC\n",
    "    LIMIT 1\n",
    "\"\"\"\n",
    "\n",
    "result = execute_query(query, (context.cycle_name,))\n",
    "\n",
    "if result.empty:\n",
    "    raise ValueError(\"Analysis execution step not found - please complete Step 01 first\")\n",
    "\n",
    "output_data = result.iloc[0]['output_data']\n",
    "analysis_batch_id = output_data.get('batch_id')\n",
    "\n",
    "if not analysis_batch_id:\n",
    "    raise ValueError(\"Analysis batch ID not found in Step 01 output\")\n",
    "\n",
    "ux.success(f\"Retrieved Analysis batch: ID={analysis_batch_id}\")\n",
    "step.log(f\"Retrieved Analysis batch: ID={analysis_batch_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "batch-status-header",
   "metadata": {},
   "source": [
    "## 3) Batch Status Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "batch-status",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display batch status and summary\n",
    "ux.subheader(\"Batch Status\")\n",
    "\n",
    "# Read batch details\n",
    "batch = read_batch(analysis_batch_id)\n",
    "\n",
    "batch_info = [\n",
    "    [\"Batch ID\", batch['id']],\n",
    "    [\"Batch Type\", batch['batch_type']],\n",
    "    [\"Status\", batch['status']],\n",
    "    [\"Created\", batch['created_ts'].strftime('%Y-%m-%d %H:%M:%S')]\n",
    "]\n",
    "ux.table(batch_info, headers=[\"Property\", \"Value\"])\n",
    "\n",
    "# Get all jobs in batch\n",
    "jobs = get_batch_jobs(analysis_batch_id)\n",
    "total_jobs = len(jobs)\n",
    "\n",
    "# Count jobs by status\n",
    "status_counts = {}\n",
    "for job in jobs:\n",
    "    status = job['status']\n",
    "    status_counts[status] = status_counts.get(status, 0) + 1\n",
    "\n",
    "# Display status summary\n",
    "ux.info(f\"\\nTotal Jobs: {total_jobs}\")\n",
    "status_rows = [[status, count] for status, count in sorted(status_counts.items())]\n",
    "if status_rows:\n",
    "    ux.table(status_rows, headers=[\"Status\", \"Count\"])\n",
    "\n",
    "# Highlight key metrics\n",
    "finished_count = status_counts.get(JobStatus.FINISHED, 0)\n",
    "failed_count = status_counts.get(JobStatus.FAILED, 0)\n",
    "error_count = status_counts.get(JobStatus.ERROR, 0)\n",
    "in_progress = total_jobs - finished_count - failed_count - error_count\n",
    "\n",
    "if finished_count == total_jobs:\n",
    "    ux.success(f\"\\nAll {total_jobs} jobs completed successfully!\")\n",
    "elif failed_count > 0 or error_count > 0:\n",
    "    ux.warning(f\"\\n{failed_count + error_count} job(s) failed or errored\")\n",
    "elif in_progress > 0:\n",
    "    ux.info(f\"\\n{in_progress} job(s) still in progress\")\n",
    "\n",
    "step.log(f\"Batch status: {batch['status']}, Jobs: {finished_count} finished, {failed_count} failed, {in_progress} in progress\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fetch-details-header",
   "metadata": {},
   "source": [
    "## 4) Fetch Job Details from Moody's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fetch-details",
   "metadata": {},
   "outputs": [],
   "source": "# Fetch detailed job information from Moody's API\nux.subheader(\"Fetching Job Details from Moody's\")\n\nirp_client = IRPClient()\n\njob_details = []\nfailed_to_fetch = []\n\nfor job in jobs:\n    workflow_id = job.get('moodys_workflow_id')\n    if not workflow_id:\n        continue\n    \n    # Get job configuration from database\n    config_query = \"SELECT job_configuration_data FROM irp_job_configuration WHERE id = %s\"\n    config_result = execute_query(config_query, (job['job_configuration_id'],))\n    job_config = config_result.iloc[0]['job_configuration_data'] if not config_result.empty else {}\n    \n    try:\n        # Fetch job details from Moody's API\n        moodys_job = irp_client.analysis.get_analysis_job(int(workflow_id))\n        job_details.append({\n            'job_id': job['id'],\n            'workflow_id': workflow_id,\n            'local_status': job['status'],\n            'moodys_data': moodys_job,\n            'job_config': job_config\n        })\n    except Exception as e:\n        failed_to_fetch.append({'job_id': job['id'], 'workflow_id': workflow_id, 'error': str(e)})\n\nux.success(f\"Fetched details for {len(job_details)} job(s)\")\nif failed_to_fetch:\n    ux.warning(f\"Failed to fetch {len(failed_to_fetch)} job(s)\")\n\nstep.log(f\"Fetched {len(job_details)} job details from Moody's API\")"
  },
  {
   "cell_type": "markdown",
   "id": "summary-table-header",
   "metadata": {},
   "source": [
    "## 5) Analysis Job Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "summary-table",
   "metadata": {},
   "outputs": [],
   "source": "# Build summary table with job results\nux.subheader(\"Analysis Job Results\")\n\nsummary_rows = []\n\nfor detail in job_details:\n    moodys_data = detail['moodys_data']\n    job_config = detail.get('job_config', {})\n    \n    # Extract from Moody's API response (top-level fields)\n    job_name = moodys_data.get('name', 'N/A')\n    status = moodys_data.get('status', 'N/A')\n    progress = moodys_data.get('progress', 0)\n    \n    # Get configuration details from our database\n    portfolio = job_config.get('Portfolio', 'N/A')\n    database = job_config.get('Database', 'N/A')\n    analysis_profile = job_config.get('Analysis Profile', 'N/A')\n    \n    # Calculate duration if available\n    start_time = moodys_data.get('startedAt')\n    end_time = moodys_data.get('endedAt')\n    duration = 'N/A'\n    if start_time and end_time:\n        try:\n            start_dt = datetime.fromisoformat(start_time.replace('Z', '+00:00'))\n            end_dt = datetime.fromisoformat(end_time.replace('Z', '+00:00'))\n            duration_mins = (end_dt - start_dt).total_seconds() / 60\n            duration = f\"{duration_mins:.1f} min\"\n        except:\n            pass\n    \n    summary_rows.append({\n        'Analysis Name': job_name,\n        'Status': status,\n        'Progress': f\"{progress}%\",\n        'Portfolio': portfolio,\n        'Database': database,\n        'Analysis Profile': analysis_profile[:30] + '...' if len(str(analysis_profile)) > 30 else analysis_profile,\n        'Duration': duration\n    })\n\nif summary_rows:\n    summary_df = pd.DataFrame(summary_rows)\n    \n    # Display with formatting\n    pd.set_option('display.max_colwidth', 40)\n    pd.set_option('display.width', None)\n    print(summary_df.to_string(index=False))\nelse:\n    ux.warning(\"No job details available to display\")"
  },
  {
   "cell_type": "markdown",
   "id": "success-details-header",
   "metadata": {},
   "source": [
    "## 6) Successful Jobs - Detailed View"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "success-details",
   "metadata": {},
   "outputs": [],
   "source": "# Display detailed information for successful jobs\nux.subheader(\"Successful Analysis Jobs\")\n\nsuccessful_jobs = [d for d in job_details if d['moodys_data'].get('status') == 'FINISHED']\n\nif not successful_jobs:\n    ux.info(\"No successfully completed jobs yet\")\nelse:\n    ux.success(f\"{len(successful_jobs)} job(s) completed successfully\\n\")\n    \n    for detail in successful_jobs:\n        moodys_data = detail['moodys_data']\n        job_config = detail.get('job_config', {})\n        details_obj = moodys_data.get('details', {})\n        \n        job_name = moodys_data.get('name', 'N/A')\n        ux.info(f\"Analysis: {job_name}\")\n        \n        # Calculate duration\n        start_time = moodys_data.get('startedAt')\n        end_time = moodys_data.get('endedAt')\n        duration = 'N/A'\n        if start_time and end_time:\n            try:\n                start_dt = datetime.fromisoformat(start_time.replace('Z', '+00:00'))\n                end_dt = datetime.fromisoformat(end_time.replace('Z', '+00:00'))\n                duration_mins = (end_dt - start_dt).total_seconds() / 60\n                duration = f\"{duration_mins:.1f} min\"\n            except:\n                pass\n        \n        detail_rows = [\n            [\"Workflow ID\", detail['workflow_id']],\n            [\"Job ID (Local)\", detail['job_id']],\n            [\"Status\", moodys_data.get('status', 'N/A')],\n            [\"Progress\", f\"{moodys_data.get('progress', 0)}%\"],\n            [\"Duration\", duration],\n            [\"Started At\", moodys_data.get('startedAt', 'N/A')],\n            [\"Ended At\", moodys_data.get('endedAt', 'N/A')],\n            [\"\", \"\"],\n            [\"Portfolio\", job_config.get('Portfolio', 'N/A')],\n            [\"Database (EDM)\", job_config.get('Database', 'N/A')],\n            [\"Analysis Profile\", job_config.get('Analysis Profile', 'N/A')],\n            [\"Output Profile\", job_config.get('Output Profile', 'N/A')],\n            [\"Event Rate\", job_config.get('Event Rate', 'N/A')],\n        ]\n        \n        # Add treaty info if present\n        for i in range(1, 6):\n            treaty = job_config.get(f'Reinsurance Treaty {i}')\n            if treaty:\n                detail_rows.append([f\"Reinsurance Treaty {i}\", treaty])\n        \n        ux.table(detail_rows, headers=[\"Property\", \"Value\"])\n        \n        # Show details summary if available\n        if details_obj.get('summary'):\n            ux.info(f\"Summary: {details_obj['summary']}\")\n        \n        print()"
  },
  {
   "cell_type": "markdown",
   "id": "failed-details-header",
   "metadata": {},
   "source": [
    "## 7) Failed Jobs - Error Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "failed-details",
   "metadata": {},
   "outputs": [],
   "source": "# Display detailed information for failed jobs\nux.subheader(\"Failed Analysis Jobs\")\n\nfailed_jobs = [d for d in job_details if d['moodys_data'].get('status') in ['FAILED', 'CANCELLED', 'ERROR']]\n\nif not failed_jobs:\n    ux.success(\"No failed jobs!\")\nelse:\n    ux.error(f\"{len(failed_jobs)} job(s) failed\\n\")\n    \n    for detail in failed_jobs:\n        moodys_data = detail['moodys_data']\n        job_config = detail.get('job_config', {})\n        \n        job_name = moodys_data.get('name', 'N/A')\n        status = moodys_data.get('status', 'N/A')\n        \n        ux.warning(f\"Analysis: {job_name}\")\n        \n        error_rows = [\n            [\"Workflow ID\", detail['workflow_id']],\n            [\"Job ID (Local)\", detail['job_id']],\n            [\"Status\", status],\n            [\"Progress\", f\"{moodys_data.get('progress', 0)}%\"],\n            [\"Portfolio\", job_config.get('Portfolio', 'N/A')],\n            [\"Database (EDM)\", job_config.get('Database', 'N/A')],\n        ]\n        ux.table(error_rows, headers=[\"Property\", \"Value\"])\n        \n        # Check tasks for errors\n        tasks = moodys_data.get('tasks', [])\n        failed_tasks = [t for t in tasks if t.get('status') not in ['FINISHED', 'QUEUED', 'PENDING', 'RUNNING']]\n        \n        if failed_tasks:\n            ux.info(\"Failed Tasks:\")\n            for task in failed_tasks:\n                task_output = task.get('output', {})\n                errors = task_output.get('errors', [])\n                print(f\"  - Task {task.get('taskId')}: {task.get('name')} - {task.get('status')}\")\n                for error in errors:\n                    print(f\"      Error: {error.get('message', 'Unknown error')}\")\n        \n        # Show details summary if available (may contain error info)\n        details_obj = moodys_data.get('details', {})\n        if details_obj.get('summary'):\n            ux.info(f\"Details: {details_obj['summary']}\")\n        \n        print()"
  },
  {
   "cell_type": "markdown",
   "id": "in-progress-header",
   "metadata": {},
   "source": [
    "## 8) In-Progress Jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "in-progress",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display information for in-progress jobs\n",
    "ux.subheader(\"In-Progress Analysis Jobs\")\n",
    "\n",
    "in_progress_statuses = ['SUBMITTED', 'PENDING', 'QUEUED', 'RUNNING']\n",
    "in_progress_jobs = [d for d in job_details if d['moodys_data'].get('status') in in_progress_statuses]\n",
    "\n",
    "if not in_progress_jobs:\n",
    "    ux.success(\"No jobs currently in progress\")\n",
    "else:\n",
    "    ux.info(f\"{len(in_progress_jobs)} job(s) still running\\n\")\n",
    "    \n",
    "    progress_rows = []\n",
    "    for detail in in_progress_jobs:\n",
    "        moodys_data = detail['moodys_data']\n",
    "        progress_rows.append([\n",
    "            moodys_data.get('name', 'N/A'),\n",
    "            moodys_data.get('status', 'N/A'),\n",
    "            f\"{moodys_data.get('progress', 0)}%\",\n",
    "            detail['workflow_id']\n",
    "        ])\n",
    "    \n",
    "    ux.table(progress_rows, headers=[\"Analysis Name\", \"Status\", \"Progress\", \"Workflow ID\"])\n",
    "    \n",
    "    ux.info(\"\\nRe-run this notebook to check for updates.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "complete-header",
   "metadata": {},
   "source": [
    "## 9) Complete Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complete-step",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete step execution\n",
    "ux.header(\"Step Completion\")\n",
    "\n",
    "try:\n",
    "    # Prepare output summary\n",
    "    output_data = {\n",
    "        'batch_id': analysis_batch_id,\n",
    "        'batch_status': batch['status'],\n",
    "        'total_jobs': total_jobs,\n",
    "        'jobs_finished': finished_count,\n",
    "        'jobs_failed': failed_count + error_count,\n",
    "        'jobs_in_progress': in_progress,\n",
    "        'jobs_fetched': len(job_details)\n",
    "    }\n",
    "    \n",
    "    # Complete the step\n",
    "    step.complete(output_data)\n",
    "\n",
    "    ux.success(\"\\n\" + \"=\"*60)\n",
    "    ux.success(\"ANALYSIS SUMMARY COMPLETED\")\n",
    "    ux.success(\"=\"*60)\n",
    "    \n",
    "    # Final summary\n",
    "    ux.info(f\"\\nBatch Status: {batch['status']}\")\n",
    "    ux.info(f\"Total Jobs: {total_jobs}\")\n",
    "    \n",
    "    if finished_count > 0:\n",
    "        ux.success(f\"  Completed: {finished_count}\")\n",
    "    if failed_count + error_count > 0:\n",
    "        ux.error(f\"  Failed: {failed_count + error_count}\")\n",
    "    if in_progress > 0:\n",
    "        ux.warning(f\"  In Progress: {in_progress}\")\n",
    "    \n",
    "    if finished_count == total_jobs:\n",
    "        ux.info(\"\\nAll analyses complete! Proceed to Stage 05 (Grouping) when ready.\")\n",
    "    elif in_progress > 0:\n",
    "        ux.info(\"\\nSome jobs still in progress. Re-run this notebook to check for updates.\")\n",
    "    else:\n",
    "        ux.warning(\"\\nSome jobs failed. Review errors above and consider resubmitting.\")\n",
    "\n",
    "except Exception as e:\n",
    "    ux.error(f\"Step completion failed: {str(e)}\")\n",
    "    step.fail(str(e))\n",
    "    raise"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}