{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "notebook_header",
   "metadata": {},
   "source": [
    "# Step 08: Control Totals\n",
    "\n",
    "This notebook executes control totals SQL scripts and compares Contract Import File (3b) vs RMS EDM (3d) results.\n",
    "\n",
    "**Tasks:**\n",
    "- Load configuration metadata (date_value, cycle_type)\n",
    "- Validate Workspace EDM\n",
    "- Execute 3b_Control_Totals_Contract_Import_File_Tables.sql\n",
    "- Execute 3d_RMS_EDM_Control_Totals.sql\n",
    "- Compare 3b vs 3d results and display differences\n",
    "- Execute 3e_GeocodingSummary.sql and validate GeoHaz thresholds\n",
    "- Compare 3d vs 3e results for base portfolios"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup_header",
   "metadata": {},
   "source": [
    "## 1) Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "from helpers.notebook_setup import initialize_notebook_context\n",
    "from helpers import ux\n",
    "from helpers.database import execute_query\n",
    "from helpers.sqlserver import execute_query_from_file, sql_file_exists\n",
    "from helpers.constants import WORKSPACE_PATH\n",
    "from helpers.configuration import read_configuration, get_base_portfolios\n",
    "from helpers.irp_integration import IRPClient\n",
    "from helpers.control_totals import (\n",
    "    compare_3b_vs_3d_pivot,\n",
    "    compare_3d_vs_3e_pivot,\n",
    "    validate_geohaz_thresholds,\n",
    "    get_import_file_mapping_from_config,\n",
    "    get_exposure_group_portname_mapping\n",
    ")\n",
    "from helpers.excel_export import (\n",
    "    save_control_totals_3b_vs_3d_to_excel,\n",
    "    save_geohaz_validation_to_excel\n",
    ")\n",
    "from helpers.csv_export import save_dataframes_to_csv\n",
    "\n",
    "# Flag to track execution state\n",
    "execution_failed = False\n",
    "error_message = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "context_init",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize notebook context and step tracking\n",
    "context, step = initialize_notebook_context('Step_08_Control_Totals.ipynb')\n",
    "\n",
    "# Display context\n",
    "ux.header(\"Control Totals Execution\")\n",
    "ux.info(f\"Cycle: {context.cycle_name}\")\n",
    "ux.info(f\"Stage: {context.stage_name}\")\n",
    "ux.info(f\"Step: {context.step_name}\")\n",
    "ux.success(f\"✓ Step tracking initialized for '{context.step_name}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "config_header",
   "metadata": {},
   "source": [
    "## 2) Load Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load_config",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration to get date_value and cycle_type\n",
    "ux.subheader(\"Load Configuration\")\n",
    "\n",
    "# Query for active configuration\n",
    "query = \"\"\"\n",
    "    SELECT c.id, c.configuration_data\n",
    "    FROM irp_configuration c\n",
    "    INNER JOIN irp_cycle cy ON c.cycle_id = cy.id\n",
    "    WHERE cy.cycle_name = %s\n",
    "      AND c.status IN ('VALID', 'ACTIVE')\n",
    "    ORDER BY c.created_ts DESC\n",
    "    LIMIT 1\n",
    "\"\"\"\n",
    "\n",
    "result = execute_query(query, (context.cycle_name,))\n",
    "\n",
    "if result.empty:\n",
    "    execution_failed = True\n",
    "    error_message = \"No valid configuration found for this cycle\"\n",
    "    ux.error(f\"✗ {error_message}\")\n",
    "else:\n",
    "    config_id = int(result.iloc[0]['id'])\n",
    "    config_data = result.iloc[0]['configuration_data']\n",
    "    metadata = config_data.get('Metadata', {})\n",
    "    \n",
    "    date_value = metadata.get('Current Date Value', '')\n",
    "    cycle_type = metadata.get('Cycle Type', '')\n",
    "    \n",
    "    if not date_value or not cycle_type:\n",
    "        execution_failed = True\n",
    "        error_message = f\"Missing required metadata: date_value={date_value}, cycle_type={cycle_type}\"\n",
    "        ux.error(f\"✗ {error_message}\")\n",
    "    else:\n",
    "        ux.success(f\"✓ Configuration loaded\")\n",
    "        ux.info(f\"  Configuration ID: {config_id}\")\n",
    "        ux.info(f\"  Date Value: {date_value}\")\n",
    "        ux.info(f\"  Cycle Type: {cycle_type}\")\n",
    "        step.log(f\"Configuration loaded: date_value={date_value}, cycle_type={cycle_type}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edm_header",
   "metadata": {},
   "source": [
    "## 3) Validate Workspace EDM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "validate_edm",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Workspace EDM\n",
    "workspace_edm_full_name = None\n",
    "\n",
    "if execution_failed:\n",
    "    ux.warning(\"⏭ Skipping EDM validation due to configuration error\")\n",
    "else:\n",
    "    ux.subheader(\"Validate Workspace EDM\")\n",
    "    \n",
    "    try:\n",
    "        irp_client = IRPClient()\n",
    "        workspace_edm = \"WORKSPACE_EDM\"\n",
    "        workspace_edms = irp_client.edm.search_edms(filter=f\"exposureName=\\\"{workspace_edm}\\\"\")\n",
    "        \n",
    "        if len(workspace_edms) == 0:\n",
    "            moody_job_id = irp_client.edm.submit_create_edm_job(edm_name=workspace_edm)\n",
    "            irp_client.job.poll_risk_data_job_to_completion(moody_job_id)\n",
    "            workspace_edms = irp_client.edm.search_edms(filter=f\"exposureName=\\\"{workspace_edm}\\\"\")\n",
    "        \n",
    "        workspace_edm_obj = workspace_edms[0]\n",
    "        workspace_edm_full_name = workspace_edm_obj['databaseName']\n",
    "        \n",
    "        ux.success(f\"✓ Workspace EDM validated\")\n",
    "        ux.info(f\"  EDM Full Name: {workspace_edm_full_name}\")\n",
    "        step.log(f\"Workspace EDM: {workspace_edm_full_name}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        execution_failed = True\n",
    "        error_message = f\"Failed to validate Workspace EDM: {str(e)}\"\n",
    "        ux.error(f\"✗ {error_message}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "import_file_header",
   "metadata": {},
   "source": [
    "## 4) Execute Import File Control Totals (3b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "execute_3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute 3b_Control_Totals_Contract_Import_File_Tables.sql\n",
    "import_file_results = []\n",
    "csv_3b_path = None\n",
    "\n",
    "if execution_failed:\n",
    "    ux.warning(\"⏭ Skipping 3b execution due to previous error\")\n",
    "else:\n",
    "    ux.subheader(\"Execute Import File Control Totals (3b)\")\n",
    "    \n",
    "    sql_file_3b = WORKSPACE_PATH / 'sql' / 'control_totals' / '3b_Control_Totals_Contract_Import_File_Tables.sql'\n",
    "    \n",
    "    if not sql_file_exists(sql_file_3b):\n",
    "        ux.warning(f\"⚠ SQL file not found: {sql_file_3b}\")\n",
    "        ux.info(\"Skipping 3b execution\")\n",
    "    else:\n",
    "        ux.info(f\"Executing: {sql_file_3b.name}\")\n",
    "        ux.info(f\"Parameters: DATE_VALUE={date_value}, CYCLE_TYPE={cycle_type}\")\n",
    "        ux.info(\"\")\n",
    "        \n",
    "        try:\n",
    "            # Execute SQL script - returns list of DataFrames (one per SELECT)\n",
    "            import_file_results = execute_query_from_file(\n",
    "                sql_file_3b,\n",
    "                params={'DATE_VALUE': date_value, 'CYCLE_TYPE': cycle_type},\n",
    "                connection='ASSURANT',\n",
    "                database='DW_EXP_MGMT_USER'\n",
    "            )\n",
    "            \n",
    "            ux.success(f\"✓ Executed 3b script: {len(import_file_results)} result set(s)\")\n",
    "            step.log(f\"Executed 3b script: {len(import_file_results)} result sets\")\n",
    "            \n",
    "            # Save combined results to CSV for investigation (comma-delimited)\n",
    "            if import_file_results:\n",
    "                notebook_dir = context.notebook_path.parent\n",
    "                df_3b_combined = pd.concat(import_file_results, ignore_index=True)\n",
    "                csv_3b_paths = save_dataframes_to_csv(\n",
    "                    df_3b_combined,\n",
    "                    f\"Control_Totals_3b_{date_value}\",\n",
    "                    output_dir=notebook_dir,\n",
    "                    delimiter=','\n",
    "                )\n",
    "                csv_3b_path = csv_3b_paths[0] if csv_3b_paths else None\n",
    "                if csv_3b_path:\n",
    "                    ux.info(f\"  Raw data saved to: {csv_3b_path.name}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            ux.error(f\"✗ Error executing 3b script: {str(e)}\")\n",
    "            step.log(f\"Error executing 3b script: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edm_control_totals_header",
   "metadata": {},
   "source": [
    "## 5) Execute RMS EDM Control Totals (3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "execute_3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute 3d_RMS_EDM_Control_Totals.sql\n",
    "edm_results = []\n",
    "df_3d_normalized = None\n",
    "csv_3d_path = None\n",
    "\n",
    "if execution_failed:\n",
    "    ux.warning(\"⏭ Skipping 3d execution due to previous error\")\n",
    "elif workspace_edm_full_name is None:\n",
    "    ux.warning(\"⚠ Cannot execute 3d: Workspace EDM not available\")\n",
    "else:\n",
    "    ux.subheader(\"Execute RMS EDM Control Totals (3d)\")\n",
    "\n",
    "    sql_file_3d = WORKSPACE_PATH / 'sql' / 'control_totals' / '3d_RMS_EDM_Control_Totals.sql'\n",
    "\n",
    "    if not sql_file_exists(sql_file_3d):\n",
    "        ux.warning(f\"⚠ SQL file not found: {sql_file_3d}\")\n",
    "        ux.info(\"Skipping 3d execution\")\n",
    "    else:\n",
    "        ux.info(f\"Executing: {sql_file_3d.name}\")\n",
    "        ux.info(f\"Parameters: WORKSPACE_EDM={workspace_edm_full_name}, DATE_VALUE={date_value}, CYCLE_TYPE={cycle_type}\")\n",
    "        ux.info(\"\")\n",
    "\n",
    "        try:\n",
    "            # Execute SQL script - returns list of DataFrames (10 result sets)\n",
    "            edm_results = execute_query_from_file(\n",
    "                sql_file_3d,\n",
    "                params={\n",
    "                    'WORKSPACE_EDM': workspace_edm_full_name,\n",
    "                    'DATE_VALUE': date_value,\n",
    "                    'CYCLE_TYPE': cycle_type\n",
    "                },\n",
    "                connection='DATABRIDGE'\n",
    "            )\n",
    "\n",
    "            ux.success(f\"✓ Executed 3d script: {len(edm_results)} result set(s)\")\n",
    "            step.log(f\"Executed 3d script: {len(edm_results)} result sets\")\n",
    "\n",
    "            # Normalize the 10 result sets into a single DataFrame (merged by PORTNAME)\n",
    "            if edm_results and len(edm_results) >= 10:\n",
    "                from helpers.control_totals import normalize_3d_results\n",
    "                df_3d_normalized = normalize_3d_results(edm_results)\n",
    "\n",
    "                if df_3d_normalized is not None and not df_3d_normalized.empty:\n",
    "                    ux.success(f\"✓ Normalized 3d results: {len(df_3d_normalized)} unique PORTNAMEs\")\n",
    "\n",
    "                    # Save normalized results to CSV for investigation (comma-delimited)\n",
    "                    notebook_dir = context.notebook_path.parent\n",
    "                    csv_3d_paths = save_dataframes_to_csv(\n",
    "                        df_3d_normalized,\n",
    "                        f\"Control_Totals_3d_{date_value}\",\n",
    "                        output_dir=notebook_dir,\n",
    "                        delimiter=','\n",
    "                    )\n",
    "                    csv_3d_path = csv_3d_paths[0] if csv_3d_paths else None\n",
    "                    if csv_3d_path:\n",
    "                        ux.info(f\"  Normalized data saved to: {csv_3d_path.name}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            ux.error(f\"✗ Error executing 3d script: {str(e)}\")\n",
    "            step.log(f\"Error executing 3d script: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparison_header",
   "metadata": {},
   "source": [
    "## 6) Compare Import File (3b) vs RMS EDM (3d) Control Totals\n",
    "\n",
    "Compares control totals between 3b (Contract Import File) and 3d (RMS EDM):\n",
    "\n",
    "**Non-Flood perils** (7 attributes): PolicyCount, PolicyPremium, PolicyLimit, LocationCountDistinct, TotalReplacementValue, LocationLimit, LocationDeductible\n",
    "\n",
    "**Flood perils** (10 attributes): Adds AttachmentPoint, PolicyDeductible, PolicySublimit\n",
    "\n",
    "**A difference of 0 means the values match.** Detailed results are exported to Excel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compare_3b_vs_3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare 3b vs 3d control totals\n",
    "comparison_results = None\n",
    "all_matched = False\n",
    "non_flood_summary = {}\n",
    "flood_summary = {}\n",
    "\n",
    "if execution_failed:\n",
    "    ux.warning(\"⏭ Skipping comparison due to previous error\")\n",
    "elif not import_file_results or not edm_results:\n",
    "    ux.warning(\"⚠ Cannot compare: Missing 3b or 3d results\")\n",
    "else:\n",
    "    ux.subheader(\"3b vs 3d Comparison Results\")\n",
    "    \n",
    "    try:\n",
    "        # Get ExposureGroup -> Portname mapping from configuration\n",
    "        exposure_group_mapping = get_exposure_group_portname_mapping(config_data)\n",
    "        \n",
    "        # Run comparison (pivot format - one row per PORTNAME)\n",
    "        comparison_results, all_matched = compare_3b_vs_3d_pivot(\n",
    "            import_file_results,\n",
    "            edm_results,\n",
    "            exposure_group_mapping\n",
    "        )\n",
    "        \n",
    "        if comparison_results is not None and not comparison_results.empty:\n",
    "            # Split into Flood and Non-Flood for separate summaries\n",
    "            is_flood = comparison_results['PORTNAME'].str.startswith('USFL_')\n",
    "            flood_results = comparison_results[is_flood]\n",
    "            non_flood_results = comparison_results[~is_flood]\n",
    "            \n",
    "            # Non-Flood summary\n",
    "            if not non_flood_results.empty:\n",
    "                non_flood_total = len(non_flood_results)\n",
    "                non_flood_matched = (non_flood_results['Status'] == 'MATCH').sum()\n",
    "                non_flood_mismatched = non_flood_total - non_flood_matched\n",
    "                non_flood_summary = {\n",
    "                    'total': non_flood_total,\n",
    "                    'matched': int(non_flood_matched),\n",
    "                    'mismatched': int(non_flood_mismatched)\n",
    "                }\n",
    "                \n",
    "                ux.info(\"Non-Flood Perils:\")\n",
    "                if non_flood_mismatched == 0:\n",
    "                    ux.success(f\"  ✓ All {non_flood_total} exposure groups match\")\n",
    "                else:\n",
    "                    ux.warning(f\"  ⚠ {non_flood_mismatched} of {non_flood_total} exposure groups have mismatches\")\n",
    "            \n",
    "            # Flood summary\n",
    "            if not flood_results.empty:\n",
    "                flood_total = len(flood_results)\n",
    "                flood_matched = (flood_results['Status'] == 'MATCH').sum()\n",
    "                flood_mismatched = flood_total - flood_matched\n",
    "                flood_summary = {\n",
    "                    'total': flood_total,\n",
    "                    'matched': int(flood_matched),\n",
    "                    'mismatched': int(flood_mismatched)\n",
    "                }\n",
    "                \n",
    "                ux.info(\"Flood Perils (USFL_*):\")\n",
    "                if flood_mismatched == 0:\n",
    "                    ux.success(f\"  ✓ All {flood_total} exposure groups match\")\n",
    "                else:\n",
    "                    ux.warning(f\"  ⚠ {flood_mismatched} of {flood_total} exposure groups have mismatches\")\n",
    "            \n",
    "            # Log to step\n",
    "            total_groups = len(comparison_results)\n",
    "            matched_groups = (comparison_results['Status'] == 'MATCH').sum()\n",
    "            step.log(f\"3b vs 3d comparison complete: {matched_groups}/{total_groups} groups matched\")\n",
    "        else:\n",
    "            ux.warning(\"No comparison results generated\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        ux.error(f\"✗ Error comparing control totals: {str(e)}\")\n",
    "        step.log(f\"Error comparing control totals: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "export_comparison_header",
   "metadata": {},
   "source": [
    "### Export Comparison Results to Excel\n",
    "\n",
    "Results will be exported after 3d vs 3e comparison is complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "export_comparison_excel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export will happen after 3d vs 3e comparison\n",
    "# See \"Export Control Totals to Excel\" section below\n",
    "ux.info(\"Comparison export deferred until after 3d vs 3e comparison\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "geohaz_header",
   "metadata": {},
   "source": [
    "## 7) Execute GeoHaz Control Totals (3e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "execute_3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute GeoHaz Control Totals Query\n",
    "geocoding_results = None\n",
    "csv_3e_path = None\n",
    "\n",
    "if execution_failed:\n",
    "    ux.warning(\"⏭ Skipping 3e execution due to previous error\")\n",
    "elif workspace_edm_full_name is None:\n",
    "    ux.warning(\"⚠ Cannot execute 3e: Workspace EDM not available\")\n",
    "else:\n",
    "    ux.subheader(\"Execute GeoHaz Control Totals (3e)\")\n",
    "    \n",
    "    sql_file_3e = WORKSPACE_PATH / 'sql' / 'control_totals' / '3e_GeocodingSummary.sql'\n",
    "    \n",
    "    if not sql_file_exists(sql_file_3e):\n",
    "        ux.warning(f\"⚠ SQL file not found: {sql_file_3e}\")\n",
    "        ux.info(\"Skipping 3e execution\")\n",
    "    else:\n",
    "        ux.info(f\"Executing: {sql_file_3e.name}\")\n",
    "        ux.info(f\"Parameters: WORKSPACE_EDM={workspace_edm_full_name}, DATE_VALUE={date_value}, CYCLE_TYPE={cycle_type}\")\n",
    "        ux.info(\"\")\n",
    "        \n",
    "        try:\n",
    "            result = execute_query_from_file(\n",
    "                sql_file_3e,\n",
    "                params={\n",
    "                    'WORKSPACE_EDM': workspace_edm_full_name,\n",
    "                    'CYCLE_TYPE': cycle_type,\n",
    "                    'DATE_VALUE': date_value\n",
    "                },\n",
    "                connection='DATABRIDGE'\n",
    "            )\n",
    "            \n",
    "            # Extract geocoding results (first result set)\n",
    "            geocoding_results = result[0] if isinstance(result, list) else result\n",
    "            \n",
    "            ux.success(f\"✓ Executed 3e script: {len(geocoding_results)} geocoding records retrieved\")\n",
    "            step.log(f\"Executed 3e script: {len(geocoding_results)} geocoding records\")\n",
    "            \n",
    "            # Save results to CSV for investigation (comma-delimited)\n",
    "            if geocoding_results is not None and not geocoding_results.empty:\n",
    "                notebook_dir = context.notebook_path.parent\n",
    "                csv_3e_paths = save_dataframes_to_csv(\n",
    "                    geocoding_results,\n",
    "                    f\"Control_Totals_3e_{date_value}\",\n",
    "                    output_dir=notebook_dir,\n",
    "                    delimiter=','\n",
    "                )\n",
    "                csv_3e_path = csv_3e_paths[0] if csv_3e_paths else None\n",
    "                if csv_3e_path:\n",
    "                    ux.info(f\"  Raw data saved to: {csv_3e_path.name}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            ux.error(f\"✗ Error executing 3e script: {str(e)}\")\n",
    "            step.log(f\"Error executing 3e script: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "geohaz_validation_header",
   "metadata": {},
   "source": [
    "### Validate GeoHaz Thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "validate_geohaz",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate geocoding results against configuration thresholds\n",
    "validation_results = None\n",
    "geohaz_all_passed = False\n",
    "geohaz_summary = {}\n",
    "\n",
    "if execution_failed:\n",
    "    ux.warning(\"⏭ Skipping GeoHaz validation due to previous error\")\n",
    "elif geocoding_results is None or geocoding_results.empty:\n",
    "    ux.warning(\"⚠ No geocoding results to validate\")\n",
    "else:\n",
    "    ux.subheader(\"GeoHaz Threshold Validation\")\n",
    "    \n",
    "    # Get GeoHaz thresholds from configuration\n",
    "    geohaz_thresholds = config_data.get('GeoHaz Thresholds', [])\n",
    "    \n",
    "    if not geohaz_thresholds:\n",
    "        ux.warning(\"⚠ No GeoHaz thresholds found in configuration - skipping validation\")\n",
    "    else:\n",
    "        # Get portfolio to import file mapping from configuration\n",
    "        import_file_mapping = get_import_file_mapping_from_config(config_data)\n",
    "        \n",
    "        # Perform validation\n",
    "        validation_results, geohaz_all_passed = validate_geohaz_thresholds(\n",
    "            geocoding_results=geocoding_results,\n",
    "            geohaz_thresholds=geohaz_thresholds,\n",
    "            import_file_mapping=import_file_mapping\n",
    "        )\n",
    "        \n",
    "        # Handle empty validation results (e.g., no matching portfolios or all portfolios empty)\n",
    "        if validation_results is None or validation_results.empty:\n",
    "            ux.warning(\"⚠ No geocoding results matched the configured thresholds\")\n",
    "            ux.info(\"This may occur when:\")\n",
    "            ux.info(\"  - No portfolios in geocoding results match Import File names in thresholds\")\n",
    "            ux.info(\"  - All matching portfolios had zero locations\")\n",
    "            step.log(\"GeoHaz validation: No matching results to validate\")\n",
    "        else:\n",
    "            # Display summary\n",
    "            total_checks = len(validation_results)\n",
    "            passed_checks = len(validation_results[validation_results['Status'] == 'PASS'])\n",
    "            failed_checks = len(validation_results[validation_results['Status'] == 'FAIL'])\n",
    "            \n",
    "            geohaz_summary = {\n",
    "                'total_checks': int(total_checks),\n",
    "                'passed_checks': int(passed_checks),\n",
    "                'failed_checks': int(failed_checks),\n",
    "                'all_passed': bool(geohaz_all_passed)\n",
    "            }\n",
    "            \n",
    "            if geohaz_all_passed:\n",
    "                ux.success(f\"✓ All {total_checks} geocoding thresholds met\")\n",
    "            else:\n",
    "                ux.warning(f\"⚠ {failed_checks} of {total_checks} geocoding thresholds not met\")\n",
    "            \n",
    "            # Log validation status\n",
    "            if geohaz_all_passed:\n",
    "                step.log(f\"GeoHaz validation: All {total_checks} thresholds met\")\n",
    "            else:\n",
    "                step.log(f\"GeoHaz validation: {failed_checks}/{total_checks} thresholds failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "geohaz_export_header",
   "metadata": {},
   "source": [
    "### Export GeoHaz Validation to Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "export_geohaz_excel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export validation results to Excel (one sheet per Import File)\n",
    "excel_geohaz_path = None\n",
    "\n",
    "if validation_results is not None and not validation_results.empty:\n",
    "    # Get the notebook directory for output\n",
    "    notebook_dir = context.notebook_path.parent\n",
    "    \n",
    "    excel_geohaz_path = save_geohaz_validation_to_excel(\n",
    "        validation_results=validation_results,\n",
    "        date_value=date_value,\n",
    "        cycle_type=cycle_type,\n",
    "        output_dir=notebook_dir\n",
    "    )\n",
    "    \n",
    "    if excel_geohaz_path:\n",
    "        ux.success(f\"✓ GeoHaz validation exported to: {excel_geohaz_path.name}\")\n",
    "        step.log(f\"GeoHaz validation exported to: {excel_geohaz_path}\")\n",
    "else:\n",
    "    ux.info(\"No GeoHaz validation results to export\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jyv6dw3xe8i",
   "metadata": {},
   "source": [
    "## 8) Compare RMS EDM (3d) vs Geocoding Summary (3e) Control Totals\n",
    "\n",
    "Compares control totals between 3d (RMS EDM) and 3e (Geocoding Summary) for base portfolios only.\n",
    "\n",
    "**Attributes compared:**\n",
    "- RiskCount (3e) vs LocationCountDistinct (3d)\n",
    "- TIV (3e) vs LocationLimit (3d)\n",
    "- TRV (3e) vs TotalReplacementValue (3d)\n",
    "\n",
    "**A difference of 0 means the values match.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "litl9h0863",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare 3d vs 3e control totals\n",
    "comparison_3d_vs_3e = None\n",
    "all_matched_3d_vs_3e = False\n",
    "summary_3d_vs_3e = {}\n",
    "\n",
    "if execution_failed:\n",
    "    ux.warning(\"Skipping 3d vs 3e comparison due to previous error\")\n",
    "elif not edm_results or geocoding_results is None or geocoding_results.empty:\n",
    "    ux.warning(\"Cannot compare: Missing 3d or 3e results\")\n",
    "else:\n",
    "    ux.subheader(\"3d vs 3e Comparison Results\")\n",
    "\n",
    "    try:\n",
    "        # Get base portfolio names from configuration (using existing function)\n",
    "        base_portfolio_list = get_base_portfolios(config_data.get('Portfolios', []))\n",
    "        base_portfolio_names = [p['Portfolio'] for p in base_portfolio_list]\n",
    "        ux.info(f\"Base portfolios: {', '.join(base_portfolio_names)}\")\n",
    "\n",
    "        # Run comparison (pivot format)\n",
    "        comparison_3d_vs_3e, all_matched_3d_vs_3e = compare_3d_vs_3e_pivot(\n",
    "            edm_results,\n",
    "            [geocoding_results],\n",
    "            base_portfolio_names\n",
    "        )\n",
    "\n",
    "        if comparison_3d_vs_3e is not None and not comparison_3d_vs_3e.empty:\n",
    "            # Split into Flood and Non-Flood\n",
    "            is_flood = comparison_3d_vs_3e['PORTNAME'].str.startswith('USFL_')\n",
    "            flood_results_3d_3e = comparison_3d_vs_3e[is_flood]\n",
    "            non_flood_results_3d_3e = comparison_3d_vs_3e[~is_flood]\n",
    "\n",
    "            # Display summary\n",
    "            total = len(comparison_3d_vs_3e)\n",
    "            matched = (comparison_3d_vs_3e['Status'] == 'MATCH').sum()\n",
    "\n",
    "            summary_3d_vs_3e = {\n",
    "                'total': total,\n",
    "                'matched': int(matched),\n",
    "                'mismatched': total - int(matched),\n",
    "                'all_matched': bool(all_matched_3d_vs_3e)\n",
    "            }\n",
    "\n",
    "            if all_matched_3d_vs_3e:\n",
    "                ux.success(f\"All {total} base portfolios match\")\n",
    "            else:\n",
    "                ux.warning(f\"{total - matched} of {total} base portfolios have mismatches\")\n",
    "\n",
    "            step.log(f\"3d vs 3e comparison: {matched}/{total} matched\")\n",
    "        else:\n",
    "            ux.warning(\"No comparison results generated\")\n",
    "\n",
    "    except Exception as e:\n",
    "        ux.error(f\"Error comparing 3d vs 3e: {str(e)}\")\n",
    "        step.log(f\"Error comparing 3d vs 3e: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82qe6uu1qzh",
   "metadata": {},
   "source": [
    "### Export Control Totals to Excel\n",
    "\n",
    "Exports both 3b vs 3d and 3d vs 3e comparison results to a single Excel file with three sheets:\n",
    "- **3b_vs_3d_NonFlood**: Non-Flood perils comparison\n",
    "- **3b_vs_3d_Flood**: Flood perils comparison  \n",
    "- **3d_vs_3e**: Base portfolios comparison (all perils combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ek17nlzk8k",
   "metadata": {},
   "outputs": [],
   "source": "# Export comparison results to Excel (combined 3b vs 3d and 3d vs 3e)\nexcel_control_totals_path = None\n\n# Check if we have any results to export\nhas_3b_vs_3d = comparison_results is not None and not comparison_results.empty\nhas_3d_vs_3e = comparison_3d_vs_3e is not None and not comparison_3d_vs_3e.empty\n\nif has_3b_vs_3d or has_3d_vs_3e:\n    notebook_dir = context.notebook_path.parent\n\n    excel_control_totals_path = save_control_totals_3b_vs_3d_to_excel(\n        comparison_results_3b_vs_3d=comparison_results,\n        date_value=date_value,\n        cycle_type=cycle_type,\n        output_dir=notebook_dir,\n        comparison_results_3d_vs_3e=comparison_3d_vs_3e\n    )\n\n    if excel_control_totals_path:\n        sheets_written = []\n        if has_3b_vs_3d:\n            sheets_written.extend(['3b_vs_3d_NonFlood', '3b_vs_3d_Flood'])\n        if has_3d_vs_3e:\n            sheets_written.append('3d_vs_3e')\n        ux.success(f\"Control totals exported to: {excel_control_totals_path.name}\")\n        ux.info(f\"  Sheets: {', '.join(sheets_written)}\")\n        step.log(f\"Control totals exported to: {excel_control_totals_path}\")\nelse:\n    ux.info(\"No comparison results to export\")"
  },
  {
   "cell_type": "markdown",
   "id": "complete_header",
   "metadata": {},
   "source": [
    "## 9) Complete Step Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complete_step",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete step execution\n",
    "ux.header(\"Step Completion\")\n",
    "\n",
    "if execution_failed:\n",
    "    # Handle configuration/execution failure\n",
    "    from helpers.step import update_step_run\n",
    "    from helpers.constants import StepStatus\n",
    "    \n",
    "    update_step_run(step.run_id, StepStatus.FAILED, error_message=error_message)\n",
    "    \n",
    "    ux.error(\"\\n\" + \"=\"*60)\n",
    "    ux.error(\"CONTROL TOTALS EXECUTION FAILED\")\n",
    "    ux.error(\"=\"*60)\n",
    "    ux.error(f\"\\nError: {error_message}\")\n",
    "    ux.info(\"\\nPlease fix the error and retry.\")\n",
    "\n",
    "else:\n",
    "    # Build comparison summary for output\n",
    "    comparison_summary = {}\n",
    "    if comparison_results is not None and not comparison_results.empty:\n",
    "        total_groups = len(comparison_results)\n",
    "        matched_groups = int((comparison_results['Status'] == 'MATCH').sum())\n",
    "        comparison_summary = {\n",
    "            'total_exposure_groups': total_groups,\n",
    "            'matched_groups': matched_groups,\n",
    "            'mismatched_groups': total_groups - matched_groups,\n",
    "            'all_matched': bool(all_matched),\n",
    "            'non_flood': non_flood_summary,\n",
    "            'flood': flood_summary\n",
    "        }\n",
    "    \n",
    "    # Complete the step successfully\n",
    "    output_data = {\n",
    "        'date_value': date_value,\n",
    "        'cycle_type': cycle_type,\n",
    "        'import_file_result_count': len(import_file_results),\n",
    "        'edm_result_count': len(edm_results),\n",
    "        '3b_vs_3d_comparison': comparison_summary,\n",
    "        '3d_vs_3e_comparison': summary_3d_vs_3e,\n",
    "        'geohaz_validation': geohaz_summary\n",
    "    }\n",
    "    step.complete(output_data)\n",
    "\n",
    "    ux.success(\"\\n\" + \"=\"*60)\n",
    "    ux.success(\"✓ CONTROL TOTALS VALIDATION COMPLETED\")\n",
    "    ux.success(\"=\"*60)\n",
    "    \n",
    "    # Display 3b vs 3d summary\n",
    "    ux.info(f\"\\nImport File (3b): {len(import_file_results)} result set(s)\")\n",
    "    ux.info(f\"RMS EDM (3d): {len(edm_results)} result set(s)\")\n",
    "    \n",
    "    if comparison_summary:\n",
    "        ux.info(f\"\\n3b vs 3d Comparison:\")\n",
    "        \n",
    "        # Non-Flood summary\n",
    "        if non_flood_summary:\n",
    "            if non_flood_summary['mismatched'] == 0:\n",
    "                ux.success(f\"  Non-Flood: ✓ All {non_flood_summary['total']} groups match\")\n",
    "            else:\n",
    "                ux.warning(f\"  Non-Flood: ⚠ {non_flood_summary['mismatched']}/{non_flood_summary['total']} groups have mismatches\")\n",
    "        \n",
    "        # Flood summary\n",
    "        if flood_summary:\n",
    "            if flood_summary['mismatched'] == 0:\n",
    "                ux.success(f\"  Flood: ✓ All {flood_summary['total']} groups match\")\n",
    "            else:\n",
    "                ux.warning(f\"  Flood: ⚠ {flood_summary['mismatched']}/{flood_summary['total']} groups have mismatches\")\n",
    "    \n",
    "    # Display 3d vs 3e summary\n",
    "    if summary_3d_vs_3e:\n",
    "        ux.info(f\"\\n3d vs 3e Comparison (Base Portfolios):\")\n",
    "        if summary_3d_vs_3e.get('all_matched'):\n",
    "            ux.success(f\"  ✓ All {summary_3d_vs_3e['total']} base portfolios match\")\n",
    "        else:\n",
    "            ux.warning(f\"  ⚠ {summary_3d_vs_3e['mismatched']}/{summary_3d_vs_3e['total']} base portfolios have mismatches\")\n",
    "    \n",
    "    # Display GeoHaz summary\n",
    "    if geohaz_summary:\n",
    "        ux.info(f\"\\nGeoHaz Validation: {geohaz_summary['passed_checks']}/{geohaz_summary['total_checks']} checks passed\")\n",
    "        if geohaz_summary['all_passed']:\n",
    "            ux.success(\"  ✓ All geocoding thresholds met\")\n",
    "        else:\n",
    "            ux.warning(f\"  ⚠ {geohaz_summary['failed_checks']} threshold(s) not met\")\n",
    "    elif validation_results is not None and validation_results.empty:\n",
    "        ux.info(\"\\nGeoHaz validation: No matching results to validate\")\n",
    "    else:\n",
    "        ux.info(\"\\nGeoHaz validation: Skipped (no thresholds configured or no results)\")\n",
    "    \n",
    "    # Display exported files\n",
    "    ux.info(\"\\nExported Files:\")\n",
    "    if csv_3b_path:\n",
    "        ux.info(f\"  - {csv_3b_path.name}\")\n",
    "    if csv_3d_path:\n",
    "        ux.info(f\"  - {csv_3d_path.name}\")\n",
    "    if csv_3e_path:\n",
    "        ux.info(f\"  - {csv_3e_path.name}\")\n",
    "    if excel_control_totals_path:\n",
    "        ux.info(f\"  - {excel_control_totals_path.name}\")\n",
    "    if excel_geohaz_path:\n",
    "        ux.info(f\"  - {excel_geohaz_path.name}\")\n",
    "    \n",
    "    ux.info(\"\\nNext: Proceed to Stage 04 (Analysis Execution)\")\n",
    "\n",
    "    # Send Teams notification for milestone completion\n",
    "    try:\n",
    "        from helpers.teams_notification import TeamsNotificationClient, build_notification_actions\n",
    "        from helpers.database import get_current_schema\n",
    "\n",
    "        teams = TeamsNotificationClient()\n",
    "        schema = get_current_schema()\n",
    "        actions = build_notification_actions(\n",
    "            notebook_path=str(context.notebook_path),\n",
    "            cycle_name=context.cycle_name,\n",
    "            schema=schema\n",
    "        )\n",
    "        \n",
    "        # Build comparison status message\n",
    "        comparison_msg = \"\"\n",
    "        if comparison_summary:\n",
    "            if non_flood_summary:\n",
    "                if non_flood_summary['mismatched'] == 0:\n",
    "                    comparison_msg += f\"- Non-Flood: ✓ All {non_flood_summary['total']} groups match\\n\"\n",
    "                else:\n",
    "                    comparison_msg += f\"- Non-Flood: ⚠ {non_flood_summary['mismatched']}/{non_flood_summary['total']} groups have mismatches\\n\"\n",
    "            if flood_summary:\n",
    "                if flood_summary['mismatched'] == 0:\n",
    "                    comparison_msg += f\"- Flood: ✓ All {flood_summary['total']} groups match\\n\"\n",
    "                else:\n",
    "                    comparison_msg += f\"- Flood: ⚠ {flood_summary['mismatched']}/{flood_summary['total']} groups have mismatches\\n\"\n",
    "        \n",
    "        # Build 3d vs 3e status message\n",
    "        comparison_3d_3e_msg = \"\"\n",
    "        if summary_3d_vs_3e:\n",
    "            if summary_3d_vs_3e.get('all_matched'):\n",
    "                comparison_3d_3e_msg = f\"- 3d vs 3e: ✓ All {summary_3d_vs_3e['total']} base portfolios match\\n\"\n",
    "            else:\n",
    "                comparison_3d_3e_msg = f\"- 3d vs 3e: ⚠ {summary_3d_vs_3e['mismatched']}/{summary_3d_vs_3e['total']} base portfolios have mismatches\\n\"\n",
    "        \n",
    "        # Build GeoHaz status message\n",
    "        geohaz_msg = \"\"\n",
    "        if geohaz_summary:\n",
    "            if geohaz_summary['all_passed']:\n",
    "                geohaz_msg = f\"- GeoHaz: ✓ All {geohaz_summary['total_checks']} thresholds met\\n\"\n",
    "            else:\n",
    "                geohaz_msg = f\"- GeoHaz: ⚠ {geohaz_summary['failed_checks']}/{geohaz_summary['total_checks']} thresholds not met\\n\"\n",
    "\n",
    "        teams.send_success(\n",
    "            title=f\"[{context.cycle_name}] Stage 03 Control Totals Complete\",\n",
    "            message=f\"**Cycle:** {context.cycle_name}\\n\"\n",
    "                    f\"**Stage:** {context.stage_name}\\n\"\n",
    "                    f\"**Step:** {context.step_name}\\n\\n\"\n",
    "                    f\"**Results:**\\n\"\n",
    "                    f\"- Import File (3b): {len(import_file_results)} result set(s)\\n\"\n",
    "                    f\"- RMS EDM (3d): {len(edm_results)} result set(s)\\n\\n\"\n",
    "                    f\"**3b vs 3d Comparison:**\\n\"\n",
    "                    f\"{comparison_msg}\\n\"\n",
    "                    f\"**3d vs 3e Comparison:**\\n\"\n",
    "                    f\"{comparison_3d_3e_msg}\\n\"\n",
    "                    f\"**GeoHaz Validation:**\\n\"\n",
    "                    f\"{geohaz_msg}\\n\"\n",
    "                    f\"Ready to proceed to Stage 04 Analysis Execution.\",\n",
    "            actions=actions\n",
    "        )\n",
    "        ux.info(\"\\nTeams notification sent.\")\n",
    "    except Exception as e:\n",
    "        ux.warning(f\"\\nCould not send Teams notification: {str(e)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}